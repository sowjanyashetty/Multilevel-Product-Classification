{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcoQ9DtXTowk"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import re\n",
        "import string\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn import model_selection, naive_bayes, svm\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "#import spacy\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import metrics\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import urllib.request\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, BatchNormalization, Input\n",
        "from keras.layers import Conv2D, MaxPooling2D, concatenate\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing import image\n",
        "\n",
        "from tqdm import tqdm\n",
        "from keras.models import load_model, Model\n",
        "from pathlib import Path\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4w62AUNSTowm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OSUPvzGSTown"
      },
      "outputs": [],
      "source": [
        "pd.set_option('display.max_rows',None)\n",
        "train=pd.read_csv(r'train.csv')\n",
        "train=train.replace(np.nan, '',regex=True)\n",
        "val=pd.read_csv(r'validation.csv')\n",
        "val=val.replace(np.nan, '',regex=True)\n",
        "test=pd.read_csv(r'newtestdata1.csv')\n",
        "test=test.replace(np.nan, '',regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofZqlEvQTown"
      },
      "outputs": [],
      "source": [
        "\n",
        "punctuaions=set(string.punctuation)\n",
        "\n",
        "#inputs\n",
        "X_text_train=train['title'].map(str)+' '+train['description'].map(str)\n",
        "X_text_val=val['title'].map(str)+' '+val['description'].map(str)\n",
        "X_text_test=test['title'].map(str)+' '+test['description'].map(str)\n",
        "#outputs\n",
        "y_text_train=train['categories__2'].values\n",
        "y_text_test=test['categories__2'].values\n",
        "y_text_val=val['categories__2'].values\n",
        "y_text_val=[x.lower() for x in y_text_val ]\n",
        "y_text_train=[x.lower() for x in y_text_train ]\n",
        "y_text_test=[x.lower() for x in y_text_test ]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7l0EkVWHTown"
      },
      "outputs": [],
      "source": [
        "def leafnode_extraction(data_frame):\n",
        "    leafnode=[]\n",
        "    for index,col in data_frame.iterrows():\n",
        "        if len(col['categories__6'])!=0:\n",
        "            leafnode.append(col['categories__6'])\n",
        "        elif len(col['categories__5'])!=0:\n",
        "            leafnode.append(col['categories__5'])\n",
        "        elif len(col['categories__4'])!=0:\n",
        "            leafnode.append(col['categories__4'])\n",
        "        elif len(col['categories__3'])!=0:\n",
        "            leafnode.append(col['categories__3'])\n",
        "        else:\n",
        "            leafnode.append(col['categories__2'])\n",
        "    return leafnode\n",
        "\n",
        "\n",
        "\n",
        "#feature extraction\n",
        "def tf_idf_vectorization(inp,test,val):\n",
        "    X_train_tfidf=[]\n",
        "    X_new_tfidf=[]\n",
        "    X_val_tfidf=[]\n",
        "    tfidf_vect1=TfidfVectorizer(max_features=5000)\n",
        "    tfidf_vect1.fit(inp['final_lemmatized_string'])\n",
        "    X_train_tfidf = tfidf_vect1.transform(inp['final_lemmatized_string'])\n",
        "    X_new_tfidf = tfidf_vect1.transform(test['final_lemmatized_string'])\n",
        "    X_val_tfidf = tfidf_vect1.transform(val['final_lemmatized_string'])\n",
        "    print(X_train_tfidf.shape)\n",
        "    print(X_new_tfidf.shape)\n",
        "    return  X_train_tfidf,X_new_tfidf,X_val_tfidf\n",
        "def create_model(dims,n):\n",
        "    model=Sequential()\n",
        "    model.add(Dense(512, input_dim=dims[1],activation='relu'))\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(Dense(32,activation='relu'))\n",
        "    model.add(Dense(n, activation='softmax'))\n",
        "    model.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPGlqV1tTowo",
        "outputId": "6fc38b77-2f39-4c9f-e1b8-fbb01bae16b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "#stopwords\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.tokenize import word_tokenize\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stop_words.update(['.', ',', '\"', \"'\", ':', ';', '(', ')', '[', ']', '{', '}','&','nan'])\n",
        "stemmer = SnowballStemmer('english')\n",
        "#processed_train = []\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        },
        "id": "DDeaJzE6Towo",
        "outputId": "93685be5-e732-4de8-9df2-e7f2995b4d77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               title  \\\n",
              "0  Cisco-Linksys EFAH05W EtherFast 10/100 5-Port ...   \n",
              "1  Nikon Coolpix 800 2MP Digital Camera w/ 2x Opt...   \n",
              "2  Aiwa XR-M75 Compact Stereo System (Discontinue...   \n",
              "3                Olympus Stylus Epic DLX 35mm Camera   \n",
              "4  JBL S310 3-Way Floorstanding Speaker (Single S...   \n",
              "\n",
              "                                         description  \\\n",
              "0  The EtherFast 5-Port 10/100 Auto-Sensing Hub f...   \n",
              "1  Nikon first brought 2-megapixel quality to the...   \n",
              "2  With so many compact and mini stereos to choos...   \n",
              "3  Product Information\\nIf you are passionate abo...   \n",
              "4  The JBL S310 is a 3-way, 10-inch floor-standin...   \n",
              "\n",
              "                                               imUrl price brand  \\\n",
              "0  http://ecx.images-amazon.com/images/I/41JSBWRC...  79.0         \n",
              "1  http://ecx.images-amazon.com/images/I/7183RBY6...  7.33         \n",
              "2  http://ecx.images-amazon.com/images/I/41S6N954...               \n",
              "3  http://ecx.images-amazon.com/images/I/41R370QD...               \n",
              "4  http://ecx.images-amazon.com/images/I/4184SSV9...               \n",
              "\n",
              "  categories__1            categories__2        categories__3  \\\n",
              "0   Electronics  Computers & Accessories  Networking Products   \n",
              "1   Electronics           Camera & Photo      Digital Cameras   \n",
              "2   Electronics               Home Audio      Compact Stereos   \n",
              "3   Electronics           Camera & Photo     Film Photography   \n",
              "4   Electronics               Home Audio    Stereo Components   \n",
              "\n",
              "                   categories__4               categories__5 categories__6  \\\n",
              "0                           Hubs                                             \n",
              "1  Point & Shoot Digital Cameras                                             \n",
              "2                                                                            \n",
              "3                   Film Cameras  Point & Shoot Film Cameras                 \n",
              "4                       Speakers      Floorstanding Speakers                 \n",
              "\n",
              "                                     lemmatized_text  \\\n",
              "0  [etherfast, workgroup, hub, etherfast, hub, li...   \n",
              "1  [nikon, coolpix, digital, camera, optical, zoo...   \n",
              "2  [aiwa, compact, stereo, system, discontinued, ...   \n",
              "3  [olympus, stylus, epic, dlx, camera, product, ...   \n",
              "4  [jbl, floorstanding, speaker, single, speaker,...   \n",
              "\n",
              "                             final_lemmatized_string  \n",
              "0   etherfast workgroup hub etherfast hub linksys...  \n",
              "1   nikon coolpix digital camera optical zoom nik...  \n",
              "2   aiwa compact stereo system discontinued manuf...  \n",
              "3   olympus stylus epic dlx camera product inform...  \n",
              "4   jbl floorstanding speaker single speaker blac...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-39f7a297-4215-4ad6-aa41-838a97f1697f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>description</th>\n",
              "      <th>imUrl</th>\n",
              "      <th>price</th>\n",
              "      <th>brand</th>\n",
              "      <th>categories__1</th>\n",
              "      <th>categories__2</th>\n",
              "      <th>categories__3</th>\n",
              "      <th>categories__4</th>\n",
              "      <th>categories__5</th>\n",
              "      <th>categories__6</th>\n",
              "      <th>lemmatized_text</th>\n",
              "      <th>final_lemmatized_string</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Cisco-Linksys EFAH05W EtherFast 10/100 5-Port ...</td>\n",
              "      <td>The EtherFast 5-Port 10/100 Auto-Sensing Hub f...</td>\n",
              "      <td>http://ecx.images-amazon.com/images/I/41JSBWRC...</td>\n",
              "      <td>79.0</td>\n",
              "      <td></td>\n",
              "      <td>Electronics</td>\n",
              "      <td>Computers &amp; Accessories</td>\n",
              "      <td>Networking Products</td>\n",
              "      <td>Hubs</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>[etherfast, workgroup, hub, etherfast, hub, li...</td>\n",
              "      <td>etherfast workgroup hub etherfast hub linksys...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Nikon Coolpix 800 2MP Digital Camera w/ 2x Opt...</td>\n",
              "      <td>Nikon first brought 2-megapixel quality to the...</td>\n",
              "      <td>http://ecx.images-amazon.com/images/I/7183RBY6...</td>\n",
              "      <td>7.33</td>\n",
              "      <td></td>\n",
              "      <td>Electronics</td>\n",
              "      <td>Camera &amp; Photo</td>\n",
              "      <td>Digital Cameras</td>\n",
              "      <td>Point &amp; Shoot Digital Cameras</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>[nikon, coolpix, digital, camera, optical, zoo...</td>\n",
              "      <td>nikon coolpix digital camera optical zoom nik...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Aiwa XR-M75 Compact Stereo System (Discontinue...</td>\n",
              "      <td>With so many compact and mini stereos to choos...</td>\n",
              "      <td>http://ecx.images-amazon.com/images/I/41S6N954...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Electronics</td>\n",
              "      <td>Home Audio</td>\n",
              "      <td>Compact Stereos</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>[aiwa, compact, stereo, system, discontinued, ...</td>\n",
              "      <td>aiwa compact stereo system discontinued manuf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Olympus Stylus Epic DLX 35mm Camera</td>\n",
              "      <td>Product Information\\nIf you are passionate abo...</td>\n",
              "      <td>http://ecx.images-amazon.com/images/I/41R370QD...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Electronics</td>\n",
              "      <td>Camera &amp; Photo</td>\n",
              "      <td>Film Photography</td>\n",
              "      <td>Film Cameras</td>\n",
              "      <td>Point &amp; Shoot Film Cameras</td>\n",
              "      <td></td>\n",
              "      <td>[olympus, stylus, epic, dlx, camera, product, ...</td>\n",
              "      <td>olympus stylus epic dlx camera product inform...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>JBL S310 3-Way Floorstanding Speaker (Single S...</td>\n",
              "      <td>The JBL S310 is a 3-way, 10-inch floor-standin...</td>\n",
              "      <td>http://ecx.images-amazon.com/images/I/4184SSV9...</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>Electronics</td>\n",
              "      <td>Home Audio</td>\n",
              "      <td>Stereo Components</td>\n",
              "      <td>Speakers</td>\n",
              "      <td>Floorstanding Speakers</td>\n",
              "      <td></td>\n",
              "      <td>[jbl, floorstanding, speaker, single, speaker,...</td>\n",
              "      <td>jbl floorstanding speaker single speaker blac...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-39f7a297-4215-4ad6-aa41-838a97f1697f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-39f7a297-4215-4ad6-aa41-838a97f1697f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-39f7a297-4215-4ad6-aa41-838a97f1697f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-7c91ee31-9b12-4bdb-83ce-2d7558596d10\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7c91ee31-9b12-4bdb-83ce-2d7558596d10')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-7c91ee31-9b12-4bdb-83ce-2d7558596d10 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "val",
              "summary": "{\n  \"name\": \"val\",\n  \"rows\": 500,\n  \"fields\": [\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 500,\n        \"samples\": [\n          \"Meade/Laserline CD300RT2 Plastic CD Spinner (300-Capacity) (Discontinued by Manufacturer)\",\n          \"COKIN A153 Gray ND-4 Filter\",\n          \"Professional Kingston MicroSDHC 4GB (4 Gigabyte) Card for TomTom RIDER 2nd Edition GPS with custom formatting and Standard SD Adapter. (SDHC Class 4 Certified)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 447,\n        \"samples\": [\n          \"Professional Kingston MicroSDHC 16GB (16 Gigabyte) Card for Motorola Droid R2D2 Phone Phone with custom formatting and Standard SD Adapter. (SDHC Class 4 Certified)\",\n          \"Enjoy higher local area network and modem throughput with a single PC Card. Patented 3Com Parallel Tasking performance gives you higher throughput to and from your Ethernet or Fast Ethernet network. Built in V.90 56K technology with 3Com's Line Probing performance gives you higher modem throughput too. Enjoy both LAN and modem connections in the office with Nway 10/100 auto-negotiation to automatically configure your PC Card for 10 or 100 Mbps connections. And get reliable modem access on the road with select cellular phones using Direct-Connect Cellular and a separately sold cable.\",\n          \"For use only with Mighty Bright LED lights requiring 3 AAA batteries and the MiniFlex\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"imUrl\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 431,\n        \"samples\": [\n          \"http://ecx.images-amazon.com/images/I/51DEF4AY29L._SY300_.jpg\",\n          \"http://ecx.images-amazon.com/images/I/31LBfPuAwyL.jpg\",\n          \"http://ecx.images-amazon.com/images/I/31AS1JFFD8L._SX300_.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"price\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"1970-01-01 00:00:00\",\n        \"max\": \"1970-01-01 00:00:00.000000549\",\n        \"num_unique_values\": 185,\n        \"samples\": [\n          15.03,\n          11.69,\n          39.36\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"brand\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 56,\n        \"samples\": [\n          \"\",\n          \"Linksys\",\n          \"Fuji\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"categories__1\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Electronics\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"categories__2\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"Portable Audio & Video\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"categories__3\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 54,\n        \"samples\": [\n          \"VCRs\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"categories__4\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 93,\n        \"samples\": [\n          \"Shoe Mount Flashes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"categories__5\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 79,\n        \"samples\": [\n          \"Trackballs\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"categories__6\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lemmatized_text\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"final_lemmatized_string\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 496,\n        \"samples\": [\n          \" memorex jewel case insert pack whether digitally assembling family archive next platinum album trying sensibly track cd generous pack bright white matte finish label ready assist insert jewel case included sheet front back case provided pack compatible laser inkjet printer\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "#Preprocess the text in training and testing dataset stemming and lemmatizing\n",
        "lemmatized_train =[]\n",
        "lemmatized_test=[]\n",
        "lemmatized_val=[]\n",
        "\n",
        "for doc in X_text_train:\n",
        "    tokens = word_tokenize(doc)\n",
        "    tokens=[w.lower() for w in tokens if w.isalpha()]\n",
        "    filtered = [word for word in tokens if word not in stop_words]\n",
        "    lemmatized=[wordnet_lemmatizer.lemmatize(word) for word in filtered]\n",
        "    lemmatized_train.append(lemmatized)\n",
        "\n",
        "for doc in X_text_test:\n",
        "    tokens = word_tokenize(doc)\n",
        "    tokens=[w.lower() for w in tokens if w.isalpha()]\n",
        "    filtered = [word for word in tokens if word not in stop_words]\n",
        "    lemmatized=[wordnet_lemmatizer.lemmatize(word) for word in filtered]\n",
        "    lemmatized_test.append(lemmatized)\n",
        "\n",
        "\n",
        "for doc in X_text_val:\n",
        "    tokens = word_tokenize(doc)\n",
        "    tokens=[w.lower() for w in tokens if w.isalpha()]\n",
        "    filtered = [word for word in tokens if word not in stop_words]\n",
        "    lemmatized=[wordnet_lemmatizer.lemmatize(word) for word in filtered]\n",
        "    lemmatized_val.append(lemmatized)\n",
        "#print(lemmatized_train[1])\n",
        "train['lemmatized_text']=lemmatized_train\n",
        "test['lemmatized_text']=lemmatized_test\n",
        "val['lemmatized_text']=lemmatized_val\n",
        "\n",
        "\n",
        "# Converting array to string\n",
        "row_lst1 =[]\n",
        "for lst in train.loc[:,'lemmatized_text']:\n",
        "    text = ''\n",
        "    for word in lst:\n",
        "        text = text + ' ' + word\n",
        "    row_lst1.append(text)\n",
        "train['final_lemmatized_string']=row_lst1\n",
        "#train.drop('final_stemmed_text',axis=1,inplace=True)\n",
        "train.head()\n",
        "row_lst1 =[]\n",
        "\n",
        "for lst in test.loc[:,'lemmatized_text']:\n",
        "    text = ''\n",
        "    for word in lst:\n",
        "        text = text + ' ' + word\n",
        "    row_lst1.append(text)\n",
        "\n",
        "test['final_lemmatized_string']=row_lst1\n",
        "test.head()\n",
        "row_lst1 =[]\n",
        "for lst in val.loc[:,'lemmatized_text']:\n",
        "    text = ''\n",
        "    for word in lst:\n",
        "        text = text + ' ' + word\n",
        "    row_lst1.append(text)\n",
        "val['final_lemmatized_string']=row_lst1\n",
        "val.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hy7q0ygKTowp"
      },
      "outputs": [],
      "source": [
        "#feature extraction\n",
        "tfidf_vect=TfidfVectorizer(max_features=5000)\n",
        "tfidf_vect.fit(train['final_lemmatized_string'])\n",
        "\n",
        "X_train_tfidf = tfidf_vect.transform(train['final_lemmatized_string'])\n",
        "X_new_tfidf = tfidf_vect.transform(test['final_lemmatized_string'])\n",
        "X_new_val = tfidf_vect.transform(val['final_lemmatized_string'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwZQKGzPTowp"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LHAgqWxdTowq",
        "outputId": "eb67a72d-e9b7-431f-a4fd-183b789f3088"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3565, 11)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Encoding labels\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_labels_train = label_encoder.fit_transform(y_text_train)\n",
        "encoded_labels_train = to_categorical(encoded_labels_train)\n",
        "encoded_labels_test = label_encoder.fit_transform(y_text_test)\n",
        "encoded_labels_test = to_categorical(encoded_labels_test)\n",
        "encoded_labels_val = label_encoder.fit_transform(y_text_val)\n",
        "encoded_labels_val = to_categorical(encoded_labels_val)\n",
        "print(encoded_labels_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvDxb-I0Towq"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Build Denoising Autoencoder (DAE)\n",
        "input_dim = X_train_tfidf.shape[1]\n",
        "input_layer = Input(shape=(input_dim,))\n",
        "encoded = Dense(512, activation='relu')(input_layer)\n",
        "encoded = Dropout(0.5)(encoded)\n",
        "decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
        "dae = Model(input_layer, decoded)\n",
        "dae.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "dae.fit(X_train_tfidf.toarray(), X_train_tfidf.toarray(), epochs=65, batch_size=10, validation_data=(X_new_val.toarray(), X_new_val.toarray()))\n",
        "#dae.save(\"encodelevel.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HIlIMPucTowq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gu55RZwSTowq",
        "outputId": "1089bff7-4ca1-48d0-d70d-4fa3382f4d60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "112/112 [==============================] - 0s 1ms/step\n",
            "68/68 [==============================] - 0s 1ms/step\n",
            "16/16 [==============================] - 0s 2ms/step\n"
          ]
        }
      ],
      "source": [
        "\n",
        "encoder = Model(input_layer, encoded)\n",
        "X_train_encoded = encoder.predict(X_train_tfidf.toarray())\n",
        "X_test_encoded = encoder.predict(X_new_tfidf.toarray())\n",
        "X_val_encoded = encoder.predict(X_new_val.toarray())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtWavK-lTowq"
      },
      "outputs": [],
      "source": [
        "def train_denoising_autoencoder(X_train, X_new, X_new_val):\n",
        "    # Build Denoising Autoencoder (DAE)\n",
        "    input_dim = X_train.shape[1]\n",
        "    input_layer = Input(shape=(input_dim,))\n",
        "    encoded = Dense(512, activation='relu')(input_layer)\n",
        "    encoded = Dropout(0.5)(encoded)\n",
        "    decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
        "\n",
        "    dae = Model(input_layer, decoded)\n",
        "    dae.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "    dae.fit(X_train.toarray(), X_train.toarray(), epochs=50, batch_size=5, validation_data=(X_new_val.toarray(), X_new_val.toarray()))\n",
        "\n",
        "    # Extract features using DAE\n",
        "    encoder = Model(input_layer, encoded)\n",
        "    X_train_encoded = encoder.predict(X_train.toarray())\n",
        "    X_test_encoded = encoder.predict(X_new.toarray())\n",
        "    X_val_encoded = encoder.predict(X_new_val.toarray())\n",
        "    return X_train_encoded, X_test_encoded, X_val_encoded\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R30wPibWTowr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To Download the images for the first time make changes to download train and test images as well\n"
      ],
      "metadata": {
        "id": "fCdOs0BhV5Nm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBVlYEWSTows",
        "outputId": "36e08b89-8914-4539-c831-d64e4b790b71"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 500/500 [02:16<00:00,  3.67it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "500\n"
          ]
        }
      ],
      "source": [
        "#-----To download validation dataset images  Run only once to download images to local path----------\n",
        "\n",
        "val_images=list(val['imUrl'])\n",
        "X_images=[]\n",
        "for i in tqdm(range(0,len(val_images))):\n",
        "    img=Image.open(urllib.request.urlopen(val_images[i]))\n",
        "    X_images.append(img)\n",
        "print(len(val_images))\n",
        "a=0\n",
        "for i in X_images:\n",
        "    if i.mode=='P':\n",
        "        i=i.convert('RGB')\n",
        "    b='C:/Users/sowjanya/Documents/RMTC_IMPLEMENTATION/code/final_modified_folder/val_images/'+str(a)+'.jpg'\n",
        "    i.save(b)\n",
        "    a=a+1"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Hg25RIVNVzwm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extract Images from drive**"
      ],
      "metadata": {
        "id": "9wYy9PpxV0OJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Path to the zip file in Google Drive\n",
        "zip_file_path = '/content/drive/My Drive/RMTC-08-04-24/train_images.zip'\n",
        "\n",
        "# Directory to extract the contents to\n",
        "extract_to_dir = '/content/train_images'\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(extract_to_dir, exist_ok=True)\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to_dir)\n",
        "\n",
        "# List the extracted files\n",
        "extracted_files = os.listdir(extract_to_dir)\n",
        "print(\"Files extracted to:\", extract_to_dir)\n",
        "print(\"Extracted files:\", extracted_files)\n",
        "\n",
        "\n",
        "\n",
        "# Path to the zip file in Google Drive\n",
        "zip_file_path = '/content/drive/My Drive/RMTC-08-04-24/test_images.zip'\n",
        "\n",
        "# Directory to extract the contents to\n",
        "extract_to_dir = '/content/test_images'\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(extract_to_dir, exist_ok=True)\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to_dir)\n",
        "\n",
        "# List the extracted files\n",
        "extracted_files = os.listdir(extract_to_dir)\n",
        "print(\"Files extracted to:\", extract_to_dir)\n",
        "print(\"Extracted files:\", extracted_files)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Path to the zip file in Google Drive\n",
        "zip_file_path = '/content/drive/My Drive/RMTC-08-04-24/val_images.zip'\n",
        "\n",
        "# Directory to extract the contents to\n",
        "extract_to_dir = '/content/val_images'\n",
        "\n",
        "# Create the directory if it doesn't exist\n",
        "os.makedirs(extract_to_dir, exist_ok=True)\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_to_dir)\n",
        "\n",
        "# List the extracted files\n",
        "extracted_files = os.listdir(extract_to_dir)\n",
        "print(\"Files extracted to:\", extract_to_dir)\n",
        "print(\"Extracted files:\", extracted_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmrbBUSVWEtx",
        "outputId": "b81a947c-c6ca-4b3b-c7bd-b9baa0c65601"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Files extracted to: /content/train_images\n",
            "Extracted files: ['train_images']\n",
            "Files extracted to: /content/test_images\n",
            "Extracted files: ['test_images']\n",
            "Files extracted to: /content/val_images\n",
            "Extracted files: ['val_images']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7RIpKxn1Towt",
        "outputId": "1f28812f-a529-44d7-f9e6-7a897a07ebd9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2169/2169 [00:02<00:00, 1059.14it/s]\n",
            "100%|██████████| 3565/3565 [00:03<00:00, 1037.66it/s]\n",
            "100%|██████████| 500/500 [00:00<00:00, 1021.89it/s]\n"
          ]
        }
      ],
      "source": [
        "X_Train_Images=[]\n",
        "X_Test_Images=[]\n",
        "for i in tqdm(range(test.shape[0])):\n",
        "    img=image.load_img('test_images/test_images/'+str(i)+'.jpg',target_size=(200,200,3))\n",
        "    img=image.img_to_array(img)\n",
        "    img=img/255\n",
        "    X_Test_Images.append(img)\n",
        "X_test_img=np.array(X_Test_Images)\n",
        "lst=[]\n",
        "for i in range(train.shape[0]):\n",
        "    img='train_images/train_images/'+str(i)+'.jpg'\n",
        "    lst.append(img)\n",
        "#print(lst)\n",
        "train['image']=lst\n",
        "lst=[]\n",
        "for i in range(test.shape[0]):\n",
        "    img='test_images/test_images/'+str(i)+'.jpg'\n",
        "    lst.append(img)\n",
        "#print(lst)\n",
        "test['image']=lst\n",
        "target_size = (200, 200)\n",
        "\n",
        "X_Train_Images = []  # List to store resized images\n",
        "\n",
        "# Load and preprocess the training set images\n",
        "for i in tqdm(range(train.shape[0])):\n",
        "    img = image.load_img('train_images/train_images/' + str(i) + '.jpg', target_size=(200,200,3))\n",
        "    img = image.img_to_array(img)\n",
        "    img = img / 255\n",
        "    X_Train_Images.append(img)\n",
        "\n",
        "# Convert the list of images to a NumPy array\n",
        "X_train_img = np.array(X_Train_Images)\n",
        "X_Val_Images=[]\n",
        "for i in tqdm(range(val.shape[0])):\n",
        "    img=image.load_img('val_images/val_images/'+str(i)+'.jpg',target_size=(200,200,3))\n",
        "    img=image.img_to_array(img)\n",
        "    img=img/255\n",
        "    X_Val_Images.append(img)\n",
        "X_val_img=np.array(X_Val_Images)\n",
        "lst=[]\n",
        "for i in range(val.shape[0]):\n",
        "    img='val_images/val_images/'+str(i)+'.jpg'\n",
        "    lst.append(img)\n",
        "#print(lst)\n",
        "val['image']=lst\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lKe8vgkqTowt"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Input, concatenate\n",
        "\n",
        "# Define your CNN model for image input\n",
        "def create_cnn_model():\n",
        "    cnn_input = Input(shape=(200, 200, 3))\n",
        "    cnn = Conv2D(32, (3, 3), activation='relu')(cnn_input)\n",
        "    # Add more CNN layers as needed\n",
        "    cnn = MaxPooling2D((2, 2))(cnn)\n",
        "    cnn = Flatten()(cnn)\n",
        "    cnn = Dense(128, activation='relu')(cnn)\n",
        "    cnn = Dropout(0.5)(cnn)\n",
        "    cnn = Dense(64, activation='relu')(cnn)\n",
        "    return Model(inputs=cnn_input, outputs=cnn)\n",
        "\n",
        "# Define your DBN model for text input\n",
        "def create_dbn_model(input_dim):\n",
        "    dbn_input = Input(shape=(input_dim,))\n",
        "    dbn = Dense(512, activation='relu')(dbn_input)\n",
        "    dbn = Dropout(0.5)(dbn)\n",
        "    dbn = Dense(256, activation='relu')(dbn)\n",
        "    return Model(inputs=dbn_input, outputs=dbn)\n",
        "\n",
        "# Combine both models\n",
        "def create_multi_modal_model(cnn_model, dbn_model,num_classes):\n",
        "    combined_input = concatenate([cnn_model.output, dbn_model.output])\n",
        "    combined = Dense(128, activation='relu')(combined_input)\n",
        "    combined = Dropout(0.5)(combined)\n",
        "    combined = Dense(64, activation='relu')(combined)\n",
        "    output = Dense(num_classes, activation='softmax')(combined)  # Adjust output layer based on the number of classes\n",
        "    return Model(inputs=[cnn_model.input, dbn_model.input], outputs=output)\n",
        "\n",
        "def cnn_dbn(num_classes,X_train_img,X_train_encoded,encoded_labels_train,wp,size,X_val_img,X_val_encoded,encoded_labels_val):\n",
        "    cnn_model = create_cnn_model()\n",
        "    cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    # Instantiate DBN model for text\n",
        "    input_dim_dbn = X_train_encoded.shape[1]\n",
        "    dbn_model = create_dbn_model(input_dim_dbn)\n",
        "    dbn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    multi_modal_model = create_multi_modal_model(cnn_model, dbn_model,num_classes)\n",
        "    multi_modal_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the multi-modal model using both image and text inputs\n",
        "    multi_modal_model.fit([X_train_img, X_train_encoded], encoded_labels_train, epochs=ep, batch_size=size, validation_data=([X_val_img, X_val_encoded], encoded_labels_val))\n",
        "    return multi_modal_model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t8aUvqQyYdSB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HjWbMX3TTowt",
        "outputId": "3eb428de-2db8-43ab-b8d7-3402aa149f9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/52\n",
            "238/238 [==============================] - 8s 26ms/step - loss: 1.9102 - accuracy: 0.5248 - val_loss: 0.7824 - val_accuracy: 0.8040\n",
            "Epoch 2/52\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 0.7639 - accuracy: 0.7792 - val_loss: 0.5447 - val_accuracy: 0.8440\n",
            "Epoch 3/52\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 0.5670 - accuracy: 0.8331 - val_loss: 0.4190 - val_accuracy: 0.8780\n",
            "Epoch 4/52\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 0.4803 - accuracy: 0.8583 - val_loss: 0.4111 - val_accuracy: 0.8900\n",
            "Epoch 5/52\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 0.4131 - accuracy: 0.8799 - val_loss: 0.3726 - val_accuracy: 0.9040\n",
            "Epoch 6/52\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 0.3665 - accuracy: 0.8940 - val_loss: 0.3840 - val_accuracy: 0.9000\n",
            "Epoch 7/52\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 0.3239 - accuracy: 0.9142 - val_loss: 0.4466 - val_accuracy: 0.8840\n",
            "Epoch 8/52\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 0.2947 - accuracy: 0.9195 - val_loss: 0.3586 - val_accuracy: 0.9060\n",
            "Epoch 9/52\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 0.2598 - accuracy: 0.9273 - val_loss: 0.3133 - val_accuracy: 0.9200\n",
            "Epoch 10/52\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 0.2487 - accuracy: 0.9296 - val_loss: 0.3493 - val_accuracy: 0.9120\n",
            "Epoch 11/52\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 0.2128 - accuracy: 0.9372 - val_loss: 0.3574 - val_accuracy: 0.8980\n",
            "Epoch 12/52\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 0.2220 - accuracy: 0.9352 - val_loss: 0.3284 - val_accuracy: 0.9120\n",
            "Epoch 13/52\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 0.1992 - accuracy: 0.9414 - val_loss: 0.3872 - val_accuracy: 0.9060\n",
            "Epoch 14/52\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 0.2119 - accuracy: 0.9405 - val_loss: 0.3479 - val_accuracy: 0.9160\n",
            "Epoch 15/52\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 0.1704 - accuracy: 0.9498 - val_loss: 0.3879 - val_accuracy: 0.9100\n",
            "Epoch 16/52\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 0.1636 - accuracy: 0.9518 - val_loss: 0.3988 - val_accuracy: 0.9080\n",
            "Epoch 17/52\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 0.1795 - accuracy: 0.9470 - val_loss: 0.3761 - val_accuracy: 0.9120\n",
            "Epoch 18/52\n",
            "238/238 [==============================] - 6s 23ms/step - loss: 0.1464 - accuracy: 0.9590 - val_loss: 0.3709 - val_accuracy: 0.9160\n",
            "Epoch 19/52\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 0.1279 - accuracy: 0.9604 - val_loss: 0.3907 - val_accuracy: 0.9140\n",
            "Epoch 20/52\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 0.1219 - accuracy: 0.9644 - val_loss: 0.4195 - val_accuracy: 0.9120\n",
            "Epoch 21/52\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 0.1388 - accuracy: 0.9619 - val_loss: 0.4191 - val_accuracy: 0.9120\n",
            "Epoch 22/52\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 0.1240 - accuracy: 0.9649 - val_loss: 0.3821 - val_accuracy: 0.9140\n",
            "Epoch 23/52\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 0.1334 - accuracy: 0.9599 - val_loss: 0.4338 - val_accuracy: 0.9020\n",
            "Epoch 24/52\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 0.1295 - accuracy: 0.9599 - val_loss: 0.3372 - val_accuracy: 0.9320\n",
            "Epoch 25/52\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 0.1150 - accuracy: 0.9666 - val_loss: 0.3618 - val_accuracy: 0.9220\n",
            "Epoch 26/52\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 0.0998 - accuracy: 0.9700 - val_loss: 0.3820 - val_accuracy: 0.9180\n",
            "Epoch 27/52\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 0.1219 - accuracy: 0.9638 - val_loss: 0.4337 - val_accuracy: 0.9160\n",
            "Epoch 28/52\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 0.0946 - accuracy: 0.9708 - val_loss: 0.4428 - val_accuracy: 0.9060\n",
            "Epoch 29/52\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 0.1292 - accuracy: 0.9666 - val_loss: 0.3971 - val_accuracy: 0.9060\n",
            "Epoch 30/52\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 0.1067 - accuracy: 0.9689 - val_loss: 0.4742 - val_accuracy: 0.9020\n",
            "Epoch 31/52\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 0.1248 - accuracy: 0.9641 - val_loss: 0.4487 - val_accuracy: 0.9080\n",
            "Epoch 32/52\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 0.1019 - accuracy: 0.9669 - val_loss: 0.4607 - val_accuracy: 0.9100\n",
            "Epoch 33/52\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 0.1275 - accuracy: 0.9635 - val_loss: 0.3660 - val_accuracy: 0.9200\n",
            "Epoch 34/52\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 0.0767 - accuracy: 0.9790 - val_loss: 0.4744 - val_accuracy: 0.9140\n",
            "Epoch 35/52\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 0.0784 - accuracy: 0.9790 - val_loss: 0.4597 - val_accuracy: 0.9120\n",
            "Epoch 36/52\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 0.0837 - accuracy: 0.9748 - val_loss: 0.4678 - val_accuracy: 0.9200\n",
            "Epoch 37/52\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 0.0735 - accuracy: 0.9762 - val_loss: 0.4128 - val_accuracy: 0.9260\n",
            "Epoch 38/52\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 0.1012 - accuracy: 0.9719 - val_loss: 0.4240 - val_accuracy: 0.9180\n",
            "Epoch 39/52\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 0.0877 - accuracy: 0.9773 - val_loss: 0.4192 - val_accuracy: 0.9260\n",
            "Epoch 40/52\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 0.0768 - accuracy: 0.9781 - val_loss: 0.4016 - val_accuracy: 0.9280\n",
            "Epoch 41/52\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 0.1033 - accuracy: 0.9700 - val_loss: 0.3990 - val_accuracy: 0.9060\n",
            "Epoch 42/52\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 0.0899 - accuracy: 0.9759 - val_loss: 0.3865 - val_accuracy: 0.9140\n",
            "Epoch 43/52\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 0.0790 - accuracy: 0.9764 - val_loss: 0.3984 - val_accuracy: 0.9160\n",
            "Epoch 44/52\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 0.0759 - accuracy: 0.9784 - val_loss: 0.4587 - val_accuracy: 0.9160\n",
            "Epoch 45/52\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 0.0665 - accuracy: 0.9812 - val_loss: 0.4172 - val_accuracy: 0.9240\n",
            "Epoch 46/52\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 0.0679 - accuracy: 0.9804 - val_loss: 0.3887 - val_accuracy: 0.9200\n",
            "Epoch 47/52\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 0.0819 - accuracy: 0.9773 - val_loss: 0.4107 - val_accuracy: 0.9280\n",
            "Epoch 48/52\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 0.0734 - accuracy: 0.9804 - val_loss: 0.4304 - val_accuracy: 0.9200\n",
            "Epoch 49/52\n",
            "238/238 [==============================] - 5s 22ms/step - loss: 0.0766 - accuracy: 0.9770 - val_loss: 0.4387 - val_accuracy: 0.9140\n",
            "Epoch 50/52\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 0.0887 - accuracy: 0.9742 - val_loss: 0.4849 - val_accuracy: 0.9100\n",
            "Epoch 51/52\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 0.1027 - accuracy: 0.9711 - val_loss: 0.3869 - val_accuracy: 0.9180\n",
            "Epoch 52/52\n",
            "238/238 [==============================] - 5s 23ms/step - loss: 0.0870 - accuracy: 0.9742 - val_loss: 0.4540 - val_accuracy: 0.9220\n",
            "68/68 [==============================] - 1s 11ms/step - loss: 0.4022 - accuracy: 0.9142\n",
            "Test Accuracy: 0.9142462015151978\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "\n",
        "# Instantiate CNN model for image\n",
        "cnn_model = create_cnn_model()\n",
        "cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Instantiate DBN model for text\n",
        "input_dim_dbn = X_train_encoded.shape[1]\n",
        "num_classes = 11# Set the input dimensions based on the DBN input shape\n",
        "dbn_model = create_dbn_model(input_dim_dbn)\n",
        "dbn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Instantiate combined multi-modal model\n",
        "multi_modal_model = create_multi_modal_model(cnn_model, dbn_model,num_classes)\n",
        "multi_modal_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the multi-modal model using both image and text inputs\n",
        "multi_modal_model.fit([X_train_img, X_train_encoded], encoded_labels_train, epochs=52, batch_size=15, validation_data=([X_val_img, X_val_encoded], encoded_labels_val))\n",
        "\n",
        "# Evaluate the multi-modal model\n",
        "loss, accuracy = multi_modal_model.evaluate([X_test_img, X_test_encoded], encoded_labels_test)\n",
        "print(f'Test Accuracy: {accuracy}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = multi_modal_model.predict([X_test_img, X_test_encoded])\n",
        "from sklearn.metrics import precision_score, recall_score,f1_score\n",
        "# Calculate precision\n",
        "# Convert predictions to multilabel-indicator format\n",
        "predicted_labels_multilabel = np.eye(num_classes)[predictions.argmax(axis=1)]\n",
        "\n",
        "# Now you can calculate precision using the multilabel-indicator format\n",
        "test_precision = precision_score(encoded_labels_test, predicted_labels_multilabel, average='weighted')\n",
        "print(f'Test Precision: {test_precision}')\n",
        "# Calculate recall\n",
        "test_recall = recall_score(encoded_labels_test,predicted_labels_multilabel, average='weighted')\n",
        "\n",
        "print(f'Test Recall: {test_recall}')\n",
        "# Calculate F1-score\n",
        "test_f1_score = f1_score(encoded_labels_test,predicted_labels_multilabel, average='weighted')\n",
        "print(f'Test F1-score: {test_f1_score}')\n",
        "predicted_class_indices = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Convert class indices back to original labels using inverse_transform of label_encoder\n",
        "predicted_labels = label_encoder.inverse_transform(predicted_class_indices)\n",
        "\n",
        "# Display predicted labels\n",
        "test['pcategories__2']=predicted_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fls8aA_0j3zP",
        "outputId": "9d1d9f2d-7673-4c8d-9cf9-d618791ce7c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "68/68 [==============================] - 1s 9ms/step\n",
            "Test Precision: 0.919090393072512\n",
            "Test Recall: 0.921161825726141\n",
            "Test F1-score: 0.9195958039419695\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NpkxHKUTowt",
        "outputId": "826bf007-e2dc-4043-d0a7-09394472b01c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "68/68 [==============================] - 1s 10ms/step\n",
            "Test Precision: 0.9133682760259961\n",
            "Test Recall: 0.9151682803135085\n",
            "Test F1-score: 0.9136892544973451\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "predictions = multi_modal_model.predict([X_test_img, X_test_encoded])\n",
        "from sklearn.metrics import precision_score, recall_score,f1_score\n",
        "# Calculate precision\n",
        "# Convert predictions to multilabel-indicator format\n",
        "predicted_labels_multilabel = np.eye(num_classes)[predictions.argmax(axis=1)]\n",
        "\n",
        "# Now you can calculate precision using the multilabel-indicator format\n",
        "test_precision = precision_score(encoded_labels_test, predicted_labels_multilabel, average='weighted')\n",
        "print(f'Test Precision: {test_precision}')\n",
        "# Calculate recall\n",
        "test_recall = recall_score(encoded_labels_test,predicted_labels_multilabel, average='weighted')\n",
        "\n",
        "print(f'Test Recall: {test_recall}')\n",
        "# Calculate F1-score\n",
        "test_f1_score = f1_score(encoded_labels_test,predicted_labels_multilabel, average='weighted')\n",
        "print(f'Test F1-score: {test_f1_score}')\n",
        "predicted_class_indices = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Convert class indices back to original labels using inverse_transform of label_encoder\n",
        "predicted_labels = label_encoder.inverse_transform(predicted_class_indices)\n",
        "\n",
        "# Display predicted labels\n",
        "test['pcategories__2']=predicted_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ocM7rWyDTowt",
        "outputId": "8d4d1fef-333c-4c22-ef3e-288a59f58266"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1292"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score\n",
        "# Create confusion matrix\n",
        "y_text_test = test['categories__2'].str.lower()\n",
        "predictions_dbncnn =test['pcategories__2']\n",
        "# Calculate accuracy\n",
        "accuracy = (y_text_test == predictions_dbncnn).mean()\n",
        "print(\"Accuracy:\", accuracy)\n",
        "conf_matrix = confusion_matrix(y_text_test, predictions_dbncnn)\n",
        "\n",
        "# Plot heatmap for confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False)\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()\n",
        "\n",
        "# Plot heatmap for precision, recall, and F1 score\n",
        "data = [[precision, recall, f1]]\n",
        "metrics = ['Precision', 'Recall', 'F1 Score']\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.heatmap(data, annot=True, fmt=\".2f\", cmap=\"YlGnBu\", xticklabels=metrics, yticklabels=False, cbar=False)\n",
        "plt.title('Precision, Recall, and F1 Score')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        },
        "id": "ASJCYDeCoMaG",
        "outputId": "0493c609-5431-44d8-bc09-6944ba8d5748"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.921161825726141\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'precision' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-81d6f101cde7>\u001b[0m in \u001b[0;36m<cell line: 21>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Plot heatmap for precision, recall, and F1 score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'Precision'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Recall'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'F1 Score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'precision' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2024vGETowt"
      },
      "outputs": [],
      "source": [
        "file_path = 'predictionsnew_92_1.csv'\n",
        "\n",
        "# Save the modified 'test' DataFrame to a CSV file without the DataFrame index\n",
        "test.to_csv(file_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cQintlHTowt"
      },
      "outputs": [],
      "source": [
        "\n",
        "test=pd.read_csv(r'predictionsfirstlevel.csv')\n",
        "test=test.replace(np.nan, '',regex=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YRzoq8pVTowt"
      },
      "outputs": [],
      "source": [
        "\n",
        "leafnode=leafnode_extraction(train)\n",
        "leafnode=[x.lower() for x in leafnode]\n",
        "testleafnode=leafnode_extraction(test)\n",
        "testleafnode=[x.lower() for x in testleafnode]\n",
        "leafnodeval=leafnode_extraction(val)\n",
        "leafnodeval=[x.lower() for x in leafnodeval]\n",
        "train['leaf']=leafnode\n",
        "test['leaf']=testleafnode\n",
        "val['leaf']=leafnodeval\n",
        "test.head()\n",
        "\n",
        "# to train leafnode prediction\n",
        "# extraction of train samples of particular level1 category\n",
        "\n",
        "inp1=train.loc[train['categories__2']=='Computers & Accessories']\n",
        "inp2=train.loc[train['categories__2']=='Accessories & Supplies']\n",
        "inp3=train.loc[train['categories__2']=='GPS & Navigation']\n",
        "inp4=train.loc[train['categories__2']=='eBook Readers & Accessories']\n",
        "inp5=train.loc[train['categories__2']=='Car & Vehicle Electronics']\n",
        "inp6=train.loc[train['categories__2']=='Camera & Photo']\n",
        "inp7=train.loc[train['categories__2']=='Portable Audio & Video']\n",
        "inp8=train.loc[train['categories__2']=='Cell Phones & Accessories']\n",
        "inp9=train.loc[train['categories__2']=='Television & Video']\n",
        "inp10=train.loc[train['categories__2']=='Home Audio']\n",
        "inp11=train.loc[train['categories__2']=='Security & Surveillance']\n",
        "\n",
        "\n",
        "val1=val.loc[train['categories__2']=='Computers & Accessories']\n",
        "val2=val.loc[train['categories__2']=='Accessories & Supplies']\n",
        "val3=val.loc[train['categories__2']=='GPS & Navigation']\n",
        "val4=val.loc[train['categories__2']=='eBook Readers & Accessories']\n",
        "val5=val.loc[train['categories__2']=='Car & Vehicle Electronics']\n",
        "val6=val.loc[train['categories__2']=='Camera & Photo']\n",
        "val7=val.loc[train['categories__2']=='Portable Audio & Video']\n",
        "val8=val.loc[train['categories__2']=='Cell Phones & Accessories']\n",
        "val9=val.loc[train['categories__2']=='Television & Video']\n",
        "val10=val.loc[train['categories__2']=='Home Audio']\n",
        "val11=val.loc[train['categories__2']=='Security & Surveillance']\n",
        "\n",
        "#test\n",
        "testinp1=test.loc[test['pcategories__2']=='computers & accessories']\n",
        "testinp2=test.loc[test['pcategories__2']=='accessories & supplies']\n",
        "testinp3=test.loc[test['pcategories__2']=='gps & navigation']\n",
        "testinp4=test.loc[test['pcategories__2']=='ebook readers & accessories']\n",
        "testinp5=test.loc[test['pcategories__2']=='car & vehicle electronics']\n",
        "testinp6=test.loc[test['pcategories__2']=='camera & photo']\n",
        "testinp7=test.loc[test['pcategories__2']=='portable audio & video']\n",
        "testinp8=test.loc[test['pcategories__2']=='cell phones & accessories']\n",
        "testinp9=test.loc[test['pcategories__2']=='television & video']\n",
        "testinp10=test.loc[test['pcategories__2']=='home audio']\n",
        "testinp11=test.loc[test['pcategories__2']=='security & surveillance']\n",
        "#//////////////////////////////////////////"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwlL8F-xTowt",
        "outputId": "65cdda85-cb9f-4fd6-9028-ef142a443e80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2169"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "len(testinp1)+len(testinp2)+len(testinp3)+len(testinp4)+len(testinp5)+len(testinp6)+len(testinp7)+len(testinp8)+len(testinp9)+len(testinp10)+len(testinp11)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a_Z3seokTowu"
      },
      "outputs": [],
      "source": [
        "def encode_labels(train_labels, test_labels, val_labels):\n",
        "    # Combine labels from train, test, and validation sets\n",
        "    all_labels = np.concatenate((train_labels, test_labels, val_labels), axis=0)\n",
        "\n",
        "    # Initialize and fit the label encoder\n",
        "    label_encoder = LabelEncoder()\n",
        "    label_encoder.fit(all_labels)\n",
        "    encoded_labels_train = label_encoder.transform(train_labels)\n",
        "    encoded_labels_train = to_categorical(encoded_labels_train, num_classes=len(label_encoder.classes_))\n",
        "\n",
        "    encoded_labels_test = label_encoder.transform(test_labels)\n",
        "    encoded_labels_test = to_categorical(encoded_labels_test, num_classes=len(label_encoder.classes_))\n",
        "    encoded_val_labels = label_encoder.transform(val_labels)\n",
        "    encoded_val_labels = to_categorical(encoded_val_labels, num_classes=len(label_encoder.classes_))\n",
        "    return encoded_labels_train, encoded_labels_test, encoded_val_labels, label_encoder\n",
        "\n",
        "def Load_images(inp):\n",
        "    X_Images=[]\n",
        "    for i in list(inp['image']):\n",
        "        img=image.load_img(i,target_size=(200,200,3))\n",
        "        img=image.img_to_array(img)\n",
        "        img=img/255\n",
        "        X_Images.append(img)\n",
        "    x_images=np.array(X_Images)\n",
        "    return x_images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TAGw0_qCTowu"
      },
      "outputs": [],
      "source": [
        "# Combine both models\n",
        "def create_multi_modal_model(cnn_model, dbn_model,num_classes):\n",
        "    combined_input = concatenate([cnn_model.output, dbn_model.output])\n",
        "    combined = Dense(128, activation='relu')(combined_input)\n",
        "    combined = Dropout(0.5)(combined)\n",
        "    combined = Dense(64, activation='relu')(combined)\n",
        "    output = Dense(num_classes, activation='softmax')(combined)  # Adjust output layer based on the number of classes\n",
        "    return Model(inputs=[cnn_model.input, dbn_model.input], outputs=output)\n",
        "\n",
        "def cnn_dbn(num_classes,X_train_img,X_train_encoded,encoded_labels_train,wp,size,X_val_img,X_val_encoded,encoded_labels_val):\n",
        "    cnn_model = create_cnn_model()\n",
        "    cnn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    # Instantiate DBN model for text\n",
        "    input_dim_dbn = X_train_encoded.shape[1]\n",
        "    dbn_model = create_dbn_model(input_dim_dbn)\n",
        "    dbn_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    multi_modal_model = create_multi_modal_model(cnn_model, dbn_model,num_classes)\n",
        "    multi_modal_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # Train the multi-modal model using both image and text inputs\n",
        "    multi_modal_model.fit([X_train_img, X_train_encoded], encoded_labels_train, epochs=ep, batch_size=size, validation_data=([X_val_img, X_val_encoded], encoded_labels_val))\n",
        "    return multi_modal_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNGXrUjaTowu",
        "outputId": "cbd6238f-c406-4b0c-fd82-ca6c4dd1737d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 590
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                               title  \\\n",
              "0  Panasonic SC-AK29 Compact Stereo System (Disco...   \n",
              "1  JVC MXJ200 Compact Stereo System (Discontinued...   \n",
              "2        Sennheiser  RS4-9 On-Ear Wireless Headphone   \n",
              "3  Pioneer VSX-D309 Audio/Video Receiver (Discont...   \n",
              "4  Pioneer VSX-108 Audio/Video Receiver (Disconti...   \n",
              "\n",
              "                                         description  \\\n",
              "0  Equipped with a five-CD changer, Panasonic's S...   \n",
              "1  JVC's MX-J200 compact stereo may be small, but...   \n",
              "2  Sennheiser's RS4-9 wireless headphones consist...   \n",
              "3  With built-in Dolby Digital, DTS, and Dolby Pr...   \n",
              "4  With 50 watts per channel and surround conveni...   \n",
              "\n",
              "                                               imUrl  price brand  \\\n",
              "0  http://ecx.images-amazon.com/images/I/41QGRQSQ...  134.5         \n",
              "1  http://ecx.images-amazon.com/images/I/41W6F65V...  134.5         \n",
              "2  http://g-ecx.images-amazon.com/images/G/01/x-s...  134.5         \n",
              "3  http://ecx.images-amazon.com/images/I/41JTX248...  134.5         \n",
              "4  http://ecx.images-amazon.com/images/I/41AJK34P...  134.5         \n",
              "\n",
              "  categories__1           categories__2              categories__3  \\\n",
              "0   Electronics              Home Audio            Compact Stereos   \n",
              "1   Electronics              Home Audio            Compact Stereos   \n",
              "2   Electronics  Accessories & Supplies  Audio & Video Accessories   \n",
              "3   Electronics              Home Audio          Stereo Components   \n",
              "4   Electronics              Home Audio          Stereo Components   \n",
              "\n",
              "            categories__4        categories__5 categories__6  \\\n",
              "0                                                              \n",
              "1                                                              \n",
              "2              Headphones                                      \n",
              "3  Receivers & Amplifiers  Component Receivers                 \n",
              "4  Receivers & Amplifiers  Component Receivers                 \n",
              "\n",
              "                                     lemmatized_text  \\\n",
              "0  ['panasonic', 'compact', 'stereo', 'system', '...   \n",
              "1  ['jvc', 'compact', 'stereo', 'system', 'discon...   \n",
              "2  ['sennheiser', 'wireless', 'headphone', 'sennh...   \n",
              "3  ['pioneer', 'receiver', 'discontinued', 'manuf...   \n",
              "4  ['pioneer', 'receiver', 'discontinued', 'manuf...   \n",
              "\n",
              "                             final_lemmatized_string  \\\n",
              "0   panasonic compact stereo system discontinued ...   \n",
              "1   jvc compact stereo system discontinued manufa...   \n",
              "2   sennheiser wireless headphone sennheiser wire...   \n",
              "3   pioneer receiver discontinued manufacturer do...   \n",
              "4   pioneer receiver discontinued manufacturer wa...   \n",
              "\n",
              "                           image          pcategories__2                 leaf  \n",
              "0  test_images/test_images/0.jpg              home audio      compact stereos  \n",
              "1  test_images/test_images/1.jpg              home audio      compact stereos  \n",
              "2  test_images/test_images/2.jpg  accessories & supplies           headphones  \n",
              "3  test_images/test_images/3.jpg              home audio  component receivers  \n",
              "4  test_images/test_images/4.jpg              home audio  component receivers  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b74f3853-c075-4ce7-8935-e4a2cac668c2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>description</th>\n",
              "      <th>imUrl</th>\n",
              "      <th>price</th>\n",
              "      <th>brand</th>\n",
              "      <th>categories__1</th>\n",
              "      <th>categories__2</th>\n",
              "      <th>categories__3</th>\n",
              "      <th>categories__4</th>\n",
              "      <th>categories__5</th>\n",
              "      <th>categories__6</th>\n",
              "      <th>lemmatized_text</th>\n",
              "      <th>final_lemmatized_string</th>\n",
              "      <th>image</th>\n",
              "      <th>pcategories__2</th>\n",
              "      <th>leaf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Panasonic SC-AK29 Compact Stereo System (Disco...</td>\n",
              "      <td>Equipped with a five-CD changer, Panasonic's S...</td>\n",
              "      <td>http://ecx.images-amazon.com/images/I/41QGRQSQ...</td>\n",
              "      <td>134.5</td>\n",
              "      <td></td>\n",
              "      <td>Electronics</td>\n",
              "      <td>Home Audio</td>\n",
              "      <td>Compact Stereos</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>['panasonic', 'compact', 'stereo', 'system', '...</td>\n",
              "      <td>panasonic compact stereo system discontinued ...</td>\n",
              "      <td>test_images/test_images/0.jpg</td>\n",
              "      <td>home audio</td>\n",
              "      <td>compact stereos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>JVC MXJ200 Compact Stereo System (Discontinued...</td>\n",
              "      <td>JVC's MX-J200 compact stereo may be small, but...</td>\n",
              "      <td>http://ecx.images-amazon.com/images/I/41W6F65V...</td>\n",
              "      <td>134.5</td>\n",
              "      <td></td>\n",
              "      <td>Electronics</td>\n",
              "      <td>Home Audio</td>\n",
              "      <td>Compact Stereos</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>['jvc', 'compact', 'stereo', 'system', 'discon...</td>\n",
              "      <td>jvc compact stereo system discontinued manufa...</td>\n",
              "      <td>test_images/test_images/1.jpg</td>\n",
              "      <td>home audio</td>\n",
              "      <td>compact stereos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sennheiser  RS4-9 On-Ear Wireless Headphone</td>\n",
              "      <td>Sennheiser's RS4-9 wireless headphones consist...</td>\n",
              "      <td>http://g-ecx.images-amazon.com/images/G/01/x-s...</td>\n",
              "      <td>134.5</td>\n",
              "      <td></td>\n",
              "      <td>Electronics</td>\n",
              "      <td>Accessories &amp; Supplies</td>\n",
              "      <td>Audio &amp; Video Accessories</td>\n",
              "      <td>Headphones</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>['sennheiser', 'wireless', 'headphone', 'sennh...</td>\n",
              "      <td>sennheiser wireless headphone sennheiser wire...</td>\n",
              "      <td>test_images/test_images/2.jpg</td>\n",
              "      <td>accessories &amp; supplies</td>\n",
              "      <td>headphones</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Pioneer VSX-D309 Audio/Video Receiver (Discont...</td>\n",
              "      <td>With built-in Dolby Digital, DTS, and Dolby Pr...</td>\n",
              "      <td>http://ecx.images-amazon.com/images/I/41JTX248...</td>\n",
              "      <td>134.5</td>\n",
              "      <td></td>\n",
              "      <td>Electronics</td>\n",
              "      <td>Home Audio</td>\n",
              "      <td>Stereo Components</td>\n",
              "      <td>Receivers &amp; Amplifiers</td>\n",
              "      <td>Component Receivers</td>\n",
              "      <td></td>\n",
              "      <td>['pioneer', 'receiver', 'discontinued', 'manuf...</td>\n",
              "      <td>pioneer receiver discontinued manufacturer do...</td>\n",
              "      <td>test_images/test_images/3.jpg</td>\n",
              "      <td>home audio</td>\n",
              "      <td>component receivers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Pioneer VSX-108 Audio/Video Receiver (Disconti...</td>\n",
              "      <td>With 50 watts per channel and surround conveni...</td>\n",
              "      <td>http://ecx.images-amazon.com/images/I/41AJK34P...</td>\n",
              "      <td>134.5</td>\n",
              "      <td></td>\n",
              "      <td>Electronics</td>\n",
              "      <td>Home Audio</td>\n",
              "      <td>Stereo Components</td>\n",
              "      <td>Receivers &amp; Amplifiers</td>\n",
              "      <td>Component Receivers</td>\n",
              "      <td></td>\n",
              "      <td>['pioneer', 'receiver', 'discontinued', 'manuf...</td>\n",
              "      <td>pioneer receiver discontinued manufacturer wa...</td>\n",
              "      <td>test_images/test_images/4.jpg</td>\n",
              "      <td>home audio</td>\n",
              "      <td>component receivers</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b74f3853-c075-4ce7-8935-e4a2cac668c2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-b74f3853-c075-4ce7-8935-e4a2cac668c2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-b74f3853-c075-4ce7-8935-e4a2cac668c2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f3396e75-5a3b-496b-9709-80409032c9d8\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f3396e75-5a3b-496b-9709-80409032c9d8')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f3396e75-5a3b-496b-9709-80409032c9d8 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test",
              "summary": "{\n  \"name\": \"test\",\n  \"rows\": 2169,\n  \"fields\": [\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2166,\n        \"samples\": [\n          \"FELLOWES 99841 Internet Glidepoint Touchpad\",\n          \"GeoDiscovery Geode GPS Springboard Module For Handspring Visor\",\n          \"Microtech 1M USB To SCSI Converter DB25F/USB 1.2MB/S 7 Device/ 1 USB\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1726,\n        \"samples\": [\n          \"The VTech VTalk 1311 FRS radio offers the important features you need,  but not the costlier features you don't, in a compact, fun package at a great- value price. With 14 channels and 38 subcodes, the 1311 offers a total of 532  frequencies to choose from. It also provides auto channel scan to find a clear  channel for you, channel monitor, and channel lock. It's the easy way to enjoy  two-way radio communications over a two-mile range.Additional features of the 1311 include an easy-to-read backlit LCD, microphone  jack, headset jack, and belt clip. The 1311 uses three ordinary AAA batteries  (included), and its auto power-off feature extends their life, so you can use  your radio all day.The colorful translucent casing is both fun and durable, and its compact size  lets you easily tuck the radio away in your pocket.\",\n          \"Designed for the corporate professional who depends on outstanding image performance coupled with the convenience of onscreen digital controls, the Sony CPD-E210 17-inch CRT (cathode-ray tube) monitor provides the superior color quality well suited for both high-end graphics and general use. With a virtually flat, high-resolution FD Trinitron CRT display, the CPD-E210's 17-inch (16-inch visible) screen is nearly unmatched in image quality and glare reduction.Brilliant color and dazzling clarity are two key benefits to the CPD-E210 package. Making use of the latest digital multiscan technology, the monitor supports resolutions up to an impressive 1,600 x 1,200 (maximum) with a refresh rate of 60 Hz. The CPD-E210's virtually flat, high-resolution display also incorporates a variable 0.24-0.25mm aperture grille pitch, allowing everything from the simplest images to the most complex graphics help retain their vibrancy.Allowing users to quickly and effortlessly utilize the CPD-E210's numerous options, all Sony CPD-E series monitors come equipped with the DisplayMouse onscreen menu control. The Sony DisplayMouse simplifies the setup of this premier SOHO (small office and home office) display and makes any troubleshooting needs a painless process.All Sony CPD-E series monitors include a high-contrast black screen coating.  Along with greatly reducing glare and image distortion, this resilient coating produces an exceptional range of tonal shades, from pitch black to resplendent white.The Sony CPD-E210 17-inch CRT monitor is Windows designed and Macintosh compatible. The monitor is backed by a three-year limited warranty.\",\n          \"Digital cameras and MP3 players utilize the same types of memory cards.  Fuji took advantage of that fact when they created the FinePix 40i, which  combines an MP3 player with a high-resolution digital camera. The camera uses a  2.4-megapixel Fuji Super CCD to capture images at an interpolated resolution of  2,400 x 1,600. Other possible resolutions include 1,280 x 960 and 640 x 480. The  FinePix 40i is also capable of recording AVI movies at a resolution of 320 x 240  at 10 frames per second, for up to 80 seconds.SmartMedia cards are used for storing both images and MP3 files, and the USB  port provides quick upload and download speeds for both images and audio. One  note: for copyright management reasons, all songs must be transferred to the  unit via the USB cable; a card recorded on a computer-based card reader or on a  friend's MP3 player can't be played on this unit. A tethered remote holds all  the controls for the audio player, and provides a headphone jack for the  included headphones. The video-out lets you preview images on a television. The  40i also comes with rechargeable NiMH batteries, image-editing software, and  digital audio software.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"imUrl\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2066,\n        \"samples\": [\n          \"http://ecx.images-amazon.com/images/I/21P13XQA7CL.jpg\",\n          \"http://ecx.images-amazon.com/images/I/31xLHHN5LML._SX300_.jpg\",\n          \"http://ecx.images-amazon.com/images/I/41ZC207CWFL._SX300_.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"price\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 68.15918015207615,\n        \"min\": 0.01,\n        \"max\": 679.99,\n        \"num_unique_values\": 739,\n        \"samples\": [\n          101.19,\n          141.0,\n          8.22\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"brand\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 102,\n        \"samples\": [\n          \"Konica-Minolta\",\n          \"IBM\",\n          \"Creative Labs\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"categories__1\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Electronics\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"categories__2\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 11,\n        \"samples\": [\n          \"Computers & Accessories\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"categories__3\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 60,\n        \"samples\": [\n          \"Compact Stereos\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"categories__4\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 128,\n        \"samples\": [\n          \"Camera Cases\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"categories__5\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 100,\n        \"samples\": [\n          \"Car Stereo Receivers\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"categories__6\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 20,\n        \"samples\": [\n          \"\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lemmatized_text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2094,\n        \"samples\": [\n          \"['tripp', 'lite', 'svga', 'vga', 'monitor', 'extension', 'cable', 'rgb', 'coax', 'gold']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"final_lemmatized_string\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2094,\n        \"samples\": [\n          \" tripp lite svga vga monitor extension cable rgb coax gold\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"image\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 2169,\n        \"samples\": [\n          \"test_images/test_images/2001.jpg\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pcategories__2\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"car & vehicle electronics\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"leaf\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 220,\n        \"samples\": [\n          \"surge protectors\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "test.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hhytGihkTowu",
        "outputId": "64e5e609-a988-4d3e-9b90-d839dd68c6e8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Result of Computers & Accessories:\n",
            "(1454, 5000)\n",
            "(845, 5000)\n",
            "Epoch 1/50\n",
            "291/291 [==============================] - 2s 4ms/step - loss: 0.1051 - val_loss: 0.0094\n",
            "Epoch 2/50\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0071 - val_loss: 0.0083\n",
            "Epoch 3/50\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0065 - val_loss: 0.0080\n",
            "Epoch 4/50\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0062 - val_loss: 0.0077\n",
            "Epoch 5/50\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0060 - val_loss: 0.0075\n",
            "Epoch 6/50\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0058 - val_loss: 0.0074\n",
            "Epoch 7/50\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0057 - val_loss: 0.0072\n",
            "Epoch 8/50\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0056 - val_loss: 0.0071\n",
            "Epoch 9/50\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0055 - val_loss: 0.0070\n",
            "Epoch 10/50\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0054 - val_loss: 0.0070\n",
            "Epoch 11/50\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0053 - val_loss: 0.0070\n",
            "Epoch 12/50\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0052 - val_loss: 0.0068\n",
            "Epoch 13/50\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0051 - val_loss: 0.0068\n",
            "Epoch 14/50\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0050 - val_loss: 0.0068\n",
            "Epoch 15/50\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0049 - val_loss: 0.0068\n",
            "Epoch 16/50\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0048 - val_loss: 0.0066\n",
            "Epoch 17/50\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0046 - val_loss: 0.0065\n",
            "Epoch 18/50\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0045 - val_loss: 0.0064\n",
            "Epoch 19/50\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0044 - val_loss: 0.0063\n",
            "Epoch 20/50\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0043 - val_loss: 0.0062\n",
            "Epoch 21/50\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0041 - val_loss: 0.0062\n",
            "Epoch 22/50\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0040 - val_loss: 0.0060\n",
            "Epoch 23/50\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0039 - val_loss: 0.0060\n",
            "Epoch 24/50\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0038 - val_loss: 0.0059\n",
            "Epoch 25/50\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0037 - val_loss: 0.0059\n",
            "Epoch 26/50\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0036 - val_loss: 0.0058\n",
            "Epoch 27/50\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0035 - val_loss: 0.0057\n",
            "Epoch 28/50\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0034 - val_loss: 0.0056\n",
            "Epoch 29/50\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0034 - val_loss: 0.0056\n",
            "Epoch 30/50\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0033 - val_loss: 0.0056\n",
            "Epoch 31/50\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0032 - val_loss: 0.0055\n",
            "Epoch 32/50\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0032 - val_loss: 0.0055\n",
            "Epoch 33/50\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0031 - val_loss: 0.0054\n",
            "Epoch 34/50\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0031 - val_loss: 0.0054\n",
            "Epoch 35/50\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0031 - val_loss: 0.0054\n",
            "Epoch 36/50\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0030 - val_loss: 0.0053\n",
            "Epoch 37/50\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0030 - val_loss: 0.0053\n",
            "Epoch 38/50\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0030 - val_loss: 0.0053\n",
            "Epoch 39/50\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0030 - val_loss: 0.0053\n",
            "Epoch 40/50\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0029 - val_loss: 0.0052\n",
            "Epoch 41/50\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0029 - val_loss: 0.0052\n",
            "Epoch 42/50\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0029 - val_loss: 0.0052\n",
            "Epoch 43/50\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0029 - val_loss: 0.0053\n",
            "Epoch 44/50\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0029 - val_loss: 0.0052\n",
            "Epoch 45/50\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0029 - val_loss: 0.0052\n",
            "Epoch 46/50\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0029 - val_loss: 0.0052\n",
            "Epoch 47/50\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0029 - val_loss: 0.0052\n",
            "Epoch 48/50\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0028 - val_loss: 0.0052\n",
            "Epoch 49/50\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0028 - val_loss: 0.0052\n",
            "Epoch 50/50\n",
            "291/291 [==============================] - 1s 4ms/step - loss: 0.0028 - val_loss: 0.0052\n",
            "46/46 [==============================] - 0s 1ms/step\n",
            "27/27 [==============================] - 0s 1ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "Epoch 1/50\n",
            "291/291 [==============================] - 11s 20ms/step - loss: 3.8378 - accuracy: 0.2166 - val_loss: 5.0036 - val_accuracy: 0.0966\n",
            "Epoch 2/50\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 2.9170 - accuracy: 0.3246 - val_loss: 6.1494 - val_accuracy: 0.1063\n",
            "Epoch 3/50\n",
            "291/291 [==============================] - 5s 19ms/step - loss: 2.6136 - accuracy: 0.3790 - val_loss: 6.6849 - val_accuracy: 0.1449\n",
            "Epoch 4/50\n",
            "291/291 [==============================] - 5s 19ms/step - loss: 2.3404 - accuracy: 0.4168 - val_loss: 6.8360 - val_accuracy: 0.1691\n",
            "Epoch 5/50\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 2.1144 - accuracy: 0.4395 - val_loss: 7.7991 - val_accuracy: 0.1594\n",
            "Epoch 6/50\n",
            "291/291 [==============================] - 5s 19ms/step - loss: 1.9122 - accuracy: 0.4835 - val_loss: 9.2640 - val_accuracy: 0.1932\n",
            "Epoch 7/50\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 1.7585 - accuracy: 0.5165 - val_loss: 9.6685 - val_accuracy: 0.1932\n",
            "Epoch 8/50\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 1.6186 - accuracy: 0.5406 - val_loss: 10.0880 - val_accuracy: 0.2174\n",
            "Epoch 9/50\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 1.5203 - accuracy: 0.5530 - val_loss: 9.9365 - val_accuracy: 0.2077\n",
            "Epoch 10/50\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 1.3763 - accuracy: 0.5791 - val_loss: 11.3938 - val_accuracy: 0.2126\n",
            "Epoch 11/50\n",
            "291/291 [==============================] - 5s 19ms/step - loss: 1.3727 - accuracy: 0.5942 - val_loss: 10.2932 - val_accuracy: 0.2464\n",
            "Epoch 12/50\n",
            "291/291 [==============================] - 5s 19ms/step - loss: 1.1950 - accuracy: 0.6279 - val_loss: 13.1599 - val_accuracy: 0.2415\n",
            "Epoch 13/50\n",
            "291/291 [==============================] - 5s 19ms/step - loss: 1.2318 - accuracy: 0.6190 - val_loss: 12.9920 - val_accuracy: 0.2464\n",
            "Epoch 14/50\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 1.1107 - accuracy: 0.6437 - val_loss: 12.6153 - val_accuracy: 0.2609\n",
            "Epoch 15/50\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 1.0808 - accuracy: 0.6713 - val_loss: 12.4515 - val_accuracy: 0.2271\n",
            "Epoch 16/50\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 0.9954 - accuracy: 0.6829 - val_loss: 12.8986 - val_accuracy: 0.2657\n",
            "Epoch 17/50\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 0.9940 - accuracy: 0.6905 - val_loss: 13.6629 - val_accuracy: 0.2415\n",
            "Epoch 18/50\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 0.9568 - accuracy: 0.7022 - val_loss: 13.1276 - val_accuracy: 0.2560\n",
            "Epoch 19/50\n",
            "291/291 [==============================] - 5s 19ms/step - loss: 0.9457 - accuracy: 0.7043 - val_loss: 12.5188 - val_accuracy: 0.2657\n",
            "Epoch 20/50\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 0.9059 - accuracy: 0.7125 - val_loss: 12.5216 - val_accuracy: 0.2705\n",
            "Epoch 21/50\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 0.8241 - accuracy: 0.7345 - val_loss: 15.6124 - val_accuracy: 0.2609\n",
            "Epoch 22/50\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 0.8260 - accuracy: 0.7283 - val_loss: 14.7898 - val_accuracy: 0.2705\n",
            "Epoch 23/50\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 0.7940 - accuracy: 0.7483 - val_loss: 16.8715 - val_accuracy: 0.2754\n",
            "Epoch 24/50\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 0.7779 - accuracy: 0.7421 - val_loss: 14.8152 - val_accuracy: 0.2850\n",
            "Epoch 25/50\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 0.7676 - accuracy: 0.7462 - val_loss: 15.1997 - val_accuracy: 0.2802\n",
            "Epoch 26/50\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 0.7363 - accuracy: 0.7758 - val_loss: 14.0362 - val_accuracy: 0.2512\n",
            "Epoch 27/50\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 0.7010 - accuracy: 0.7806 - val_loss: 15.9157 - val_accuracy: 0.2947\n",
            "Epoch 28/50\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 0.6888 - accuracy: 0.7772 - val_loss: 17.2617 - val_accuracy: 0.2850\n",
            "Epoch 29/50\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 0.7083 - accuracy: 0.7861 - val_loss: 16.2005 - val_accuracy: 0.2947\n",
            "Epoch 30/50\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 0.6828 - accuracy: 0.7827 - val_loss: 15.9302 - val_accuracy: 0.2754\n",
            "Epoch 31/50\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 0.6765 - accuracy: 0.7765 - val_loss: 15.1843 - val_accuracy: 0.2754\n",
            "Epoch 32/50\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 0.6388 - accuracy: 0.7889 - val_loss: 14.6725 - val_accuracy: 0.2754\n",
            "Epoch 33/50\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 0.5890 - accuracy: 0.7999 - val_loss: 14.7070 - val_accuracy: 0.2754\n",
            "Epoch 34/50\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 0.6281 - accuracy: 0.8067 - val_loss: 15.6514 - val_accuracy: 0.2995\n",
            "Epoch 35/50\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 0.6070 - accuracy: 0.8026 - val_loss: 18.9109 - val_accuracy: 0.2802\n",
            "Epoch 36/50\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 0.5991 - accuracy: 0.8150 - val_loss: 15.8133 - val_accuracy: 0.3237\n",
            "Epoch 37/50\n",
            "291/291 [==============================] - 5s 19ms/step - loss: 0.5194 - accuracy: 0.8219 - val_loss: 17.8973 - val_accuracy: 0.2754\n",
            "Epoch 38/50\n",
            "291/291 [==============================] - 5s 19ms/step - loss: 0.5520 - accuracy: 0.8281 - val_loss: 15.4539 - val_accuracy: 0.2947\n",
            "Epoch 39/50\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 0.5486 - accuracy: 0.8109 - val_loss: 15.7088 - val_accuracy: 0.2995\n",
            "Epoch 40/50\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 0.5192 - accuracy: 0.8398 - val_loss: 16.5325 - val_accuracy: 0.2947\n",
            "Epoch 41/50\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 0.5191 - accuracy: 0.8315 - val_loss: 16.0554 - val_accuracy: 0.2947\n",
            "Epoch 42/50\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 0.5639 - accuracy: 0.8274 - val_loss: 15.3934 - val_accuracy: 0.2947\n",
            "Epoch 43/50\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 0.5195 - accuracy: 0.8287 - val_loss: 17.6861 - val_accuracy: 0.2947\n",
            "Epoch 44/50\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 0.5722 - accuracy: 0.8184 - val_loss: 15.9727 - val_accuracy: 0.2899\n",
            "Epoch 45/50\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 0.5186 - accuracy: 0.8322 - val_loss: 17.0337 - val_accuracy: 0.2850\n",
            "Epoch 46/50\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 0.4886 - accuracy: 0.8473 - val_loss: 16.8389 - val_accuracy: 0.2850\n",
            "Epoch 47/50\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 0.4915 - accuracy: 0.8384 - val_loss: 17.3577 - val_accuracy: 0.2802\n",
            "Epoch 48/50\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 0.5080 - accuracy: 0.8287 - val_loss: 17.4945 - val_accuracy: 0.3043\n",
            "Epoch 49/50\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 0.5122 - accuracy: 0.8398 - val_loss: 19.1347 - val_accuracy: 0.2802\n",
            "Epoch 50/50\n",
            "291/291 [==============================] - 5s 18ms/step - loss: 0.4791 - accuracy: 0.8453 - val_loss: 18.8328 - val_accuracy: 0.2899\n",
            "27/27 [==============================] - 1s 14ms/step - loss: 3.6370 - accuracy: 0.6343\n",
            "Test Accuracy: 0.634319543838501\n",
            "27/27 [==============================] - 0s 9ms/step\n"
          ]
        }
      ],
      "source": [
        "#--------------------------------------------------------------------\n",
        "# Instantiate DBN model for text\n",
        "#Applying Model for each category__2 categories\n",
        "# Model for category  'Computers & Accessories'\n",
        "\n",
        "\n",
        "import gc\n",
        "gc.collect()\n",
        "print(' Result of Computers & Accessories:')\n",
        "encoded_labels_train, encoded_labels_test, encoded_labels_val,label_encoder=encode_labels(inp1['leaf'],testinp1['leaf'],val1['leaf'])\n",
        "X_train_leaf1,X_test_leaf1,X_val_leaf1=tf_idf_vectorization(inp1,testinp1,val1)\n",
        "X_train_encoded,X_test_encoded,X_val_encoded=train_denoising_autoencoder(X_train_leaf1, X_test_leaf1, X_val_leaf1)\n",
        "input_dim_dbn = X_train_encoded.shape[1]\n",
        "#test images loading\n",
        "X_test_img=Load_images(testinp1)\n",
        "X_train_img=Load_images(inp1)\n",
        "X_val_img=Load_images(val1)\n",
        "# Instantiate CNN model for image\n",
        "# Instantiate DBN model for text\n",
        "input_dim_dbn = X_train_encoded.shape[1]\n",
        "num_classes = 186 # Set the input dimensions based on the DBN input shape\n",
        "ep=50\n",
        "size=5\n",
        "model= cnn_dbn(num_classes,X_train_img,X_train_encoded,encoded_labels_train,ep,size,X_val_img,X_val_encoded,encoded_labels_val)\n",
        "\n",
        "# Evaluate the multi-modal model\n",
        "loss, accuracy = model.evaluate([X_test_img, X_test_encoded], encoded_labels_test)\n",
        "print(f'Test Accuracy: {accuracy}')\n",
        "predicted_probabilities= model.predict([X_test_img, X_test_encoded])\n",
        "# Convert probabilities to class indices (argmax to get the index of the highest probability)\n",
        "predicted_class_indices = np.argmax(predicted_probabilities, axis=1)\n",
        "\n",
        "# Convert class indices back to original labels using inverse_transform of label_encoder\n",
        "predicted_labels = label_encoder.inverse_transform(predicted_class_indices)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5uNzQPoETowu",
        "outputId": "f9b45393-e5ef-4919-c92a-473c43fdbef1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-3e524c413c8f>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  testinp1['pleaf']=predicted_labels\n"
          ]
        }
      ],
      "source": [
        "# Display predicted labels\n",
        "testinp1['pleaf']=predicted_labels\n",
        "file_path = 'testinp1.csv'\n",
        "\n",
        "# Save the modified 'test' DataFrame to a CSV file without the DataFrame index\n",
        "testinp1.to_csv(file_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5wxDFfjGTowu",
        "outputId": "bb3db7a1-f56f-4537-efa1-8278d51ca859",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Result of Accessories & Supplies:\n",
            "(707, 4228)\n",
            "(406, 4228)\n",
            "Epoch 1/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.2054 - val_loss: 0.0150\n",
            "Epoch 2/50\n",
            "142/142 [==============================] - 0s 4ms/step - loss: 0.0107 - val_loss: 0.0106\n",
            "Epoch 3/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0097\n",
            "Epoch 4/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0086 - val_loss: 0.0094\n",
            "Epoch 5/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0083 - val_loss: 0.0092\n",
            "Epoch 6/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0081 - val_loss: 0.0090\n",
            "Epoch 7/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0079 - val_loss: 0.0090\n",
            "Epoch 8/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0079 - val_loss: 0.0088\n",
            "Epoch 9/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0077 - val_loss: 0.0088\n",
            "Epoch 10/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0077 - val_loss: 0.0087\n",
            "Epoch 11/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0076 - val_loss: 0.0087\n",
            "Epoch 12/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0086\n",
            "Epoch 13/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0074 - val_loss: 0.0086\n",
            "Epoch 14/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0073 - val_loss: 0.0085\n",
            "Epoch 15/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0072 - val_loss: 0.0084\n",
            "Epoch 16/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0084\n",
            "Epoch 17/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0070 - val_loss: 0.0083\n",
            "Epoch 18/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0083\n",
            "Epoch 19/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0082\n",
            "Epoch 20/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0067 - val_loss: 0.0082\n",
            "Epoch 21/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0066 - val_loss: 0.0082\n",
            "Epoch 22/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0064 - val_loss: 0.0081\n",
            "Epoch 23/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0063 - val_loss: 0.0081\n",
            "Epoch 24/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0062 - val_loss: 0.0080\n",
            "Epoch 25/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0061 - val_loss: 0.0079\n",
            "Epoch 26/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0059 - val_loss: 0.0079\n",
            "Epoch 27/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0058 - val_loss: 0.0078\n",
            "Epoch 28/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0057 - val_loss: 0.0078\n",
            "Epoch 29/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0056 - val_loss: 0.0077\n",
            "Epoch 30/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0055 - val_loss: 0.0077\n",
            "Epoch 31/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0076\n",
            "Epoch 32/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0052 - val_loss: 0.0075\n",
            "Epoch 33/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0051 - val_loss: 0.0075\n",
            "Epoch 34/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0050 - val_loss: 0.0075\n",
            "Epoch 35/50\n",
            "142/142 [==============================] - 1s 4ms/step - loss: 0.0049 - val_loss: 0.0074\n",
            "Epoch 36/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0074\n",
            "Epoch 37/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0047 - val_loss: 0.0073\n",
            "Epoch 38/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0073\n",
            "Epoch 39/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0072\n",
            "Epoch 40/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 0.0072\n",
            "Epoch 41/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0043 - val_loss: 0.0071\n",
            "Epoch 42/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0042 - val_loss: 0.0071\n",
            "Epoch 43/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0042 - val_loss: 0.0071\n",
            "Epoch 44/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0041 - val_loss: 0.0071\n",
            "Epoch 45/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0041 - val_loss: 0.0071\n",
            "Epoch 46/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0040 - val_loss: 0.0070\n",
            "Epoch 47/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0040 - val_loss: 0.0070\n",
            "Epoch 48/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0039 - val_loss: 0.0070\n",
            "Epoch 49/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0039 - val_loss: 0.0070\n",
            "Epoch 50/50\n",
            "142/142 [==============================] - 0s 3ms/step - loss: 0.0039 - val_loss: 0.0070\n",
            "23/23 [==============================] - 0s 1ms/step\n",
            "13/13 [==============================] - 0s 1ms/step\n",
            "4/4 [==============================] - 0s 2ms/step\n",
            "Epoch 1/50\n",
            "142/142 [==============================] - 5s 20ms/step - loss: 5.0414 - accuracy: 0.1796 - val_loss: 6.1198 - val_accuracy: 0.0381\n",
            "Epoch 2/50\n",
            "142/142 [==============================] - 3s 18ms/step - loss: 2.8543 - accuracy: 0.3550 - val_loss: 6.6801 - val_accuracy: 0.0381\n",
            "Epoch 3/50\n",
            "142/142 [==============================] - 3s 18ms/step - loss: 2.5196 - accuracy: 0.3932 - val_loss: 7.5864 - val_accuracy: 0.0571\n",
            "Epoch 4/50\n",
            "142/142 [==============================] - 3s 18ms/step - loss: 2.3002 - accuracy: 0.4201 - val_loss: 7.7922 - val_accuracy: 0.0762\n",
            "Epoch 5/50\n",
            "142/142 [==============================] - 3s 18ms/step - loss: 2.1204 - accuracy: 0.4597 - val_loss: 9.7318 - val_accuracy: 0.0762\n",
            "Epoch 6/50\n",
            "142/142 [==============================] - 3s 18ms/step - loss: 1.9540 - accuracy: 0.4936 - val_loss: 8.5042 - val_accuracy: 0.1048\n",
            "Epoch 7/50\n",
            "142/142 [==============================] - 3s 18ms/step - loss: 1.7719 - accuracy: 0.5262 - val_loss: 7.8443 - val_accuracy: 0.1048\n",
            "Epoch 8/50\n",
            "142/142 [==============================] - 3s 18ms/step - loss: 1.6636 - accuracy: 0.5601 - val_loss: 8.2919 - val_accuracy: 0.1048\n",
            "Epoch 9/50\n",
            "142/142 [==============================] - 3s 19ms/step - loss: 1.5675 - accuracy: 0.5601 - val_loss: 9.4203 - val_accuracy: 0.0952\n",
            "Epoch 10/50\n",
            "142/142 [==============================] - 3s 18ms/step - loss: 1.3984 - accuracy: 0.6040 - val_loss: 9.7288 - val_accuracy: 0.1238\n",
            "Epoch 11/50\n",
            "142/142 [==============================] - 3s 18ms/step - loss: 1.3568 - accuracy: 0.6139 - val_loss: 11.7495 - val_accuracy: 0.1333\n",
            "Epoch 12/50\n",
            "142/142 [==============================] - 3s 18ms/step - loss: 1.3198 - accuracy: 0.6308 - val_loss: 11.8024 - val_accuracy: 0.1333\n",
            "Epoch 13/50\n",
            "142/142 [==============================] - 3s 18ms/step - loss: 1.2067 - accuracy: 0.6280 - val_loss: 11.0294 - val_accuracy: 0.1048\n",
            "Epoch 14/50\n",
            "142/142 [==============================] - 3s 19ms/step - loss: 1.1673 - accuracy: 0.6506 - val_loss: 10.6944 - val_accuracy: 0.1524\n",
            "Epoch 15/50\n",
            "142/142 [==============================] - 3s 18ms/step - loss: 1.0831 - accuracy: 0.6605 - val_loss: 9.8294 - val_accuracy: 0.1333\n",
            "Epoch 16/50\n",
            "142/142 [==============================] - 3s 18ms/step - loss: 1.0845 - accuracy: 0.6917 - val_loss: 10.1836 - val_accuracy: 0.1619\n",
            "Epoch 17/50\n",
            "142/142 [==============================] - 3s 18ms/step - loss: 0.9665 - accuracy: 0.6775 - val_loss: 11.0404 - val_accuracy: 0.1333\n",
            "Epoch 18/50\n",
            "142/142 [==============================] - 3s 18ms/step - loss: 0.9949 - accuracy: 0.6987 - val_loss: 9.8985 - val_accuracy: 0.1333\n",
            "Epoch 19/50\n",
            "142/142 [==============================] - 3s 19ms/step - loss: 0.9430 - accuracy: 0.6973 - val_loss: 10.2214 - val_accuracy: 0.1429\n",
            "Epoch 20/50\n",
            "142/142 [==============================] - 3s 18ms/step - loss: 0.8238 - accuracy: 0.7553 - val_loss: 11.6800 - val_accuracy: 0.1619\n",
            "Epoch 21/50\n",
            "142/142 [==============================] - 3s 18ms/step - loss: 0.8745 - accuracy: 0.7228 - val_loss: 10.5480 - val_accuracy: 0.1143\n",
            "Epoch 22/50\n",
            "142/142 [==============================] - 3s 18ms/step - loss: 0.8442 - accuracy: 0.7313 - val_loss: 13.1374 - val_accuracy: 0.1429\n",
            "Epoch 23/50\n",
            "142/142 [==============================] - 3s 18ms/step - loss: 0.8026 - accuracy: 0.7525 - val_loss: 10.3910 - val_accuracy: 0.1524\n",
            "Epoch 24/50\n",
            "142/142 [==============================] - 3s 19ms/step - loss: 0.8080 - accuracy: 0.7468 - val_loss: 12.1999 - val_accuracy: 0.1524\n",
            "Epoch 25/50\n",
            "142/142 [==============================] - 3s 19ms/step - loss: 0.7560 - accuracy: 0.7482 - val_loss: 11.0347 - val_accuracy: 0.1429\n",
            "Epoch 26/50\n",
            "142/142 [==============================] - 3s 19ms/step - loss: 0.7175 - accuracy: 0.7765 - val_loss: 13.2920 - val_accuracy: 0.1619\n",
            "Epoch 27/50\n",
            "142/142 [==============================] - 3s 18ms/step - loss: 0.8110 - accuracy: 0.7567 - val_loss: 11.6639 - val_accuracy: 0.1714\n",
            "Epoch 28/50\n",
            "142/142 [==============================] - 3s 19ms/step - loss: 0.7410 - accuracy: 0.7595 - val_loss: 10.0735 - val_accuracy: 0.1619\n",
            "Epoch 29/50\n",
            "142/142 [==============================] - 3s 18ms/step - loss: 0.6780 - accuracy: 0.7737 - val_loss: 11.6249 - val_accuracy: 0.1619\n",
            "Epoch 30/50\n",
            "142/142 [==============================] - 3s 18ms/step - loss: 0.5931 - accuracy: 0.8161 - val_loss: 10.6337 - val_accuracy: 0.1619\n",
            "Epoch 31/50\n",
            "142/142 [==============================] - 3s 18ms/step - loss: 0.6279 - accuracy: 0.8076 - val_loss: 12.1912 - val_accuracy: 0.1714\n",
            "Epoch 32/50\n",
            "142/142 [==============================] - 3s 18ms/step - loss: 0.5698 - accuracy: 0.8232 - val_loss: 11.9673 - val_accuracy: 0.1429\n",
            "Epoch 33/50\n",
            "142/142 [==============================] - 3s 19ms/step - loss: 0.6781 - accuracy: 0.8091 - val_loss: 10.4108 - val_accuracy: 0.1714\n",
            "Epoch 34/50\n",
            "142/142 [==============================] - 3s 18ms/step - loss: 0.5780 - accuracy: 0.8119 - val_loss: 10.9269 - val_accuracy: 0.1714\n",
            "Epoch 35/50\n",
            "142/142 [==============================] - 3s 18ms/step - loss: 0.5508 - accuracy: 0.8317 - val_loss: 10.8030 - val_accuracy: 0.1619\n",
            "Epoch 36/50\n",
            "142/142 [==============================] - 3s 18ms/step - loss: 0.5328 - accuracy: 0.8331 - val_loss: 12.7960 - val_accuracy: 0.1619\n",
            "Epoch 37/50\n",
            "142/142 [==============================] - 3s 18ms/step - loss: 0.4810 - accuracy: 0.8402 - val_loss: 12.4282 - val_accuracy: 0.1810\n",
            "Epoch 38/50\n",
            "142/142 [==============================] - 3s 18ms/step - loss: 0.5271 - accuracy: 0.8303 - val_loss: 13.0145 - val_accuracy: 0.1810\n",
            "Epoch 39/50\n",
            "142/142 [==============================] - 3s 18ms/step - loss: 0.5654 - accuracy: 0.8345 - val_loss: 11.9717 - val_accuracy: 0.1714\n",
            "Epoch 40/50\n",
            "142/142 [==============================] - 3s 19ms/step - loss: 0.4787 - accuracy: 0.8501 - val_loss: 11.8045 - val_accuracy: 0.1619\n",
            "Epoch 41/50\n",
            "142/142 [==============================] - 3s 18ms/step - loss: 0.4668 - accuracy: 0.8501 - val_loss: 11.4454 - val_accuracy: 0.1524\n",
            "Epoch 42/50\n",
            "142/142 [==============================] - 3s 18ms/step - loss: 0.4814 - accuracy: 0.8458 - val_loss: 12.7324 - val_accuracy: 0.1619\n",
            "Epoch 43/50\n",
            "142/142 [==============================] - 3s 18ms/step - loss: 0.4398 - accuracy: 0.8472 - val_loss: 13.3812 - val_accuracy: 0.1714\n",
            "Epoch 44/50\n",
            "142/142 [==============================] - 3s 18ms/step - loss: 0.5219 - accuracy: 0.8373 - val_loss: 11.6659 - val_accuracy: 0.1714\n",
            "Epoch 45/50\n",
            "142/142 [==============================] - 3s 18ms/step - loss: 0.5354 - accuracy: 0.8444 - val_loss: 10.0313 - val_accuracy: 0.1810\n",
            "Epoch 46/50\n",
            "142/142 [==============================] - 3s 18ms/step - loss: 0.4122 - accuracy: 0.8755 - val_loss: 11.6926 - val_accuracy: 0.1714\n",
            "Epoch 47/50\n",
            "142/142 [==============================] - 3s 18ms/step - loss: 0.4025 - accuracy: 0.8685 - val_loss: 12.5211 - val_accuracy: 0.1714\n",
            "Epoch 48/50\n",
            "142/142 [==============================] - 3s 18ms/step - loss: 0.4050 - accuracy: 0.8628 - val_loss: 10.6954 - val_accuracy: 0.1714\n",
            "Epoch 49/50\n",
            "142/142 [==============================] - 3s 18ms/step - loss: 0.4189 - accuracy: 0.8656 - val_loss: 15.2480 - val_accuracy: 0.1524\n",
            "Epoch 50/50\n",
            "142/142 [==============================] - 3s 18ms/step - loss: 0.4118 - accuracy: 0.8699 - val_loss: 13.0247 - val_accuracy: 0.1619\n",
            "13/13 [==============================] - 0s 11ms/step - loss: 3.1008 - accuracy: 0.5936\n",
            "Test Accuracy: 0.5935960412025452\n",
            "13/13 [==============================] - 0s 9ms/step\n"
          ]
        }
      ],
      "source": [
        "# Model for category  'Accessories & Supplies'\n",
        "\n",
        "print(' Result of Accessories & Supplies:')\n",
        "\n",
        "encoded_labels_train, encoded_labels_test, encoded_labels_val,label_encoder=encode_labels(inp2['leaf'],testinp2['leaf'],val2['leaf'])\n",
        "X_train_leaf,X_test_leaf,X_val_leaf=tf_idf_vectorization(inp2,testinp2,val2)\n",
        "X_train_encoded,X_test_encoded,X_val_encoded=train_denoising_autoencoder(X_train_leaf, X_test_leaf, X_val_leaf)\n",
        "input_dim_dbn = X_train_encoded.shape[1]\n",
        "#test images loading\n",
        "X_test_img=Load_images(testinp2)\n",
        "X_train_img=Load_images(inp2)\n",
        "X_val_img=Load_images(val2)\n",
        "input_dim_dbn = X_train_encoded.shape[1]\n",
        "num_classes = 129 # Set the input dimensions based on the DBN input shape\n",
        "ep=50\n",
        "size=5\n",
        "model= cnn_dbn(num_classes,X_train_img,X_train_encoded,encoded_labels_train,ep,size,X_val_img,X_val_encoded,encoded_labels_val)\n",
        "\n",
        "# Evaluate the multi-modal model\n",
        "loss, accuracy = model.evaluate([X_test_img, X_test_encoded], encoded_labels_test)\n",
        "print(f'Test Accuracy: {accuracy}')\n",
        "predicted_probabilities= model.predict([X_test_img, X_test_encoded])\n",
        "# Convert probabilities to class indices (argmax to get the index of the highest probability)\n",
        "predicted_class_indices = np.argmax(predicted_probabilities, axis=1)\n",
        "\n",
        "# Convert class indices back to original labels using inverse_transform of label_encoder\n",
        "predicted_labels = label_encoder.inverse_transform(predicted_class_indices)\n",
        "\n",
        "\n",
        "# Display predicted labels\n",
        "#testinp2['pleaf']=predicted_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "om5bYUc9Towu",
        "outputId": "f17f06f5-cd06-420a-a9d9-03fbc95318c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-66-35a3570095a3>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  testinp2['pleaf']=predicted_labels\n"
          ]
        }
      ],
      "source": [
        "# Display predicted labels\n",
        "#43\n",
        "testinp2['pleaf']=predicted_labels\n",
        "file_path = 'testinp2.csv'\n",
        "\n",
        "# Save the modified 'test' DataFrame to a CSV file without the DataFrame index\n",
        "testinp2.to_csv(file_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8KxNY6BSTowu",
        "outputId": "c25fb6b4-cff5-4328-e094-8695ac930252",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19576"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "# Model for category  'GPS & Navigation'\n",
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Knt139MqTowv"
      },
      "outputs": [],
      "source": [
        "keras.backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9g0TUuBTowv",
        "outputId": "d4880a82-296e-4542-de09-4b9e40201d57",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Result of GPS & Navigation:\n",
            "(45, 943)\n",
            "(11, 943)\n",
            "Epoch 1/50\n",
            "9/9 [==============================] - 1s 21ms/step - loss: 0.6806 - val_loss: 0.6607\n",
            "Epoch 2/50\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.6278 - val_loss: 0.5971\n",
            "Epoch 3/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.5155 - val_loss: 0.4853\n",
            "Epoch 4/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.3511 - val_loss: 0.3370\n",
            "Epoch 5/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.1859 - val_loss: 0.2037\n",
            "Epoch 6/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0983 - val_loss: 0.1200\n",
            "Epoch 7/50\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0599 - val_loss: 0.0810\n",
            "Epoch 8/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0461 - val_loss: 0.0631\n",
            "Epoch 9/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0431 - val_loss: 0.0538\n",
            "Epoch 10/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0400 - val_loss: 0.0495\n",
            "Epoch 11/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0383 - val_loss: 0.0468\n",
            "Epoch 12/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0372 - val_loss: 0.0450\n",
            "Epoch 13/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0368 - val_loss: 0.0438\n",
            "Epoch 14/50\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0362 - val_loss: 0.0430\n",
            "Epoch 15/50\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0357 - val_loss: 0.0421\n",
            "Epoch 16/50\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0349 - val_loss: 0.0414\n",
            "Epoch 17/50\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0347 - val_loss: 0.0410\n",
            "Epoch 18/50\n",
            "9/9 [==============================] - 0s 7ms/step - loss: 0.0343 - val_loss: 0.0403\n",
            "Epoch 19/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0339 - val_loss: 0.0399\n",
            "Epoch 20/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0332 - val_loss: 0.0396\n",
            "Epoch 21/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0331 - val_loss: 0.0393\n",
            "Epoch 22/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0330 - val_loss: 0.0390\n",
            "Epoch 23/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0328 - val_loss: 0.0384\n",
            "Epoch 24/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0325 - val_loss: 0.0381\n",
            "Epoch 25/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0322 - val_loss: 0.0376\n",
            "Epoch 26/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0322 - val_loss: 0.0372\n",
            "Epoch 27/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0321 - val_loss: 0.0370\n",
            "Epoch 28/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0319 - val_loss: 0.0367\n",
            "Epoch 29/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0316 - val_loss: 0.0365\n",
            "Epoch 30/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0314 - val_loss: 0.0362\n",
            "Epoch 31/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0313 - val_loss: 0.0359\n",
            "Epoch 32/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0312 - val_loss: 0.0356\n",
            "Epoch 33/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0312 - val_loss: 0.0352\n",
            "Epoch 34/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0309 - val_loss: 0.0349\n",
            "Epoch 35/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0307 - val_loss: 0.0348\n",
            "Epoch 36/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0304 - val_loss: 0.0347\n",
            "Epoch 37/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0306 - val_loss: 0.0345\n",
            "Epoch 38/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0304 - val_loss: 0.0341\n",
            "Epoch 39/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0302 - val_loss: 0.0337\n",
            "Epoch 40/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0303 - val_loss: 0.0336\n",
            "Epoch 41/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0299 - val_loss: 0.0334\n",
            "Epoch 42/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0298 - val_loss: 0.0331\n",
            "Epoch 43/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0295 - val_loss: 0.0329\n",
            "Epoch 44/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0296 - val_loss: 0.0328\n",
            "Epoch 45/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0293 - val_loss: 0.0327\n",
            "Epoch 46/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0293 - val_loss: 0.0325\n",
            "Epoch 47/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0292 - val_loss: 0.0322\n",
            "Epoch 48/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0291 - val_loss: 0.0321\n",
            "Epoch 49/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0289 - val_loss: 0.0319\n",
            "Epoch 50/50\n",
            "9/9 [==============================] - 0s 6ms/step - loss: 0.0288 - val_loss: 0.0318\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Epoch 1/45\n",
            "15/15 [==============================] - 3s 34ms/step - loss: 11.0635 - accuracy: 0.1556 - val_loss: 7.9271 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/45\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 3.2655 - accuracy: 0.2444 - val_loss: 2.9451 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/45\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 2.0934 - accuracy: 0.2889 - val_loss: 3.3921 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/45\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 1.7498 - accuracy: 0.4222 - val_loss: 3.5549 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/45\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 1.8060 - accuracy: 0.2889 - val_loss: 4.1111 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/45\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 1.6085 - accuracy: 0.4000 - val_loss: 3.9997 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/45\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 1.4279 - accuracy: 0.5556 - val_loss: 4.8165 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/45\n",
            "15/15 [==============================] - 0s 19ms/step - loss: 1.3288 - accuracy: 0.5333 - val_loss: 4.8681 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/45\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 1.2266 - accuracy: 0.6000 - val_loss: 4.9215 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/45\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 1.1847 - accuracy: 0.6000 - val_loss: 5.3110 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/45\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 1.2531 - accuracy: 0.5556 - val_loss: 4.6691 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/45\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 1.0290 - accuracy: 0.6222 - val_loss: 4.6266 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/45\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 1.1239 - accuracy: 0.5333 - val_loss: 4.6408 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/45\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 0.9929 - accuracy: 0.6667 - val_loss: 6.1759 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/45\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 0.8672 - accuracy: 0.6667 - val_loss: 5.2376 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/45\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 0.7675 - accuracy: 0.8222 - val_loss: 6.2066 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/45\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 0.6900 - accuracy: 0.7778 - val_loss: 5.5587 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/45\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 0.8051 - accuracy: 0.6000 - val_loss: 5.8001 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/45\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 0.7906 - accuracy: 0.8444 - val_loss: 4.7706 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/45\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 0.7423 - accuracy: 0.6889 - val_loss: 5.4794 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/45\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 0.4794 - accuracy: 0.9111 - val_loss: 7.6929 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/45\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 0.4303 - accuracy: 0.8444 - val_loss: 7.1129 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/45\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 0.5386 - accuracy: 0.7778 - val_loss: 7.5335 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/45\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 0.4402 - accuracy: 0.8667 - val_loss: 7.6292 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/45\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 0.2577 - accuracy: 0.9111 - val_loss: 8.0470 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/45\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 0.5152 - accuracy: 0.8667 - val_loss: 6.7336 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/45\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 0.4348 - accuracy: 0.8444 - val_loss: 6.0751 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/45\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 0.4529 - accuracy: 0.8889 - val_loss: 7.1572 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/45\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 0.3092 - accuracy: 0.9333 - val_loss: 8.4467 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/45\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 0.6518 - accuracy: 0.8000 - val_loss: 9.0168 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/45\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 0.2685 - accuracy: 0.8667 - val_loss: 9.3152 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/45\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 0.2146 - accuracy: 0.9111 - val_loss: 10.0240 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/45\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 0.3636 - accuracy: 0.8889 - val_loss: 8.7469 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/45\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 0.1861 - accuracy: 0.9556 - val_loss: 9.8092 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/45\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 0.2113 - accuracy: 0.9333 - val_loss: 9.6607 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/45\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 0.2519 - accuracy: 0.8889 - val_loss: 10.7026 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/45\n",
            "15/15 [==============================] - 0s 19ms/step - loss: 0.3148 - accuracy: 0.9111 - val_loss: 9.1696 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/45\n",
            "15/15 [==============================] - 0s 19ms/step - loss: 0.2573 - accuracy: 0.9111 - val_loss: 10.2551 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/45\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 0.2283 - accuracy: 0.8889 - val_loss: 12.3701 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/45\n",
            "15/15 [==============================] - 0s 19ms/step - loss: 0.2639 - accuracy: 0.9778 - val_loss: 7.9933 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/45\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 0.1655 - accuracy: 0.9333 - val_loss: 7.2465 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/45\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 0.3019 - accuracy: 0.9111 - val_loss: 7.5969 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/45\n",
            "15/15 [==============================] - 0s 18ms/step - loss: 0.1996 - accuracy: 0.9556 - val_loss: 7.8813 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/45\n",
            "15/15 [==============================] - 0s 19ms/step - loss: 0.2982 - accuracy: 0.8000 - val_loss: 10.1588 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/45\n",
            "15/15 [==============================] - 0s 19ms/step - loss: 0.1758 - accuracy: 0.9111 - val_loss: 13.7037 - val_accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 186ms/step - loss: 2.5115 - accuracy: 0.3636\n",
            "Test Accuracy: 0.3636363744735718\n",
            "1/1 [==============================] - 0s 101ms/step\n"
          ]
        }
      ],
      "source": [
        "\n",
        "print(' Result of GPS & Navigation:')\n",
        "\n",
        "encoded_labels_train, encoded_labels_test, encoded_labels_val,label_encoder=encode_labels(inp3['leaf'],testinp3['leaf'],val3['leaf'])\n",
        "X_train_leaf,X_test_leaf,X_val_leaf=tf_idf_vectorization(inp3,testinp3,val3)\n",
        "X_train_encoded,X_test_encoded,X_val_encoded=train_denoising_autoencoder(X_train_leaf, X_test_leaf, X_val_leaf)\n",
        "input_dim_dbn = X_train_encoded.shape[1]\n",
        "#test images loading\n",
        "X_test_img=Load_images(testinp3)\n",
        "X_train_img=Load_images(inp3)\n",
        "X_val_img=Load_images(val3)\n",
        "input_dim_dbn = X_train_encoded.shape[1]\n",
        "num_classes = 13 # Set the input dimensions based on the DBN input shape\n",
        "ep=45\n",
        "size=3\n",
        "model= cnn_dbn(num_classes,X_train_img,X_train_encoded,encoded_labels_train,ep,size,X_val_img,X_val_encoded,encoded_labels_val)\n",
        "\n",
        "# Evaluate the multi-modal model\n",
        "loss, accuracy = model.evaluate([X_test_img, X_test_encoded], encoded_labels_test)\n",
        "print(f'Test Accuracy: {accuracy}')\n",
        "predicted_probabilities= model.predict([X_test_img, X_test_encoded])\n",
        "# Convert probabilities to class indices (argmax to get the index of the highest probability)\n",
        "predicted_class_indices = np.argmax(predicted_probabilities, axis=1)\n",
        "\n",
        "# Convert class indices back to original labels using inverse_transform of label_encoder\n",
        "predicted_labels = label_encoder.inverse_transform(predicted_class_indices)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fwiL1VGsTowv",
        "outputId": "9caed407-030b-4b89-c75c-98576f10bcd0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-80-667fc84ab99c>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  testinp3['pleaf']=predicted_labels\n"
          ]
        }
      ],
      "source": [
        "#2727\n",
        "# Display predicted labels\n",
        "testinp3['pleaf']=predicted_labels\n",
        "file_path = 'testinp3.csv'\n",
        "\n",
        "# Save the modified 'test' DataFrame to a CSV file without the DataFrame index\n",
        "testinp3.to_csv(file_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHHUSBVXTowv",
        "outputId": "92e1fd42-451a-4c59-975a-83568f1d1004",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "13"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "encoded_labels_train, encoded_labels_test, encoded_labels_val,label_encoder1=encode_labels(inp4['leaf'],testinp4['leaf'],val4['leaf'])\n",
        "len(label_encoder1.classes_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fv5l7KxrTowv",
        "outputId": "3c055eac-28df-4480-e4d2-13efa5e9f244",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "785"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# Model for category  'GPS & Navigation'\n",
        "import gc\n",
        "gc.collect()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HcbinHInToww"
      },
      "outputs": [],
      "source": [
        "# Model for category  'eBook Readers & Accessories'\n",
        "\n",
        "print(' Result of eBook Readers & Accessories:')\n",
        "\n",
        "encoded_labels_train, encoded_labels_test, encoded_labels_val,label_encoder=encode_labels(inp4['leaf'],testinp4['leaf'],val4['leaf'])\n",
        "X_train_leaf,X_test_leaf,X_val_leaf=tf_idf_vectorization(inp4,testinp4,val4)\n",
        "X_train_encoded,X_test_encoded,X_val_encoded=train_denoising_autoencoder(X_train_leaf, X_test_leaf, X_val_leaf)\n",
        "input_dim_dbn = X_train_encoded.shape[1]\n",
        "#test images loading\n",
        "X_test_img=Load_images(testinp4)\n",
        "X_train_img=Load_images(inp4)\n",
        "X_val_img=Load_images(val4)\n",
        "input_dim_dbn = X_train_encoded.shape[1]\n",
        "num_classes = 13 # Set the input dimensions based on the DBN input shape\n",
        "ep=50\n",
        "size=5\n",
        "model= cnn_dbn(num_classes,X_train_img,X_train_encoded,encoded_labels_train,ep,size,X_val_img,X_val_encoded,encoded_labels_val)\n",
        "\n",
        "# Evaluate the multi-modal model\n",
        "loss, accuracy = model.evaluate([X_test_img, X_test_encoded], encoded_labels_test)\n",
        "print(f'Test Accuracy: {accuracy}')\n",
        "predicted_probabilities= model.predict([X_test_img, X_test_encoded])\n",
        "# Convert probabilities to class indices (argmax to get the index of the highest probability)\n",
        "predicted_class_indices = np.argmax(predicted_probabilities, axis=1)\n",
        "\n",
        "# Convert class indices back to original labels using inverse_transform of label_encoder\n",
        "predicted_labels = label_encoder.inverse_transform(predicted_class_indices)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "testinp4['pleaf']=predicted_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZNudCThqToww",
        "outputId": "829d27e6-2b99-4038-d091-2d86e84f1670",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, 16)\n"
          ]
        }
      ],
      "source": [
        "print(testinp4.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKXGotqAToww",
        "outputId": "4694ddee-2524-4400-de10-eaa28fee9627"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "45"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model for category  'Car & Vehicle Electronics'\n",
        "\n",
        "print(' Result of car & vehicle electronics:')\n",
        "\n",
        "if len(testinp5)!=0:\n",
        "    encoded_labels_train, encoded_labels_test, encoded_labels_val,label_encoder=encode_labels(inp5['leaf'],testinp5['leaf'],val5['leaf'])\n",
        "    X_train_leaf,X_test_leaf,X_val_leaf=tf_idf_vectorization(inp5,testinp5,val5)\n",
        "    X_train_encoded,X_test_encoded,X_val_encoded=train_denoising_autoencoder(X_train_leaf, X_test_leaf, X_val_leaf)\n",
        "    input_dim_dbn = X_train_encoded.shape[1]\n",
        "    #test images loading\n",
        "    X_test_img=Load_images(testinp5)\n",
        "    X_train_img=Load_images(inp5)\n",
        "    X_val_img=Load_images(val5)\n",
        "    input_dim_dbn = X_train_encoded.shape[1]\n",
        "    num_classes = 42 # Set the input dimensions based on the DBN input shape\n",
        "    ep=50\n",
        "    size=5\n",
        "    model= cnn_dbn(num_classes,X_train_img,X_train_encoded,encoded_labels_train,ep,size,X_val_img,X_val_encoded,encoded_labels_val)\n",
        "\n",
        "    # Evaluate the multi-modal model\n",
        "    loss, accuracy = model.evaluate([X_test_img, X_test_encoded], encoded_labels_test)\n",
        "    print(f'Test Accuracy: {accuracy}')\n",
        "    predicted_probabilities= model.predict([X_test_img, X_test_encoded])\n",
        "    # Convert probabilities to class indices (argmax to get the index of the highest probability)\n",
        "    predicted_class_indices = np.argmax(predicted_probabilities, axis=1)\n",
        "\n",
        "    # Convert class indices back to original labels using inverse_transform of label_encoder\n",
        "    predicted_labels = label_encoder.inverse_transform(predicted_class_indices)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2wKk1oxr52Y",
        "outputId": "37082baf-d8e0-451a-e588-637a20706eec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Result of car & vehicle electronics:\n",
            "(116, 1582)\n",
            "(18, 1582)\n",
            "Epoch 1/50\n",
            "24/24 [==============================] - 1s 9ms/step - loss: 0.6382 - val_loss: 0.5620\n",
            "Epoch 2/50\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.3124 - val_loss: 0.2109\n",
            "Epoch 3/50\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.0769 - val_loss: 0.0666\n",
            "Epoch 4/50\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.0329 - val_loss: 0.0398\n",
            "Epoch 5/50\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.0246 - val_loss: 0.0328\n",
            "Epoch 6/50\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.0220 - val_loss: 0.0291\n",
            "Epoch 7/50\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.0203 - val_loss: 0.0271\n",
            "Epoch 8/50\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.0193 - val_loss: 0.0260\n",
            "Epoch 9/50\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.0187 - val_loss: 0.0252\n",
            "Epoch 10/50\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.0181 - val_loss: 0.0249\n",
            "Epoch 11/50\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.0176 - val_loss: 0.0242\n",
            "Epoch 12/50\n",
            "24/24 [==============================] - 0s 5ms/step - loss: 0.0173 - val_loss: 0.0242\n",
            "Epoch 13/50\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.0169 - val_loss: 0.0238\n",
            "Epoch 14/50\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.0168 - val_loss: 0.0235\n",
            "Epoch 15/50\n",
            "24/24 [==============================] - 0s 5ms/step - loss: 0.0165 - val_loss: 0.0233\n",
            "Epoch 16/50\n",
            "24/24 [==============================] - 0s 5ms/step - loss: 0.0162 - val_loss: 0.0227\n",
            "Epoch 17/50\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.0160 - val_loss: 0.0223\n",
            "Epoch 18/50\n",
            "24/24 [==============================] - 0s 5ms/step - loss: 0.0157 - val_loss: 0.0221\n",
            "Epoch 19/50\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.0156 - val_loss: 0.0219\n",
            "Epoch 20/50\n",
            "24/24 [==============================] - 0s 5ms/step - loss: 0.0154 - val_loss: 0.0216\n",
            "Epoch 21/50\n",
            "24/24 [==============================] - 0s 5ms/step - loss: 0.0154 - val_loss: 0.0215\n",
            "Epoch 22/50\n",
            "24/24 [==============================] - 0s 5ms/step - loss: 0.0152 - val_loss: 0.0213\n",
            "Epoch 23/50\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.0151 - val_loss: 0.0212\n",
            "Epoch 24/50\n",
            "24/24 [==============================] - 0s 5ms/step - loss: 0.0149 - val_loss: 0.0211\n",
            "Epoch 25/50\n",
            "24/24 [==============================] - 0s 5ms/step - loss: 0.0149 - val_loss: 0.0210\n",
            "Epoch 26/50\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.0148 - val_loss: 0.0208\n",
            "Epoch 27/50\n",
            "24/24 [==============================] - 0s 5ms/step - loss: 0.0147 - val_loss: 0.0206\n",
            "Epoch 28/50\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.0146 - val_loss: 0.0205\n",
            "Epoch 29/50\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.0145 - val_loss: 0.0204\n",
            "Epoch 30/50\n",
            "24/24 [==============================] - 0s 5ms/step - loss: 0.0144 - val_loss: 0.0203\n",
            "Epoch 31/50\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.0144 - val_loss: 0.0200\n",
            "Epoch 32/50\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.0143 - val_loss: 0.0200\n",
            "Epoch 33/50\n",
            "24/24 [==============================] - 0s 5ms/step - loss: 0.0142 - val_loss: 0.0200\n",
            "Epoch 34/50\n",
            "24/24 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.0200\n",
            "Epoch 35/50\n",
            "24/24 [==============================] - 0s 5ms/step - loss: 0.0141 - val_loss: 0.0198\n",
            "Epoch 36/50\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.0198\n",
            "Epoch 37/50\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.0198\n",
            "Epoch 38/50\n",
            "24/24 [==============================] - 0s 5ms/step - loss: 0.0139 - val_loss: 0.0198\n",
            "Epoch 39/50\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0196\n",
            "Epoch 40/50\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0196\n",
            "Epoch 41/50\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.0137 - val_loss: 0.0194\n",
            "Epoch 42/50\n",
            "24/24 [==============================] - 0s 5ms/step - loss: 0.0136 - val_loss: 0.0193\n",
            "Epoch 43/50\n",
            "24/24 [==============================] - 0s 6ms/step - loss: 0.0136 - val_loss: 0.0194\n",
            "Epoch 44/50\n",
            "24/24 [==============================] - 0s 5ms/step - loss: 0.0135 - val_loss: 0.0194\n",
            "Epoch 45/50\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0191\n",
            "Epoch 46/50\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0190\n",
            "Epoch 47/50\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.0134 - val_loss: 0.0190\n",
            "Epoch 48/50\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.0133 - val_loss: 0.0189\n",
            "Epoch 49/50\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0188\n",
            "Epoch 50/50\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0188\n",
            "4/4 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "Epoch 1/50\n",
            "24/24 [==============================] - 3s 29ms/step - loss: 12.1127 - accuracy: 0.2500 - val_loss: 4.5216 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 2.3167 - accuracy: 0.4569 - val_loss: 4.4742 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 1.9038 - accuracy: 0.4828 - val_loss: 4.5203 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 1.7511 - accuracy: 0.5086 - val_loss: 4.5412 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 1.6363 - accuracy: 0.5603 - val_loss: 4.6083 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 1.4940 - accuracy: 0.5862 - val_loss: 5.1944 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 1.4634 - accuracy: 0.5690 - val_loss: 5.1036 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 1.4980 - accuracy: 0.5603 - val_loss: 5.2882 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 1.3291 - accuracy: 0.6121 - val_loss: 5.5321 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 1.3368 - accuracy: 0.6293 - val_loss: 5.4244 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 1.3351 - accuracy: 0.6466 - val_loss: 5.9248 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 1.2427 - accuracy: 0.7069 - val_loss: 5.6383 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 1.1899 - accuracy: 0.6638 - val_loss: 6.1970 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 1.1481 - accuracy: 0.6810 - val_loss: 5.9689 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 1.2107 - accuracy: 0.6810 - val_loss: 6.3983 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 1.1590 - accuracy: 0.6724 - val_loss: 6.0332 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 1.0340 - accuracy: 0.7328 - val_loss: 6.4812 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.9923 - accuracy: 0.7672 - val_loss: 7.5322 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 1.0245 - accuracy: 0.6983 - val_loss: 6.0716 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.9723 - accuracy: 0.7328 - val_loss: 6.4590 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.9932 - accuracy: 0.7155 - val_loss: 5.8376 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.9606 - accuracy: 0.7155 - val_loss: 7.3329 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.9192 - accuracy: 0.7414 - val_loss: 6.7271 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.9180 - accuracy: 0.7500 - val_loss: 6.8321 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.9589 - accuracy: 0.7586 - val_loss: 6.4213 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.7996 - accuracy: 0.7586 - val_loss: 6.5511 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.8002 - accuracy: 0.7759 - val_loss: 6.7550 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.7848 - accuracy: 0.7845 - val_loss: 7.3485 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.7734 - accuracy: 0.7672 - val_loss: 7.1487 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.7160 - accuracy: 0.8190 - val_loss: 7.5507 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.6934 - accuracy: 0.7759 - val_loss: 6.5495 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.7094 - accuracy: 0.7931 - val_loss: 7.0964 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.7018 - accuracy: 0.8103 - val_loss: 6.7830 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.6935 - accuracy: 0.8103 - val_loss: 7.2279 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.6841 - accuracy: 0.8276 - val_loss: 7.4962 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.5943 - accuracy: 0.8017 - val_loss: 7.0597 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.5080 - accuracy: 0.8534 - val_loss: 8.0870 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.5476 - accuracy: 0.8621 - val_loss: 7.1678 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.5047 - accuracy: 0.8448 - val_loss: 7.2241 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.5280 - accuracy: 0.8362 - val_loss: 7.6066 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.6075 - accuracy: 0.8276 - val_loss: 7.9845 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.6422 - accuracy: 0.7931 - val_loss: 8.4103 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.6237 - accuracy: 0.8017 - val_loss: 8.3523 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.5017 - accuracy: 0.8448 - val_loss: 8.7289 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.4433 - accuracy: 0.8621 - val_loss: 7.6117 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.4580 - accuracy: 0.8707 - val_loss: 7.7130 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.2952 - accuracy: 0.9138 - val_loss: 8.4198 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "24/24 [==============================] - 0s 20ms/step - loss: 0.4387 - accuracy: 0.8621 - val_loss: 10.0190 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.4438 - accuracy: 0.8793 - val_loss: 9.2897 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "24/24 [==============================] - 0s 19ms/step - loss: 0.5057 - accuracy: 0.8448 - val_loss: 9.2684 - val_accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.5774 - accuracy: 0.6667\n",
            "Test Accuracy: 0.6666666865348816\n",
            "1/1 [==============================] - 0s 98ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1mj72FYTToww",
        "outputId": "efe81917-abdb-41d8-e792-7229f29210bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-5cebff69f354>:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  testinp5['pleaf']=predicted_labels\n"
          ]
        }
      ],
      "source": [
        "#52\n",
        "# Display predicted labels\n",
        "\n",
        "file_path = 'testinp5.csv'\n",
        "\n",
        "\n",
        "# Display predicted labels\n",
        "testinp5['pleaf']=predicted_labels\n",
        "# Save the modified 'test' DataFrame to a CSV file without the DataFrame index\n",
        "testinp5.to_csv(file_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qN8oT_VJToww",
        "outputId": "ae7f66a0-a7b6-40f4-ed70-b97a090a1592",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10042"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "# Model for category  'GPS & Navigation'\n",
        "import gc\n",
        "gc.collect()\n",
        "#encoded_labels_train, encoded_labels_test, encoded_labels_val,label_encoder1=encode_labels(inp6['leaf'],testinp6['leaf'],val6['leaf'])\n",
        "#len(label_encoder1.classes_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p-Sj1eWwToww",
        "outputId": "f8b2a18d-bd16-4451-bc26-821f87399ab7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result of Camera & Photo:\n",
            "(497, 4145)\n",
            "(510, 4145)\n",
            "Epoch 1/50\n",
            "100/100 [==============================] - 2s 5ms/step - loss: 0.2761 - val_loss: 0.0216\n",
            "Epoch 2/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0140 - val_loss: 0.0126\n",
            "Epoch 3/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0111 - val_loss: 0.0112\n",
            "Epoch 4/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0103 - val_loss: 0.0107\n",
            "Epoch 5/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0098 - val_loss: 0.0105\n",
            "Epoch 6/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0095 - val_loss: 0.0104\n",
            "Epoch 7/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0092 - val_loss: 0.0104\n",
            "Epoch 8/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0090 - val_loss: 0.0104\n",
            "Epoch 9/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0089 - val_loss: 0.0104\n",
            "Epoch 10/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0088 - val_loss: 0.0105\n",
            "Epoch 11/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0087 - val_loss: 0.0105\n",
            "Epoch 12/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0087 - val_loss: 0.0104\n",
            "Epoch 13/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0086 - val_loss: 0.0105\n",
            "Epoch 14/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0085 - val_loss: 0.0104\n",
            "Epoch 15/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0085 - val_loss: 0.0105\n",
            "Epoch 16/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.0104\n",
            "Epoch 17/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0084 - val_loss: 0.0106\n",
            "Epoch 18/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0083 - val_loss: 0.0104\n",
            "Epoch 19/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0082 - val_loss: 0.0103\n",
            "Epoch 20/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0081 - val_loss: 0.0101\n",
            "Epoch 21/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0081 - val_loss: 0.0102\n",
            "Epoch 22/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0080 - val_loss: 0.0101\n",
            "Epoch 23/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0079 - val_loss: 0.0102\n",
            "Epoch 24/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0078 - val_loss: 0.0102\n",
            "Epoch 25/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0077 - val_loss: 0.0101\n",
            "Epoch 26/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0076 - val_loss: 0.0098\n",
            "Epoch 27/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0075 - val_loss: 0.0099\n",
            "Epoch 28/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0074 - val_loss: 0.0099\n",
            "Epoch 29/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0073 - val_loss: 0.0098\n",
            "Epoch 30/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0071 - val_loss: 0.0099\n",
            "Epoch 31/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0071 - val_loss: 0.0100\n",
            "Epoch 32/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0069 - val_loss: 0.0097\n",
            "Epoch 33/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0068 - val_loss: 0.0096\n",
            "Epoch 34/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0067 - val_loss: 0.0095\n",
            "Epoch 35/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0066 - val_loss: 0.0095\n",
            "Epoch 36/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0065 - val_loss: 0.0093\n",
            "Epoch 37/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0064 - val_loss: 0.0094\n",
            "Epoch 38/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0063 - val_loss: 0.0094\n",
            "Epoch 39/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0061 - val_loss: 0.0095\n",
            "Epoch 40/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0060 - val_loss: 0.0092\n",
            "Epoch 41/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0059 - val_loss: 0.0092\n",
            "Epoch 42/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0058 - val_loss: 0.0090\n",
            "Epoch 43/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0057 - val_loss: 0.0089\n",
            "Epoch 44/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0056 - val_loss: 0.0088\n",
            "Epoch 45/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0055 - val_loss: 0.0088\n",
            "Epoch 46/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0054 - val_loss: 0.0088\n",
            "Epoch 47/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0053 - val_loss: 0.0087\n",
            "Epoch 48/50\n",
            "100/100 [==============================] - 0s 4ms/step - loss: 0.0052 - val_loss: 0.0087\n",
            "Epoch 49/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0085\n",
            "Epoch 50/50\n",
            "100/100 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0083\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7a754cfdc1f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16/16 [==============================] - 0s 2ms/step\n",
            "16/16 [==============================] - 0s 1ms/step\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 1/70\n",
            "100/100 [==============================] - 4s 21ms/step - loss: 4.4754 - accuracy: 0.0966 - val_loss: 4.9665 - val_accuracy: 0.0169\n",
            "Epoch 2/70\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 3.2600 - accuracy: 0.2173 - val_loss: 5.4039 - val_accuracy: 0.0678\n",
            "Epoch 3/70\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 2.7272 - accuracy: 0.3682 - val_loss: 5.7944 - val_accuracy: 0.0847\n",
            "Epoch 4/70\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 2.4319 - accuracy: 0.3944 - val_loss: 6.5268 - val_accuracy: 0.0847\n",
            "Epoch 5/70\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 2.1266 - accuracy: 0.4708 - val_loss: 6.3635 - val_accuracy: 0.1356\n",
            "Epoch 6/70\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 1.9605 - accuracy: 0.4970 - val_loss: 7.9856 - val_accuracy: 0.0678\n",
            "Epoch 7/70\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 1.8781 - accuracy: 0.5231 - val_loss: 6.6069 - val_accuracy: 0.1356\n",
            "Epoch 8/70\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 1.7653 - accuracy: 0.5453 - val_loss: 6.3936 - val_accuracy: 0.1017\n",
            "Epoch 9/70\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 1.6270 - accuracy: 0.5614 - val_loss: 6.9436 - val_accuracy: 0.1186\n",
            "Epoch 10/70\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 1.4113 - accuracy: 0.6117 - val_loss: 9.0172 - val_accuracy: 0.0847\n",
            "Epoch 11/70\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 1.3717 - accuracy: 0.6278 - val_loss: 6.5358 - val_accuracy: 0.1186\n",
            "Epoch 12/70\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 1.3071 - accuracy: 0.6479 - val_loss: 9.3579 - val_accuracy: 0.1017\n",
            "Epoch 13/70\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 1.2093 - accuracy: 0.6600 - val_loss: 7.9938 - val_accuracy: 0.1356\n",
            "Epoch 14/70\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 1.1815 - accuracy: 0.6922 - val_loss: 9.2752 - val_accuracy: 0.1186\n",
            "Epoch 15/70\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 1.0900 - accuracy: 0.6942 - val_loss: 7.8683 - val_accuracy: 0.1017\n",
            "Epoch 16/70\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 1.0740 - accuracy: 0.7042 - val_loss: 9.9982 - val_accuracy: 0.1186\n",
            "Epoch 17/70\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 1.0587 - accuracy: 0.7103 - val_loss: 9.0111 - val_accuracy: 0.1356\n",
            "Epoch 18/70\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 0.9424 - accuracy: 0.7344 - val_loss: 9.1113 - val_accuracy: 0.1186\n",
            "Epoch 19/70\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 0.9988 - accuracy: 0.7082 - val_loss: 8.6723 - val_accuracy: 0.1356\n",
            "Epoch 20/70\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 1.0319 - accuracy: 0.7183 - val_loss: 9.1009 - val_accuracy: 0.1017\n",
            "Epoch 21/70\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.8160 - accuracy: 0.7525 - val_loss: 10.3521 - val_accuracy: 0.1017\n",
            "Epoch 22/70\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 0.8942 - accuracy: 0.7485 - val_loss: 11.3043 - val_accuracy: 0.0847\n",
            "Epoch 23/70\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 0.8223 - accuracy: 0.7586 - val_loss: 9.3342 - val_accuracy: 0.1186\n",
            "Epoch 24/70\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.7897 - accuracy: 0.7746 - val_loss: 10.3474 - val_accuracy: 0.1356\n",
            "Epoch 25/70\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.7311 - accuracy: 0.7746 - val_loss: 11.3141 - val_accuracy: 0.1017\n",
            "Epoch 26/70\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.7748 - accuracy: 0.7827 - val_loss: 10.1352 - val_accuracy: 0.1186\n",
            "Epoch 27/70\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.7802 - accuracy: 0.7827 - val_loss: 10.4815 - val_accuracy: 0.1356\n",
            "Epoch 28/70\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.7363 - accuracy: 0.7847 - val_loss: 11.6508 - val_accuracy: 0.1186\n",
            "Epoch 29/70\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.6758 - accuracy: 0.7867 - val_loss: 11.9759 - val_accuracy: 0.0847\n",
            "Epoch 30/70\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.6745 - accuracy: 0.8008 - val_loss: 11.9035 - val_accuracy: 0.1017\n",
            "Epoch 31/70\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.7438 - accuracy: 0.7907 - val_loss: 12.1275 - val_accuracy: 0.1186\n",
            "Epoch 32/70\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.6827 - accuracy: 0.7907 - val_loss: 10.9276 - val_accuracy: 0.1356\n",
            "Epoch 33/70\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.6615 - accuracy: 0.8008 - val_loss: 12.0595 - val_accuracy: 0.1186\n",
            "Epoch 34/70\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.7107 - accuracy: 0.7887 - val_loss: 9.6644 - val_accuracy: 0.1186\n",
            "Epoch 35/70\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.5898 - accuracy: 0.8169 - val_loss: 10.9298 - val_accuracy: 0.1017\n",
            "Epoch 36/70\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.7750 - accuracy: 0.7807 - val_loss: 11.7773 - val_accuracy: 0.1017\n",
            "Epoch 37/70\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.5004 - accuracy: 0.8431 - val_loss: 11.5681 - val_accuracy: 0.0847\n",
            "Epoch 38/70\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.5418 - accuracy: 0.8330 - val_loss: 12.1143 - val_accuracy: 0.1017\n",
            "Epoch 39/70\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.5080 - accuracy: 0.8652 - val_loss: 11.3726 - val_accuracy: 0.0847\n",
            "Epoch 40/70\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.6274 - accuracy: 0.8169 - val_loss: 10.6524 - val_accuracy: 0.1356\n",
            "Epoch 41/70\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.4514 - accuracy: 0.8471 - val_loss: 11.8553 - val_accuracy: 0.1186\n",
            "Epoch 42/70\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.5571 - accuracy: 0.8330 - val_loss: 10.8584 - val_accuracy: 0.1017\n",
            "Epoch 43/70\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.6194 - accuracy: 0.8290 - val_loss: 11.3105 - val_accuracy: 0.1186\n",
            "Epoch 44/70\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.4598 - accuracy: 0.8551 - val_loss: 11.8920 - val_accuracy: 0.0847\n",
            "Epoch 45/70\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.5319 - accuracy: 0.8531 - val_loss: 12.3070 - val_accuracy: 0.1017\n",
            "Epoch 46/70\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.5709 - accuracy: 0.8330 - val_loss: 10.8320 - val_accuracy: 0.1186\n",
            "Epoch 47/70\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.6010 - accuracy: 0.8270 - val_loss: 10.8470 - val_accuracy: 0.1017\n",
            "Epoch 48/70\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.4850 - accuracy: 0.8592 - val_loss: 12.2096 - val_accuracy: 0.0847\n",
            "Epoch 49/70\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.5039 - accuracy: 0.8571 - val_loss: 11.4803 - val_accuracy: 0.1017\n",
            "Epoch 50/70\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.4710 - accuracy: 0.8692 - val_loss: 11.5237 - val_accuracy: 0.0847\n",
            "Epoch 51/70\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.4535 - accuracy: 0.8732 - val_loss: 12.8339 - val_accuracy: 0.1017\n",
            "Epoch 52/70\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.4834 - accuracy: 0.8471 - val_loss: 11.7123 - val_accuracy: 0.0847\n",
            "Epoch 53/70\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.5076 - accuracy: 0.8571 - val_loss: 10.9447 - val_accuracy: 0.0847\n",
            "Epoch 54/70\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.4451 - accuracy: 0.8410 - val_loss: 14.2032 - val_accuracy: 0.1017\n",
            "Epoch 55/70\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 0.5312 - accuracy: 0.8551 - val_loss: 12.7517 - val_accuracy: 0.1017\n",
            "Epoch 56/70\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 0.4887 - accuracy: 0.8451 - val_loss: 13.1861 - val_accuracy: 0.1186\n",
            "Epoch 57/70\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 0.4680 - accuracy: 0.8692 - val_loss: 11.1572 - val_accuracy: 0.1017\n",
            "Epoch 58/70\n",
            "100/100 [==============================] - 2s 18ms/step - loss: 0.4875 - accuracy: 0.8491 - val_loss: 14.2696 - val_accuracy: 0.1017\n",
            "Epoch 59/70\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.3912 - accuracy: 0.8571 - val_loss: 12.5352 - val_accuracy: 0.1017\n",
            "Epoch 60/70\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.4049 - accuracy: 0.8893 - val_loss: 10.9228 - val_accuracy: 0.1017\n",
            "Epoch 61/70\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.3887 - accuracy: 0.8793 - val_loss: 11.1101 - val_accuracy: 0.1017\n",
            "Epoch 62/70\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.4363 - accuracy: 0.8813 - val_loss: 12.5597 - val_accuracy: 0.0847\n",
            "Epoch 63/70\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.4079 - accuracy: 0.8773 - val_loss: 11.4111 - val_accuracy: 0.1186\n",
            "Epoch 64/70\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.4103 - accuracy: 0.8813 - val_loss: 13.1724 - val_accuracy: 0.1017\n",
            "Epoch 65/70\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.4893 - accuracy: 0.8431 - val_loss: 13.6864 - val_accuracy: 0.0847\n",
            "Epoch 66/70\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.3492 - accuracy: 0.8954 - val_loss: 13.7134 - val_accuracy: 0.0847\n",
            "Epoch 67/70\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.3417 - accuracy: 0.8853 - val_loss: 13.0824 - val_accuracy: 0.0847\n",
            "Epoch 68/70\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.5465 - accuracy: 0.8753 - val_loss: 11.3062 - val_accuracy: 0.1017\n",
            "Epoch 69/70\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.3224 - accuracy: 0.9034 - val_loss: 13.3227 - val_accuracy: 0.0847\n",
            "Epoch 70/70\n",
            "100/100 [==============================] - 2s 19ms/step - loss: 0.4904 - accuracy: 0.8712 - val_loss: 10.7709 - val_accuracy: 0.1186\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 2.1680 - accuracy: 0.6373\n",
            "Test Accuracy: 0.6372548937797546\n",
            "16/16 [==============================] - 0s 9ms/step\n"
          ]
        }
      ],
      "source": [
        "# Model for category  'Camera & Photo'\n",
        "\n",
        "print('Result of Camera & Photo:')\n",
        "\n",
        "if len(testinp6)!=0:\n",
        "    encoded_labels_train, encoded_labels_test, encoded_labels_val,label_encoder=encode_labels(inp6['leaf'],testinp6['leaf'],val6['leaf'])\n",
        "    X_train_leaf,X_test_leaf,X_val_leaf=tf_idf_vectorization(inp6,testinp6,val6)\n",
        "    X_train_encoded,X_test_encoded,X_val_encoded=train_denoising_autoencoder(X_train_leaf, X_test_leaf, X_val_leaf)\n",
        "    input_dim_dbn = X_train_encoded.shape[1]\n",
        "    #test images loading\n",
        "    X_test_img=Load_images(testinp6)\n",
        "    X_train_img=Load_images(inp6)\n",
        "    X_val_img=Load_images(val6)\n",
        "    input_dim_dbn = X_train_encoded.shape[1]\n",
        "    num_classes = 111 # Set the input dimensions based on the DBN input shape\n",
        "    ep=70\n",
        "    size=5\n",
        "    model= cnn_dbn(num_classes,X_train_img,X_train_encoded,encoded_labels_train,ep,size,X_val_img,X_val_encoded,encoded_labels_val)\n",
        "\n",
        "    # Evaluate the multi-modal model\n",
        "    loss, accuracy = model.evaluate([X_test_img, X_test_encoded], encoded_labels_test)\n",
        "    print(f'Test Accuracy: {accuracy}')\n",
        "    predicted_probabilities= model.predict([X_test_img, X_test_encoded])\n",
        "    # Convert probabilities to class indices (argmax to get the index of the highest probability)\n",
        "    predicted_class_indices = np.argmax(predicted_probabilities, axis=1)\n",
        "\n",
        "    # Convert class indices back to original labels using inverse_transform of label_encoder\n",
        "    predicted_labels = label_encoder.inverse_transform(predicted_class_indices)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "seieQGihToww",
        "outputId": "4b00a5fd-9f46-4b81-ecef-db3555cd2682",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-40-53c8077c66e0>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  testinp6['pleaf']=predicted_labels\n"
          ]
        }
      ],
      "source": [
        "#61\n",
        "file_path = 'testinp6.csv'\n",
        "# Display predicted labels\n",
        "testinp6['pleaf']=predicted_labels\n",
        "# Save the modified 'test' DataFrame to a CSV file without the DataFrame index\n",
        "testinp6.to_csv(file_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FGxkRQtOToww",
        "outputId": "1dd4f8d8-d495-45c9-c5cc-4b347f5acbd4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "74"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "# Model for category  'GPS & Navigation'\n",
        "import gc\n",
        "gc.collect()\n",
        "encoded_labels_train, encoded_labels_test, encoded_labels_val,label_encoder1=encode_labels(inp7['leaf'],testinp7['leaf'],val7['leaf'])\n",
        "len(label_encoder1.classes_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yhPbHUKLToww",
        "outputId": "789cdce1-7a82-4cab-a840-aa66bf025c46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Result of Portable Audio & Video:\n",
            "(328, 3413)\n",
            "(206, 3413)\n",
            "Epoch 1/50\n",
            "66/66 [==============================] - 1s 7ms/step - loss: 0.3634 - val_loss: 0.0729\n",
            "Epoch 2/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.0234 - val_loss: 0.0287\n",
            "Epoch 3/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.0169 - val_loss: 0.0227\n",
            "Epoch 4/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.0151 - val_loss: 0.0205\n",
            "Epoch 5/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.0145 - val_loss: 0.0195\n",
            "Epoch 6/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.0139 - val_loss: 0.0188\n",
            "Epoch 7/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.0135 - val_loss: 0.0182\n",
            "Epoch 8/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.0131 - val_loss: 0.0179\n",
            "Epoch 9/50\n",
            "66/66 [==============================] - 0s 6ms/step - loss: 0.0129 - val_loss: 0.0174\n",
            "Epoch 10/50\n",
            "66/66 [==============================] - 0s 5ms/step - loss: 0.0127 - val_loss: 0.0170\n",
            "Epoch 11/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.0125 - val_loss: 0.0170\n",
            "Epoch 12/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0164\n",
            "Epoch 13/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0161\n",
            "Epoch 14/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.0158\n",
            "Epoch 15/50\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.0121 - val_loss: 0.0158\n",
            "Epoch 16/50\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.0120 - val_loss: 0.0154\n",
            "Epoch 17/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.0120 - val_loss: 0.0152\n",
            "Epoch 18/50\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.0152\n",
            "Epoch 19/50\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.0118 - val_loss: 0.0149\n",
            "Epoch 20/50\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.0148\n",
            "Epoch 21/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0147\n",
            "Epoch 22/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.0116 - val_loss: 0.0146\n",
            "Epoch 23/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.0115 - val_loss: 0.0144\n",
            "Epoch 24/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.0114 - val_loss: 0.0142\n",
            "Epoch 25/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.0113 - val_loss: 0.0140\n",
            "Epoch 26/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.0112 - val_loss: 0.0139\n",
            "Epoch 27/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.0111 - val_loss: 0.0139\n",
            "Epoch 28/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.0111 - val_loss: 0.0139\n",
            "Epoch 29/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.0110 - val_loss: 0.0136\n",
            "Epoch 30/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.0135\n",
            "Epoch 31/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.0108 - val_loss: 0.0135\n",
            "Epoch 32/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.0106 - val_loss: 0.0134\n",
            "Epoch 33/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.0131\n",
            "Epoch 34/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.0105 - val_loss: 0.0131\n",
            "Epoch 35/50\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.0103 - val_loss: 0.0131\n",
            "Epoch 36/50\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.0102 - val_loss: 0.0131\n",
            "Epoch 37/50\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.0101 - val_loss: 0.0126\n",
            "Epoch 38/50\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.0100 - val_loss: 0.0127\n",
            "Epoch 39/50\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.0099 - val_loss: 0.0127\n",
            "Epoch 40/50\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.0098 - val_loss: 0.0126\n",
            "Epoch 41/50\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.0097 - val_loss: 0.0125\n",
            "Epoch 42/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.0096 - val_loss: 0.0124\n",
            "Epoch 43/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.0094 - val_loss: 0.0122\n",
            "Epoch 44/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.0093 - val_loss: 0.0119\n",
            "Epoch 45/50\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0120\n",
            "Epoch 46/50\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0119\n",
            "Epoch 47/50\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.0090 - val_loss: 0.0115\n",
            "Epoch 48/50\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.0089 - val_loss: 0.0115\n",
            "Epoch 49/50\n",
            "66/66 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.0116\n",
            "Epoch 50/50\n",
            "66/66 [==============================] - 0s 4ms/step - loss: 0.0087 - val_loss: 0.0114\n",
            "11/11 [==============================] - 0s 2ms/step\n",
            "7/7 [==============================] - 0s 2ms/step\n",
            "2/2 [==============================] - 0s 4ms/step\n",
            "Epoch 1/50\n",
            "66/66 [==============================] - 4s 22ms/step - loss: 5.6232 - accuracy: 0.1494 - val_loss: 5.2221 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "66/66 [==============================] - 1s 18ms/step - loss: 2.9173 - accuracy: 0.2409 - val_loss: 5.1177 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "66/66 [==============================] - 1s 18ms/step - loss: 2.5804 - accuracy: 0.2957 - val_loss: 5.2469 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "66/66 [==============================] - 1s 18ms/step - loss: 2.2624 - accuracy: 0.3933 - val_loss: 5.7037 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "66/66 [==============================] - 1s 18ms/step - loss: 2.1103 - accuracy: 0.4116 - val_loss: 5.5819 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "66/66 [==============================] - 1s 18ms/step - loss: 1.8749 - accuracy: 0.4695 - val_loss: 6.0494 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "66/66 [==============================] - 1s 18ms/step - loss: 1.6821 - accuracy: 0.5274 - val_loss: 5.2785 - val_accuracy: 0.0417\n",
            "Epoch 8/50\n",
            "66/66 [==============================] - 1s 19ms/step - loss: 1.5429 - accuracy: 0.5518 - val_loss: 6.5224 - val_accuracy: 0.0208\n",
            "Epoch 9/50\n",
            "66/66 [==============================] - 1s 19ms/step - loss: 1.3844 - accuracy: 0.5945 - val_loss: 6.8742 - val_accuracy: 0.0208\n",
            "Epoch 10/50\n",
            "66/66 [==============================] - 1s 18ms/step - loss: 1.2330 - accuracy: 0.6585 - val_loss: 6.9196 - val_accuracy: 0.0208\n",
            "Epoch 11/50\n",
            "66/66 [==============================] - 1s 18ms/step - loss: 1.2092 - accuracy: 0.6311 - val_loss: 7.0461 - val_accuracy: 0.0417\n",
            "Epoch 12/50\n",
            "66/66 [==============================] - 1s 18ms/step - loss: 1.0700 - accuracy: 0.7012 - val_loss: 7.6281 - val_accuracy: 0.0208\n",
            "Epoch 13/50\n",
            "66/66 [==============================] - 1s 19ms/step - loss: 1.0055 - accuracy: 0.7073 - val_loss: 7.9984 - val_accuracy: 0.0208\n",
            "Epoch 14/50\n",
            "66/66 [==============================] - 1s 18ms/step - loss: 1.0062 - accuracy: 0.7165 - val_loss: 6.5611 - val_accuracy: 0.0208\n",
            "Epoch 15/50\n",
            "66/66 [==============================] - 1s 18ms/step - loss: 0.9587 - accuracy: 0.7256 - val_loss: 7.0407 - val_accuracy: 0.0208\n",
            "Epoch 16/50\n",
            "66/66 [==============================] - 1s 18ms/step - loss: 0.8891 - accuracy: 0.7348 - val_loss: 8.9967 - val_accuracy: 0.0417\n",
            "Epoch 17/50\n",
            "66/66 [==============================] - 1s 18ms/step - loss: 0.8258 - accuracy: 0.7530 - val_loss: 6.6505 - val_accuracy: 0.0417\n",
            "Epoch 18/50\n",
            "66/66 [==============================] - 1s 18ms/step - loss: 0.7595 - accuracy: 0.7744 - val_loss: 7.7100 - val_accuracy: 0.0208\n",
            "Epoch 19/50\n",
            "66/66 [==============================] - 1s 19ms/step - loss: 0.6784 - accuracy: 0.8232 - val_loss: 6.8786 - val_accuracy: 0.0417\n",
            "Epoch 20/50\n",
            "66/66 [==============================] - 1s 18ms/step - loss: 0.6502 - accuracy: 0.8049 - val_loss: 7.5170 - val_accuracy: 0.0417\n",
            "Epoch 21/50\n",
            "66/66 [==============================] - 1s 18ms/step - loss: 0.6255 - accuracy: 0.8110 - val_loss: 7.6172 - val_accuracy: 0.0417\n",
            "Epoch 22/50\n",
            "66/66 [==============================] - 1s 18ms/step - loss: 0.6551 - accuracy: 0.8171 - val_loss: 8.0069 - val_accuracy: 0.0417\n",
            "Epoch 23/50\n",
            "66/66 [==============================] - 1s 18ms/step - loss: 0.5371 - accuracy: 0.8415 - val_loss: 7.9704 - val_accuracy: 0.0417\n",
            "Epoch 24/50\n",
            "66/66 [==============================] - 1s 18ms/step - loss: 0.5985 - accuracy: 0.8201 - val_loss: 7.6359 - val_accuracy: 0.0417\n",
            "Epoch 25/50\n",
            "66/66 [==============================] - 1s 18ms/step - loss: 0.5696 - accuracy: 0.8445 - val_loss: 8.3148 - val_accuracy: 0.0208\n",
            "Epoch 26/50\n",
            "66/66 [==============================] - 1s 18ms/step - loss: 0.5464 - accuracy: 0.8384 - val_loss: 7.3811 - val_accuracy: 0.0208\n",
            "Epoch 27/50\n",
            "66/66 [==============================] - 1s 18ms/step - loss: 0.5310 - accuracy: 0.8415 - val_loss: 10.0751 - val_accuracy: 0.0208\n",
            "Epoch 28/50\n",
            "66/66 [==============================] - 1s 18ms/step - loss: 0.5819 - accuracy: 0.8110 - val_loss: 8.5391 - val_accuracy: 0.0417\n",
            "Epoch 29/50\n",
            "66/66 [==============================] - 1s 19ms/step - loss: 0.4863 - accuracy: 0.8354 - val_loss: 9.8323 - val_accuracy: 0.0417\n",
            "Epoch 30/50\n",
            "66/66 [==============================] - 1s 19ms/step - loss: 0.5370 - accuracy: 0.8293 - val_loss: 8.9795 - val_accuracy: 0.0208\n",
            "Epoch 31/50\n",
            "66/66 [==============================] - 1s 18ms/step - loss: 0.4930 - accuracy: 0.8659 - val_loss: 8.1713 - val_accuracy: 0.0417\n",
            "Epoch 32/50\n",
            "66/66 [==============================] - 1s 18ms/step - loss: 0.4148 - accuracy: 0.8720 - val_loss: 8.5678 - val_accuracy: 0.0417\n",
            "Epoch 33/50\n",
            "66/66 [==============================] - 1s 18ms/step - loss: 0.4523 - accuracy: 0.8567 - val_loss: 8.7552 - val_accuracy: 0.0417\n",
            "Epoch 34/50\n",
            "66/66 [==============================] - 1s 18ms/step - loss: 0.4569 - accuracy: 0.8598 - val_loss: 8.5627 - val_accuracy: 0.0417\n",
            "Epoch 35/50\n",
            "66/66 [==============================] - 1s 18ms/step - loss: 0.5161 - accuracy: 0.8506 - val_loss: 8.5498 - val_accuracy: 0.0208\n",
            "Epoch 36/50\n",
            "66/66 [==============================] - 1s 18ms/step - loss: 0.5569 - accuracy: 0.8384 - val_loss: 9.6679 - val_accuracy: 0.0417\n",
            "Epoch 37/50\n",
            "66/66 [==============================] - 1s 18ms/step - loss: 0.4543 - accuracy: 0.8598 - val_loss: 10.6527 - val_accuracy: 0.0208\n",
            "Epoch 38/50\n",
            "66/66 [==============================] - 1s 18ms/step - loss: 0.4904 - accuracy: 0.8537 - val_loss: 8.4570 - val_accuracy: 0.0208\n",
            "Epoch 39/50\n",
            "66/66 [==============================] - 1s 19ms/step - loss: 0.4722 - accuracy: 0.8445 - val_loss: 9.2653 - val_accuracy: 0.0208\n",
            "Epoch 40/50\n",
            "66/66 [==============================] - 1s 18ms/step - loss: 0.5187 - accuracy: 0.8476 - val_loss: 10.7567 - val_accuracy: 0.0208\n",
            "Epoch 41/50\n",
            "66/66 [==============================] - 1s 19ms/step - loss: 0.4645 - accuracy: 0.8354 - val_loss: 10.1838 - val_accuracy: 0.0208\n",
            "Epoch 42/50\n",
            "66/66 [==============================] - 1s 18ms/step - loss: 0.4626 - accuracy: 0.8598 - val_loss: 9.1987 - val_accuracy: 0.0208\n",
            "Epoch 43/50\n",
            "66/66 [==============================] - 1s 18ms/step - loss: 0.4117 - accuracy: 0.8689 - val_loss: 10.0428 - val_accuracy: 0.0208\n",
            "Epoch 44/50\n",
            "66/66 [==============================] - 1s 18ms/step - loss: 0.3444 - accuracy: 0.8872 - val_loss: 13.5440 - val_accuracy: 0.0208\n",
            "Epoch 45/50\n",
            "66/66 [==============================] - 1s 18ms/step - loss: 0.3659 - accuracy: 0.8963 - val_loss: 9.7808 - val_accuracy: 0.0417\n",
            "Epoch 46/50\n",
            "66/66 [==============================] - 1s 18ms/step - loss: 0.4885 - accuracy: 0.8598 - val_loss: 8.8127 - val_accuracy: 0.0208\n",
            "Epoch 47/50\n",
            "66/66 [==============================] - 1s 18ms/step - loss: 0.3981 - accuracy: 0.8780 - val_loss: 8.3293 - val_accuracy: 0.0208\n",
            "Epoch 48/50\n",
            "66/66 [==============================] - 1s 18ms/step - loss: 0.4475 - accuracy: 0.8659 - val_loss: 9.3531 - val_accuracy: 0.0417\n",
            "Epoch 49/50\n",
            "66/66 [==============================] - 1s 18ms/step - loss: 0.3588 - accuracy: 0.8780 - val_loss: 8.8971 - val_accuracy: 0.0417\n",
            "Epoch 50/50\n",
            "66/66 [==============================] - 1s 18ms/step - loss: 0.3884 - accuracy: 0.8933 - val_loss: 10.2789 - val_accuracy: 0.0208\n",
            "7/7 [==============================] - 0s 10ms/step - loss: 2.1759 - accuracy: 0.7233\n",
            "Test Accuracy: 0.7233009934425354\n",
            "7/7 [==============================] - 0s 9ms/step\n"
          ]
        }
      ],
      "source": [
        "# Model for category  'Portable Audio & Video'\n",
        "\n",
        "print(' Result of Portable Audio & Video:')\n",
        "\n",
        "if len(testinp7)!=0:\n",
        "    encoded_labels_train, encoded_labels_test, encoded_labels_val,label_encoder=encode_labels(inp7['leaf'],testinp7['leaf'],val7['leaf'])\n",
        "    X_train_leaf,X_test_leaf,X_val_leaf=tf_idf_vectorization(inp7,testinp7,val7)\n",
        "    X_train_encoded,X_test_encoded,X_val_encoded=train_denoising_autoencoder(X_train_leaf, X_test_leaf, X_val_leaf)\n",
        "    input_dim_dbn = X_train_encoded.shape[1]\n",
        "    #test images loading\n",
        "    X_test_img=Load_images(testinp7)\n",
        "    X_train_img=Load_images(inp7)\n",
        "    X_val_img=Load_images(val7)\n",
        "    input_dim_dbn = X_train_encoded.shape[1]\n",
        "    num_classes = 74 # Set the input dimensions based on the DBN input shape\n",
        "    ep=50\n",
        "    size=5\n",
        "    model= cnn_dbn(num_classes,X_train_img,X_train_encoded,encoded_labels_train,ep,size,X_val_img,X_val_encoded,encoded_labels_val)\n",
        "\n",
        "    # Evaluate the multi-modal model\n",
        "    loss, accuracy = model.evaluate([X_test_img, X_test_encoded], encoded_labels_test)\n",
        "    print(f'Test Accuracy: {accuracy}')\n",
        "    predicted_probabilities= model.predict([X_test_img, X_test_encoded])\n",
        "    # Convert probabilities to class indices (argmax to get the index of the highest probability)\n",
        "    predicted_class_indices = np.argmax(predicted_probabilities, axis=1)\n",
        "\n",
        "    # Convert class indices back to original labels using inverse_transform of label_encoder\n",
        "    predicted_labels = label_encoder.inverse_transform(predicted_class_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "isBIdG7kTowx",
        "outputId": "9d2bd93b-c9c7-485d-cc12-ab3de5b0b7ca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-45-231a206e7c70>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  testinp7['pleaf']=predicted_labels\n"
          ]
        }
      ],
      "source": [
        "#755\n",
        "file_path = 'testinp7.csv'\n",
        "# Display predicted labels\n",
        "testinp7['pleaf']=predicted_labels\n",
        "# Save the modified 'test' DataFrame to a CSV file without the DataFrame index\n",
        "testinp7.to_csv(file_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zMa5fmdhTowx",
        "outputId": "b53caa02-39b6-4359-bff6-421e73a094f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "# Model for category  'GPS & Navigation'\n",
        "import gc\n",
        "gc.collect()\n",
        "encoded_labels_train, encoded_labels_test, encoded_labels_val,label_encoder1=encode_labels(inp8['leaf'],testinp8['leaf'],val8['leaf'])\n",
        "len(label_encoder1.classes_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "diM-QNAtTowx",
        "outputId": "7d02b18d-5737-4a4f-82cf-e9816837aa93",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Result of Cell Phones & Accessories:\n"
          ]
        }
      ],
      "source": [
        "# Model for category  'Cell Phones & Accessories'\n",
        "\n",
        "print(' Result of Cell Phones & Accessories:')\n",
        "\n",
        "if len(testinp8)!=0:\n",
        "    encoded_labels_train, encoded_labels_test, encoded_labels_val,label_encoder=encode_labels(inp8['leaf'],testinp8['leaf'],val8['leaf'])\n",
        "    X_train_leaf,X_test_leaf,X_val_leaf=tf_idf_vectorization(inp8,testinp8,val8)\n",
        "    X_train_encoded,X_test_encoded,X_val_encoded=train_denoising_autoencoder(X_train_leaf, X_test_leaf, X_val_leaf)\n",
        "    input_dim_dbn = X_train_encoded.shape[1]\n",
        "    #test images loading\n",
        "    X_test_img=Load_images(testinp8)\n",
        "    X_train_img=Load_images(inp8)\n",
        "    X_val_img=Load_images(val8)\n",
        "    input_dim_dbn = X_train_encoded.shape[1]\n",
        "    num_classes = 5 # Set the input dimensions based on the DBN input shape\n",
        "    ep=50\n",
        "    size=5\n",
        "    model= cnn_dbn(num_classes,X_train_img,X_train_encoded,encoded_labels_train,ep,size,X_val_img,X_val_encoded,encoded_labels_val)\n",
        "\n",
        "    # Evaluate the multi-modal model\n",
        "    loss, accuracy = model.evaluate([X_test_img, X_test_encoded], encoded_labels_test)\n",
        "    print(f'Test Accuracy: {accuracy}')\n",
        "    predicted_probabilities= model.predict([X_test_img, X_test_encoded])\n",
        "    # Convert probabilities to class indices (argmax to get the index of the highest probability)\n",
        "    predicted_class_indices = np.argmax(predicted_probabilities, axis=1)\n",
        "\n",
        "    # Convert class indices back to original labels using inverse_transform of label_encoder\n",
        "    predicted_labels = label_encoder.inverse_transform(predicted_class_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMjHnM5iTowx",
        "outputId": "0ebe87e1-0944-4cee-b3a8-a5e24f8ad1f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-55-ae08a69dfee8>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  testinp8['pleaf']=predicted_labels\n"
          ]
        }
      ],
      "source": [
        "\n",
        "file_path = 'testinp8.csv'\n",
        "# Display predicted labels\n",
        "testinp8['pleaf']=predicted_labels\n",
        "# Save the modified 'test' DataFrame to a CSV file without the DataFrame index\n",
        "testinp8.to_csv(file_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K8ARDT-CTowx",
        "outputId": "03b86a32-98dd-4f2e-ae27-a1bd02d63c45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "# Model for category  'GPS & Navigation'\n",
        "import gc\n",
        "gc.collect()\n",
        "encoded_labels_train, encoded_labels_test, encoded_labels_val,label_encoder1=encode_labels(inp9['leaf'],testinp9['leaf'],val9['leaf'])\n",
        "len(label_encoder1.classes_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r00cFC_XTowx",
        "outputId": "f6b694f4-d324-4686-dd3d-ab63075b0a2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Result of Television & Video:\n",
            "(122, 2795)\n",
            "(65, 2795)\n",
            "Epoch 1/50\n",
            "25/25 [==============================] - 1s 9ms/step - loss: 0.6235 - val_loss: 0.5433\n",
            "Epoch 2/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.1996 - val_loss: 0.1853\n",
            "Epoch 3/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0388 - val_loss: 0.0898\n",
            "Epoch 4/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0275 - val_loss: 0.0732\n",
            "Epoch 5/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0249 - val_loss: 0.0630\n",
            "Epoch 6/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0233 - val_loss: 0.0593\n",
            "Epoch 7/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0224 - val_loss: 0.0558\n",
            "Epoch 8/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0215 - val_loss: 0.0542\n",
            "Epoch 9/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0212 - val_loss: 0.0534\n",
            "Epoch 10/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0205 - val_loss: 0.0511\n",
            "Epoch 11/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0202 - val_loss: 0.0505\n",
            "Epoch 12/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0196 - val_loss: 0.0493\n",
            "Epoch 13/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0194 - val_loss: 0.0484\n",
            "Epoch 14/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0193 - val_loss: 0.0483\n",
            "Epoch 15/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0191 - val_loss: 0.0458\n",
            "Epoch 16/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0189 - val_loss: 0.0446\n",
            "Epoch 17/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0185 - val_loss: 0.0440\n",
            "Epoch 18/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0186 - val_loss: 0.0429\n",
            "Epoch 19/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0182 - val_loss: 0.0427\n",
            "Epoch 20/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0181 - val_loss: 0.0409\n",
            "Epoch 21/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0180 - val_loss: 0.0395\n",
            "Epoch 22/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0178 - val_loss: 0.0396\n",
            "Epoch 23/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0177 - val_loss: 0.0390\n",
            "Epoch 24/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0177 - val_loss: 0.0380\n",
            "Epoch 25/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0177 - val_loss: 0.0372\n",
            "Epoch 26/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0175 - val_loss: 0.0372\n",
            "Epoch 27/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0174 - val_loss: 0.0362\n",
            "Epoch 28/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0173 - val_loss: 0.0357\n",
            "Epoch 29/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0173 - val_loss: 0.0353\n",
            "Epoch 30/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0173 - val_loss: 0.0347\n",
            "Epoch 31/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0173 - val_loss: 0.0345\n",
            "Epoch 32/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0171 - val_loss: 0.0339\n",
            "Epoch 33/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0171 - val_loss: 0.0331\n",
            "Epoch 34/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0170 - val_loss: 0.0329\n",
            "Epoch 35/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0169 - val_loss: 0.0325\n",
            "Epoch 36/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0168 - val_loss: 0.0323\n",
            "Epoch 37/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0168 - val_loss: 0.0320\n",
            "Epoch 38/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0167 - val_loss: 0.0321\n",
            "Epoch 39/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0166 - val_loss: 0.0312\n",
            "Epoch 40/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0165 - val_loss: 0.0308\n",
            "Epoch 41/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0164 - val_loss: 0.0305\n",
            "Epoch 42/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0164 - val_loss: 0.0303\n",
            "Epoch 43/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0163 - val_loss: 0.0295\n",
            "Epoch 44/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0162 - val_loss: 0.0295\n",
            "Epoch 45/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0161 - val_loss: 0.0292\n",
            "Epoch 46/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0160 - val_loss: 0.0291\n",
            "Epoch 47/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0159 - val_loss: 0.0286\n",
            "Epoch 48/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0159 - val_loss: 0.0280\n",
            "Epoch 49/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0157 - val_loss: 0.0281\n",
            "Epoch 50/50\n",
            "25/25 [==============================] - 0s 4ms/step - loss: 0.0157 - val_loss: 0.0276\n",
            "4/4 [==============================] - 0s 2ms/step\n",
            "3/3 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Epoch 1/50\n",
            "25/25 [==============================] - 3s 30ms/step - loss: 10.2527 - accuracy: 0.1803 - val_loss: 3.6777 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "25/25 [==============================] - 0s 20ms/step - loss: 2.7827 - accuracy: 0.2049 - val_loss: 4.0091 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "25/25 [==============================] - 0s 20ms/step - loss: 2.5717 - accuracy: 0.2869 - val_loss: 3.7309 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/50\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 2.2948 - accuracy: 0.3279 - val_loss: 3.9554 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/50\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 2.2086 - accuracy: 0.2869 - val_loss: 4.1808 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/50\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 1.9522 - accuracy: 0.3852 - val_loss: 3.8767 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/50\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 1.9464 - accuracy: 0.3443 - val_loss: 3.9795 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/50\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 1.7721 - accuracy: 0.4590 - val_loss: 4.0626 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/50\n",
            "25/25 [==============================] - 0s 20ms/step - loss: 1.5896 - accuracy: 0.5574 - val_loss: 4.0735 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/50\n",
            "25/25 [==============================] - 0s 20ms/step - loss: 1.5559 - accuracy: 0.5164 - val_loss: 4.5591 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/50\n",
            "25/25 [==============================] - 0s 20ms/step - loss: 1.3200 - accuracy: 0.6148 - val_loss: 4.2991 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/50\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 1.4474 - accuracy: 0.5082 - val_loss: 4.3798 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/50\n",
            "25/25 [==============================] - 0s 20ms/step - loss: 1.2770 - accuracy: 0.6148 - val_loss: 4.4494 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/50\n",
            "25/25 [==============================] - 0s 20ms/step - loss: 1.1346 - accuracy: 0.6639 - val_loss: 5.1396 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/50\n",
            "25/25 [==============================] - 0s 20ms/step - loss: 1.1099 - accuracy: 0.6557 - val_loss: 4.8740 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/50\n",
            "25/25 [==============================] - 0s 20ms/step - loss: 1.1021 - accuracy: 0.6721 - val_loss: 4.4588 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/50\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 1.0954 - accuracy: 0.6639 - val_loss: 4.4531 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/50\n",
            "25/25 [==============================] - 0s 20ms/step - loss: 0.9813 - accuracy: 0.7213 - val_loss: 4.5232 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/50\n",
            "25/25 [==============================] - 0s 20ms/step - loss: 0.8683 - accuracy: 0.7295 - val_loss: 4.9321 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/50\n",
            "25/25 [==============================] - 0s 20ms/step - loss: 0.7711 - accuracy: 0.7705 - val_loss: 4.8612 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/50\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 0.8038 - accuracy: 0.7459 - val_loss: 5.1118 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/50\n",
            "25/25 [==============================] - 0s 20ms/step - loss: 0.7437 - accuracy: 0.7459 - val_loss: 5.3540 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/50\n",
            "25/25 [==============================] - 0s 20ms/step - loss: 0.8478 - accuracy: 0.7541 - val_loss: 4.6051 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/50\n",
            "25/25 [==============================] - 0s 20ms/step - loss: 0.7221 - accuracy: 0.7541 - val_loss: 5.3237 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/50\n",
            "25/25 [==============================] - 0s 20ms/step - loss: 0.6732 - accuracy: 0.7869 - val_loss: 4.5765 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/50\n",
            "25/25 [==============================] - 0s 20ms/step - loss: 0.5994 - accuracy: 0.8115 - val_loss: 5.3185 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/50\n",
            "25/25 [==============================] - 0s 20ms/step - loss: 0.7677 - accuracy: 0.7623 - val_loss: 4.8994 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/50\n",
            "25/25 [==============================] - 0s 20ms/step - loss: 0.5545 - accuracy: 0.8443 - val_loss: 5.2999 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/50\n",
            "25/25 [==============================] - 0s 20ms/step - loss: 0.6023 - accuracy: 0.8115 - val_loss: 5.7071 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/50\n",
            "25/25 [==============================] - 0s 20ms/step - loss: 0.6456 - accuracy: 0.8197 - val_loss: 5.0572 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/50\n",
            "25/25 [==============================] - 0s 20ms/step - loss: 0.6711 - accuracy: 0.7787 - val_loss: 5.9618 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/50\n",
            "25/25 [==============================] - 0s 20ms/step - loss: 0.6217 - accuracy: 0.8197 - val_loss: 5.4075 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/50\n",
            "25/25 [==============================] - 0s 20ms/step - loss: 0.5760 - accuracy: 0.8443 - val_loss: 5.3266 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/50\n",
            "25/25 [==============================] - 0s 20ms/step - loss: 0.6948 - accuracy: 0.7787 - val_loss: 5.0044 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/50\n",
            "25/25 [==============================] - 1s 20ms/step - loss: 0.6181 - accuracy: 0.8115 - val_loss: 6.0196 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/50\n",
            "25/25 [==============================] - 0s 20ms/step - loss: 0.5473 - accuracy: 0.8197 - val_loss: 5.2197 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/50\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 0.5568 - accuracy: 0.8279 - val_loss: 6.2334 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/50\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 0.5748 - accuracy: 0.8115 - val_loss: 5.9859 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/50\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 0.5289 - accuracy: 0.8525 - val_loss: 5.4428 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/50\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 0.5336 - accuracy: 0.8525 - val_loss: 5.8786 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/50\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 0.4777 - accuracy: 0.8443 - val_loss: 5.7066 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/50\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 0.4856 - accuracy: 0.8525 - val_loss: 5.9650 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/50\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 0.4683 - accuracy: 0.8689 - val_loss: 5.4447 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/50\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 0.4362 - accuracy: 0.8361 - val_loss: 5.4918 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/50\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 0.4687 - accuracy: 0.8443 - val_loss: 5.6430 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/50\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 0.3750 - accuracy: 0.8770 - val_loss: 5.8578 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/50\n",
            "25/25 [==============================] - 0s 20ms/step - loss: 0.4468 - accuracy: 0.8607 - val_loss: 6.1230 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/50\n",
            "25/25 [==============================] - 0s 19ms/step - loss: 0.3786 - accuracy: 0.8525 - val_loss: 5.6620 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/50\n",
            "25/25 [==============================] - 0s 20ms/step - loss: 0.4292 - accuracy: 0.8607 - val_loss: 6.3119 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/50\n",
            "25/25 [==============================] - 0s 20ms/step - loss: 0.4011 - accuracy: 0.8607 - val_loss: 6.7854 - val_accuracy: 0.0000e+00\n",
            "3/3 [==============================] - 0s 9ms/step - loss: 2.5016 - accuracy: 0.7846\n",
            "Test Accuracy: 0.7846153974533081\n",
            "3/3 [==============================] - 0s 7ms/step\n"
          ]
        }
      ],
      "source": [
        "# Model for category  'Television & Video'\n",
        "print(' Result of Television & Video:')\n",
        "if len(testinp9)!=0:\n",
        "    encoded_labels_train, encoded_labels_test, encoded_labels_val,label_encoder=encode_labels(inp9['leaf'],testinp9['leaf'],val9['leaf'])\n",
        "    X_train_leaf,X_test_leaf,X_val_leaf=tf_idf_vectorization(inp9,testinp9,val9)\n",
        "    X_train_encoded,X_test_encoded,X_val_encoded=train_denoising_autoencoder(X_train_leaf, X_test_leaf, X_val_leaf)\n",
        "    input_dim_dbn = X_train_encoded.shape[1]\n",
        "    #test images loading\n",
        "    X_test_img=Load_images(testinp9)\n",
        "    X_train_img=Load_images(inp9)\n",
        "    X_val_img=Load_images(val9)\n",
        "    input_dim_dbn = X_train_encoded.shape[1]\n",
        "    num_classes = 30 # Set the input dimensions based on the DBN input shape\n",
        "    ep=50\n",
        "    size=5\n",
        "    model= cnn_dbn(num_classes,X_train_img,X_train_encoded,encoded_labels_train,ep,size,X_val_img,X_val_encoded,encoded_labels_val)\n",
        "\n",
        "    # Evaluate the multi-modal model\n",
        "    loss, accuracy = model.evaluate([X_test_img, X_test_encoded], encoded_labels_test)\n",
        "    print(f'Test Accuracy: {accuracy}')\n",
        "    predicted_probabilities= model.predict([X_test_img, X_test_encoded])\n",
        "    # Convert probabilities to class indices (argmax to get the index of the highest probability)\n",
        "    predicted_class_indices = np.argmax(predicted_probabilities, axis=1)\n",
        "\n",
        "    # Convert class indices back to original labels using inverse_transform of label_encoder\n",
        "    predicted_labels = label_encoder.inverse_transform(predicted_class_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HMYOblwwTowx",
        "outputId": "074dadab-022f-4e97-cd8a-8034faf5c8ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-47-218184d33405>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  testinp9['pleaf']=predicted_labels\n"
          ]
        }
      ],
      "source": [
        "#72\n",
        "file_path = 'testinp9.csv'\n",
        "# Display predicted labels\n",
        "testinp9['pleaf']=predicted_labels\n",
        "# Save the modified 'test' DataFrame to a CSV file without the DataFrame index\n",
        "testinp9.to_csv(file_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F63MNsQNTowx",
        "outputId": "97675950-786a-4809-ae2d-b609ea6781bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "# Model for category  'GPS & Navigation'\n",
        "import gc\n",
        "gc.collect()\n",
        "encoded_labels_train, encoded_labels_test, encoded_labels_val,label_encoder1=encode_labels(inp10['leaf'],testinp10['leaf'],val10['leaf'])\n",
        "len(label_encoder1.classes_)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model for category  'Home Audio'\n",
        "\n",
        "print(' Result of Home Audio:')\n",
        "if len(testinp10)!=0:\n",
        "    encoded_labels_train, encoded_labels_test, encoded_labels_val,label_encoder=encode_labels(inp10['leaf'],testinp10['leaf'],val10['leaf'])\n",
        "    X_train_leaf,X_test_leaf,X_val_leaf=tf_idf_vectorization(inp10,testinp10,val10)\n",
        "    X_train_encoded,X_test_encoded,X_val_encoded=train_denoising_autoencoder(X_train_leaf, X_test_leaf, X_val_leaf)\n",
        "    input_dim_dbn = X_train_encoded.shape[1]\n",
        "    #test images loading\n",
        "    X_test_img=Load_images(testinp10)\n",
        "    X_train_img=Load_images(inp10)\n",
        "    X_val_img=Load_images(val10)\n",
        "    input_dim_dbn = X_train_encoded.shape[1]\n",
        "    num_classes = 55 # Set the input dimensions based on the DBN input shape\n",
        "    ep=50\n",
        "    size=5\n",
        "    model= cnn_dbn(num_classes,X_train_img,X_train_encoded,encoded_labels_train,ep,size,X_val_img,X_val_encoded,encoded_labels_val)\n",
        "\n",
        "    # Evaluate the multi-modal model\n",
        "    loss, accuracy = model.evaluate([X_test_img, X_test_encoded], encoded_labels_test)\n",
        "    print(f'Test Accuracy: {accuracy}')\n",
        "    predicted_probabilities= model.predict([X_test_img, X_test_encoded])\n",
        "    # Convert probabilities to class indices (argmax to get the index of the highest probability)\n",
        "    predicted_class_indices = np.argmax(predicted_probabilities, axis=1)\n",
        "\n",
        "    # Convert class indices back to original labels using inverse_transform of label_encoder\n",
        "    predicted_labels = label_encoder.inverse_transform(predicted_class_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ls72_JsYyevo",
        "outputId": "2d9f7e8c-8508-454e-f8f0-4463dc609601"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Result of Home Audio:\n",
            "(230, 3134)\n",
            "(106, 3134)\n",
            "Epoch 1/50\n",
            "46/46 [==============================] - 1s 6ms/step - loss: 0.4883 - val_loss: 0.1857\n",
            "Epoch 2/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0480 - val_loss: 0.0369\n",
            "Epoch 3/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0201 - val_loss: 0.0270\n",
            "Epoch 4/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0171 - val_loss: 0.0235\n",
            "Epoch 5/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0159 - val_loss: 0.0223\n",
            "Epoch 6/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0152 - val_loss: 0.0209\n",
            "Epoch 7/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0146 - val_loss: 0.0205\n",
            "Epoch 8/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0141 - val_loss: 0.0202\n",
            "Epoch 9/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0138 - val_loss: 0.0201\n",
            "Epoch 10/50\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.0200\n",
            "Epoch 11/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0132 - val_loss: 0.0197\n",
            "Epoch 12/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0131 - val_loss: 0.0196\n",
            "Epoch 13/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0129 - val_loss: 0.0194\n",
            "Epoch 14/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0128 - val_loss: 0.0189\n",
            "Epoch 15/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0127 - val_loss: 0.0187\n",
            "Epoch 16/50\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.0125 - val_loss: 0.0186\n",
            "Epoch 17/50\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.0125 - val_loss: 0.0183\n",
            "Epoch 18/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0124 - val_loss: 0.0183\n",
            "Epoch 19/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0123 - val_loss: 0.0181\n",
            "Epoch 20/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.0179\n",
            "Epoch 21/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0122 - val_loss: 0.0179\n",
            "Epoch 22/50\n",
            "46/46 [==============================] - 0s 4ms/step - loss: 0.0121 - val_loss: 0.0177\n",
            "Epoch 23/50\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.0120 - val_loss: 0.0176\n",
            "Epoch 24/50\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.0174\n",
            "Epoch 25/50\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.0119 - val_loss: 0.0174\n",
            "Epoch 26/50\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.0118 - val_loss: 0.0171\n",
            "Epoch 27/50\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.0170\n",
            "Epoch 28/50\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.0117 - val_loss: 0.0168\n",
            "Epoch 29/50\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.0116 - val_loss: 0.0168\n",
            "Epoch 30/50\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.0115 - val_loss: 0.0167\n",
            "Epoch 31/50\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.0115 - val_loss: 0.0168\n",
            "Epoch 32/50\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0165\n",
            "Epoch 33/50\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0166\n",
            "Epoch 34/50\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.0113 - val_loss: 0.0159\n",
            "Epoch 35/50\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.0160\n",
            "Epoch 36/50\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.0111 - val_loss: 0.0162\n",
            "Epoch 37/50\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.0110 - val_loss: 0.0161\n",
            "Epoch 38/50\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.0110 - val_loss: 0.0160\n",
            "Epoch 39/50\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.0108 - val_loss: 0.0156\n",
            "Epoch 40/50\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.0108 - val_loss: 0.0159\n",
            "Epoch 41/50\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.0107 - val_loss: 0.0157\n",
            "Epoch 42/50\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.0106 - val_loss: 0.0153\n",
            "Epoch 43/50\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.0105 - val_loss: 0.0154\n",
            "Epoch 44/50\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.0104 - val_loss: 0.0152\n",
            "Epoch 45/50\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.0103 - val_loss: 0.0153\n",
            "Epoch 46/50\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.0102 - val_loss: 0.0150\n",
            "Epoch 47/50\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.0101 - val_loss: 0.0148\n",
            "Epoch 48/50\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.0100 - val_loss: 0.0147\n",
            "Epoch 49/50\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.0099 - val_loss: 0.0146\n",
            "Epoch 50/50\n",
            "46/46 [==============================] - 0s 3ms/step - loss: 0.0098 - val_loss: 0.0147\n",
            "8/8 [==============================] - 0s 2ms/step\n",
            "4/4 [==============================] - 0s 2ms/step\n",
            "1/1 [==============================] - 0s 18ms/step\n",
            "Epoch 1/50\n",
            "46/46 [==============================] - 3s 23ms/step - loss: 5.5179 - accuracy: 0.1087 - val_loss: 4.3349 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/50\n",
            "46/46 [==============================] - 1s 17ms/step - loss: 2.9002 - accuracy: 0.2217 - val_loss: 4.6978 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 2.6410 - accuracy: 0.2391 - val_loss: 5.1646 - val_accuracy: 0.0345\n",
            "Epoch 4/50\n",
            "46/46 [==============================] - 1s 17ms/step - loss: 2.5579 - accuracy: 0.2913 - val_loss: 4.5548 - val_accuracy: 0.0690\n",
            "Epoch 5/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 2.3157 - accuracy: 0.3652 - val_loss: 5.5187 - val_accuracy: 0.0345\n",
            "Epoch 6/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 2.0514 - accuracy: 0.3739 - val_loss: 6.3554 - val_accuracy: 0.0345\n",
            "Epoch 7/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 1.7908 - accuracy: 0.4652 - val_loss: 6.1465 - val_accuracy: 0.0690\n",
            "Epoch 8/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 1.7235 - accuracy: 0.5130 - val_loss: 6.4039 - val_accuracy: 0.0345\n",
            "Epoch 9/50\n",
            "46/46 [==============================] - 1s 17ms/step - loss: 1.5057 - accuracy: 0.5652 - val_loss: 6.6930 - val_accuracy: 0.0690\n",
            "Epoch 10/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 1.3280 - accuracy: 0.6130 - val_loss: 7.5561 - val_accuracy: 0.0690\n",
            "Epoch 11/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 1.3742 - accuracy: 0.6130 - val_loss: 6.1907 - val_accuracy: 0.0345\n",
            "Epoch 12/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 1.3106 - accuracy: 0.5957 - val_loss: 6.7328 - val_accuracy: 0.0345\n",
            "Epoch 13/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 1.2771 - accuracy: 0.6087 - val_loss: 7.8305 - val_accuracy: 0.0345\n",
            "Epoch 14/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 1.0567 - accuracy: 0.6565 - val_loss: 8.0967 - val_accuracy: 0.0345\n",
            "Epoch 15/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 1.0352 - accuracy: 0.6870 - val_loss: 8.1969 - val_accuracy: 0.0345\n",
            "Epoch 16/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.9642 - accuracy: 0.7304 - val_loss: 7.5127 - val_accuracy: 0.0345\n",
            "Epoch 17/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 1.0293 - accuracy: 0.7174 - val_loss: 9.6240 - val_accuracy: 0.0690\n",
            "Epoch 18/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.7995 - accuracy: 0.7261 - val_loss: 10.7363 - val_accuracy: 0.0690\n",
            "Epoch 19/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.7746 - accuracy: 0.7304 - val_loss: 11.5797 - val_accuracy: 0.0690\n",
            "Epoch 20/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.8137 - accuracy: 0.7348 - val_loss: 10.4026 - val_accuracy: 0.0345\n",
            "Epoch 21/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.6569 - accuracy: 0.7739 - val_loss: 10.7380 - val_accuracy: 0.0690\n",
            "Epoch 22/50\n",
            "46/46 [==============================] - 1s 19ms/step - loss: 0.6705 - accuracy: 0.7739 - val_loss: 11.1008 - val_accuracy: 0.0690\n",
            "Epoch 23/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.6187 - accuracy: 0.7957 - val_loss: 13.2710 - val_accuracy: 0.0690\n",
            "Epoch 24/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.7208 - accuracy: 0.7565 - val_loss: 12.3124 - val_accuracy: 0.0690\n",
            "Epoch 25/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.5129 - accuracy: 0.8435 - val_loss: 10.3385 - val_accuracy: 0.0690\n",
            "Epoch 26/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.6065 - accuracy: 0.8304 - val_loss: 9.3099 - val_accuracy: 0.0690\n",
            "Epoch 27/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.5881 - accuracy: 0.8130 - val_loss: 10.5435 - val_accuracy: 0.0690\n",
            "Epoch 28/50\n",
            "46/46 [==============================] - 1s 19ms/step - loss: 0.5895 - accuracy: 0.8130 - val_loss: 9.6273 - val_accuracy: 0.0690\n",
            "Epoch 29/50\n",
            "46/46 [==============================] - 1s 19ms/step - loss: 0.5360 - accuracy: 0.8217 - val_loss: 12.2667 - val_accuracy: 0.0690\n",
            "Epoch 30/50\n",
            "46/46 [==============================] - 1s 19ms/step - loss: 0.5258 - accuracy: 0.8478 - val_loss: 12.2364 - val_accuracy: 0.0690\n",
            "Epoch 31/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.6459 - accuracy: 0.8043 - val_loss: 12.2224 - val_accuracy: 0.0690\n",
            "Epoch 32/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.5260 - accuracy: 0.8261 - val_loss: 12.4069 - val_accuracy: 0.0345\n",
            "Epoch 33/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.3925 - accuracy: 0.8652 - val_loss: 9.7668 - val_accuracy: 0.0690\n",
            "Epoch 34/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.3258 - accuracy: 0.9000 - val_loss: 10.1488 - val_accuracy: 0.0690\n",
            "Epoch 35/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.2964 - accuracy: 0.9000 - val_loss: 13.7843 - val_accuracy: 0.0345\n",
            "Epoch 36/50\n",
            "46/46 [==============================] - 1s 17ms/step - loss: 0.4470 - accuracy: 0.8739 - val_loss: 11.7935 - val_accuracy: 0.0690\n",
            "Epoch 37/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.5380 - accuracy: 0.8174 - val_loss: 11.5909 - val_accuracy: 0.0690\n",
            "Epoch 38/50\n",
            "46/46 [==============================] - 1s 17ms/step - loss: 0.3423 - accuracy: 0.9087 - val_loss: 11.4724 - val_accuracy: 0.0690\n",
            "Epoch 39/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.3471 - accuracy: 0.8870 - val_loss: 11.4533 - val_accuracy: 0.0690\n",
            "Epoch 40/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.4747 - accuracy: 0.8783 - val_loss: 9.3640 - val_accuracy: 0.0690\n",
            "Epoch 41/50\n",
            "46/46 [==============================] - 1s 17ms/step - loss: 0.4984 - accuracy: 0.8391 - val_loss: 9.4038 - val_accuracy: 0.0345\n",
            "Epoch 42/50\n",
            "46/46 [==============================] - 1s 17ms/step - loss: 0.4323 - accuracy: 0.9000 - val_loss: 9.9916 - val_accuracy: 0.0690\n",
            "Epoch 43/50\n",
            "46/46 [==============================] - 1s 17ms/step - loss: 0.3261 - accuracy: 0.9130 - val_loss: 9.2293 - val_accuracy: 0.0345\n",
            "Epoch 44/50\n",
            "46/46 [==============================] - 1s 17ms/step - loss: 0.3267 - accuracy: 0.9130 - val_loss: 11.1944 - val_accuracy: 0.0690\n",
            "Epoch 45/50\n",
            "46/46 [==============================] - 1s 17ms/step - loss: 0.4063 - accuracy: 0.8565 - val_loss: 9.6546 - val_accuracy: 0.0690\n",
            "Epoch 46/50\n",
            "46/46 [==============================] - 1s 17ms/step - loss: 0.2716 - accuracy: 0.9174 - val_loss: 10.6759 - val_accuracy: 0.0345\n",
            "Epoch 47/50\n",
            "46/46 [==============================] - 1s 17ms/step - loss: 0.2318 - accuracy: 0.9087 - val_loss: 10.4620 - val_accuracy: 0.0690\n",
            "Epoch 48/50\n",
            "46/46 [==============================] - 1s 17ms/step - loss: 0.2029 - accuracy: 0.9348 - val_loss: 12.0364 - val_accuracy: 0.0690\n",
            "Epoch 49/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.2676 - accuracy: 0.9174 - val_loss: 10.3478 - val_accuracy: 0.0345\n",
            "Epoch 50/50\n",
            "46/46 [==============================] - 1s 18ms/step - loss: 0.2798 - accuracy: 0.9087 - val_loss: 9.9205 - val_accuracy: 0.0690\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 3.4090 - accuracy: 0.5472\n",
            "Test Accuracy: 0.5471698045730591\n",
            "4/4 [==============================] - 0s 8ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4DS7DI8uTowy",
        "outputId": "b985c8c8-c37f-4ae0-80be-25b560464919",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-55-38e11dd002e2>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  testinp10['pleaf']=predicted_labels\n"
          ]
        }
      ],
      "source": [
        "#56\n",
        "file_path = 'testinp10.csv'\n",
        "# Display predicted labels\n",
        "testinp10['pleaf']=predicted_labels\n",
        "# Save the modified 'test' DataFrame to a CSV file without the DataFrame index\n",
        "testinp10.to_csv(file_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zg2XkixTowy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92c05510-bb00-46ba-d29e-5c87ad679307"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "# Model for category  'GPS & Navigation'\n",
        "import gc\n",
        "gc.collect()\n",
        "encoded_labels_train, encoded_labels_test, encoded_labels_val,label_encoder1=encode_labels(inp11['leaf'],testinp11['leaf'],val11['leaf'])\n",
        "len(label_encoder1.classes_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hgX6lbsdTowy",
        "outputId": "28fbcbd0-46a8-4d86-cc75-ed7bcb45e1c1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Result of Security & Surveillance:\n",
            "(16, 465)\n",
            "(2, 465)\n",
            "Epoch 1/50\n",
            "4/4 [==============================] - 1s 44ms/step - loss: 0.6900 - val_loss: 0.6780\n",
            "Epoch 2/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6728 - val_loss: 0.6611\n",
            "Epoch 3/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6520 - val_loss: 0.6411\n",
            "Epoch 4/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.6262 - val_loss: 0.6168\n",
            "Epoch 5/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5893 - val_loss: 0.5881\n",
            "Epoch 6/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.5467 - val_loss: 0.5528\n",
            "Epoch 7/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4958 - val_loss: 0.5113\n",
            "Epoch 8/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.4308 - val_loss: 0.4640\n",
            "Epoch 9/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3785 - val_loss: 0.4123\n",
            "Epoch 10/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.3110 - val_loss: 0.3585\n",
            "Epoch 11/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2533 - val_loss: 0.3064\n",
            "Epoch 12/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.2057 - val_loss: 0.2585\n",
            "Epoch 13/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1637 - val_loss: 0.2178\n",
            "Epoch 14/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1333 - val_loss: 0.1851\n",
            "Epoch 15/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1155 - val_loss: 0.1588\n",
            "Epoch 16/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.1026 - val_loss: 0.1385\n",
            "Epoch 17/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0956 - val_loss: 0.1226\n",
            "Epoch 18/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0857 - val_loss: 0.1109\n",
            "Epoch 19/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0806 - val_loss: 0.1029\n",
            "Epoch 20/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0776 - val_loss: 0.0966\n",
            "Epoch 21/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0741 - val_loss: 0.0917\n",
            "Epoch 22/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0708 - val_loss: 0.0880\n",
            "Epoch 23/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0709 - val_loss: 0.0848\n",
            "Epoch 24/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0693 - val_loss: 0.0823\n",
            "Epoch 25/50\n",
            "4/4 [==============================] - 0s 9ms/step - loss: 0.0670 - val_loss: 0.0802\n",
            "Epoch 26/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0667 - val_loss: 0.0792\n",
            "Epoch 27/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0647 - val_loss: 0.0784\n",
            "Epoch 28/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0652 - val_loss: 0.0784\n",
            "Epoch 29/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0647 - val_loss: 0.0779\n",
            "Epoch 30/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0639 - val_loss: 0.0777\n",
            "Epoch 31/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0628 - val_loss: 0.0773\n",
            "Epoch 32/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0620 - val_loss: 0.0763\n",
            "Epoch 33/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0622 - val_loss: 0.0752\n",
            "Epoch 34/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0615 - val_loss: 0.0745\n",
            "Epoch 35/50\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0603 - val_loss: 0.0737\n",
            "Epoch 36/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0600 - val_loss: 0.0733\n",
            "Epoch 37/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0591 - val_loss: 0.0730\n",
            "Epoch 38/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0594 - val_loss: 0.0729\n",
            "Epoch 39/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0587 - val_loss: 0.0729\n",
            "Epoch 40/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0588 - val_loss: 0.0725\n",
            "Epoch 41/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0572 - val_loss: 0.0723\n",
            "Epoch 42/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0570 - val_loss: 0.0720\n",
            "Epoch 43/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0569 - val_loss: 0.0716\n",
            "Epoch 44/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0565 - val_loss: 0.0712\n",
            "Epoch 45/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0565 - val_loss: 0.0710\n",
            "Epoch 46/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0560 - val_loss: 0.0708\n",
            "Epoch 47/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0557 - val_loss: 0.0707\n",
            "Epoch 48/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0551 - val_loss: 0.0704\n",
            "Epoch 49/50\n",
            "4/4 [==============================] - 0s 10ms/step - loss: 0.0550 - val_loss: 0.0703\n",
            "Epoch 50/50\n",
            "4/4 [==============================] - 0s 11ms/step - loss: 0.0556 - val_loss: 0.0700\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "Epoch 1/35\n",
            "4/4 [==============================] - 3s 93ms/step - loss: 26.1586 - accuracy: 0.1250 - val_loss: 18.7856 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/35\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 26.3142 - accuracy: 0.1250 - val_loss: 15.2177 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/35\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 18.5480 - accuracy: 0.1875 - val_loss: 11.1295 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/35\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 7.1162 - accuracy: 0.2500 - val_loss: 8.1784 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/35\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 10.4637 - accuracy: 0.1250 - val_loss: 6.8009 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/35\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 6.4517 - accuracy: 0.1250 - val_loss: 5.1660 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/35\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 4.0296 - accuracy: 0.0625 - val_loss: 3.5334 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/35\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 2.5458 - accuracy: 0.2500 - val_loss: 2.9354 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/35\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 2.3859 - accuracy: 0.1250 - val_loss: 2.6334 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/35\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 2.0295 - accuracy: 0.1250 - val_loss: 2.8173 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/35\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 2.6715 - accuracy: 0.3125 - val_loss: 3.0863 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/35\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 2.0309 - accuracy: 0.3125 - val_loss: 3.1703 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/35\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 2.0685 - accuracy: 0.2500 - val_loss: 3.3436 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/35\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1.9644 - accuracy: 0.3125 - val_loss: 3.5009 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/35\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1.7526 - accuracy: 0.5000 - val_loss: 3.7993 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/35\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 2.0973 - accuracy: 0.3125 - val_loss: 3.7104 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/35\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1.6169 - accuracy: 0.4375 - val_loss: 3.9458 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/35\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1.7845 - accuracy: 0.3750 - val_loss: 4.6799 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/35\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1.7620 - accuracy: 0.3750 - val_loss: 5.2568 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/35\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1.8012 - accuracy: 0.3750 - val_loss: 5.2110 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/35\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1.7965 - accuracy: 0.3125 - val_loss: 5.3829 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/35\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1.9550 - accuracy: 0.3125 - val_loss: 5.4286 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/35\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1.3829 - accuracy: 0.5000 - val_loss: 5.2521 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/35\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1.7910 - accuracy: 0.1250 - val_loss: 5.1112 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/35\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1.7237 - accuracy: 0.1875 - val_loss: 4.9525 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/35\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 1.3776 - accuracy: 0.6875 - val_loss: 4.9937 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/35\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1.9123 - accuracy: 0.1875 - val_loss: 4.9839 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/35\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 2.0041 - accuracy: 0.2500 - val_loss: 4.4325 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/35\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1.7287 - accuracy: 0.3750 - val_loss: 4.5994 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/35\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 1.9200 - accuracy: 0.2500 - val_loss: 4.1603 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/35\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1.4889 - accuracy: 0.2500 - val_loss: 3.9047 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/35\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1.5952 - accuracy: 0.3750 - val_loss: 3.7723 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/35\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1.4289 - accuracy: 0.4375 - val_loss: 4.0830 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/35\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 1.6783 - accuracy: 0.3125 - val_loss: 4.3762 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/35\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 1.5413 - accuracy: 0.4375 - val_loss: 5.0082 - val_accuracy: 0.0000e+00\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.3868 - accuracy: 0.0000e+00\n",
            "Test Accuracy: 0.0\n",
            "1/1 [==============================] - 0s 97ms/step\n"
          ]
        }
      ],
      "source": [
        "# Model for category  'Security & Surveillance'\n",
        "\n",
        "print(' Result of Security & Surveillance:')\n",
        "if len(testinp11)!=0:\n",
        "    encoded_labels_train, encoded_labels_test, encoded_labels_val,label_encoder=encode_labels(inp11['leaf'],testinp11['leaf'],val11['leaf'])\n",
        "    X_train_leaf,X_test_leaf,X_val_leaf=tf_idf_vectorization(inp11,testinp11,val11)\n",
        "    X_train_encoded,X_test_encoded,X_val_encoded=train_denoising_autoencoder(X_train_leaf, X_test_leaf, X_val_leaf)\n",
        "    input_dim_dbn = X_train_encoded.shape[1]\n",
        "    #test images loading\n",
        "    X_test_img=Load_images(testinp11)\n",
        "    X_train_img=Load_images(inp11)\n",
        "    X_val_img=Load_images(val11)\n",
        "    input_dim_dbn = X_train_encoded.shape[1]\n",
        "    num_classes = 11 # Set the input dimensions based on the DBN input shape\n",
        "    ep=35\n",
        "    size=5\n",
        "    model= cnn_dbn(num_classes,X_train_img,X_train_encoded,encoded_labels_train,ep,size,X_val_img,X_val_encoded,encoded_labels_val)\n",
        "\n",
        "    # Evaluate the multi-modal model\n",
        "    loss, accuracy = model.evaluate([X_test_img, X_test_encoded], encoded_labels_test)\n",
        "    print(f'Test Accuracy: {accuracy}')\n",
        "    predicted_probabilities= model.predict([X_test_img, X_test_encoded])\n",
        "    # Convert probabilities to class indices (argmax to get the index of the highest probability)\n",
        "    predicted_class_indices = np.argmax(predicted_probabilities, axis=1)\n",
        "\n",
        "    # Convert class indices back to original labels using inverse_transform of label_encoder\n",
        "    predicted_labels = label_encoder.inverse_transform(predicted_class_indices)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G0_qPeYZTowy",
        "outputId": "dd7ff9fe-9ce4-419c-f4d1-3e6fd93aa09b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-60-6cb33d7c7699>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  testinp11['pleaf']=predicted_labels\n"
          ]
        }
      ],
      "source": [
        "#55\n",
        "file_path = 'testinp11.csv'\n",
        "# Display predicted labels\n",
        "testinp11['pleaf']=predicted_labels\n",
        "# Save the modified 'test' DataFrame to a CSV file without the DataFrame index\n",
        "testinp11.to_csv(file_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d4HT6ul1Towy",
        "outputId": "ae59311c-ba78-430b-c025-3eb751971754",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                  title description  \\\n",
              "1508  Minolta APS Adapter Ad-10 For Dimage Scan Dual...               \n",
              "1985  Altec Lansing XA3051 5.1 Speakers (6-Speaker, ...               \n",
              "\n",
              "                                                  imUrl  price brand  \\\n",
              "1508  http://ecx.images-amazon.com/images/I/21GYT3DE...  134.5         \n",
              "1985  http://ecx.images-amazon.com/images/I/41M7MZ4P...  134.5         \n",
              "\n",
              "     categories__1            categories__2         categories__3  \\\n",
              "1508   Electronics           Camera & Photo           Accessories   \n",
              "1985   Electronics  Computers & Accessories  Cables & Accessories   \n",
              "\n",
              "             categories__4 categories__5 categories__6  \\\n",
              "1508  Batteries & Chargers      Adapters                 \n",
              "1985     Computer Speakers                               \n",
              "\n",
              "                                        lemmatized_text  \\\n",
              "1508  ['minolta', 'aps', 'adapter', 'dimage', 'scan'...   \n",
              "1985  ['altec', 'lansing', 'speaker', 'black', 'amp'...   \n",
              "\n",
              "                                final_lemmatized_string  \\\n",
              "1508   minolta aps adapter dimage scan dual amp scan...   \n",
              "1985             altec lansing speaker black amp silver   \n",
              "\n",
              "                                 image           pcategories__2  \\\n",
              "1508  test_images/test_images/1508.jpg  security & surveillance   \n",
              "1985  test_images/test_images/1985.jpg  security & surveillance   \n",
              "\n",
              "                   leaf           pleaf  \n",
              "1508           adapters  radio scanners  \n",
              "1985  computer speakers  radio scanners  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-05f88499-c8c3-47c8-bdcc-eb40b12db992\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>description</th>\n",
              "      <th>imUrl</th>\n",
              "      <th>price</th>\n",
              "      <th>brand</th>\n",
              "      <th>categories__1</th>\n",
              "      <th>categories__2</th>\n",
              "      <th>categories__3</th>\n",
              "      <th>categories__4</th>\n",
              "      <th>categories__5</th>\n",
              "      <th>categories__6</th>\n",
              "      <th>lemmatized_text</th>\n",
              "      <th>final_lemmatized_string</th>\n",
              "      <th>image</th>\n",
              "      <th>pcategories__2</th>\n",
              "      <th>leaf</th>\n",
              "      <th>pleaf</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1508</th>\n",
              "      <td>Minolta APS Adapter Ad-10 For Dimage Scan Dual...</td>\n",
              "      <td></td>\n",
              "      <td>http://ecx.images-amazon.com/images/I/21GYT3DE...</td>\n",
              "      <td>134.5</td>\n",
              "      <td></td>\n",
              "      <td>Electronics</td>\n",
              "      <td>Camera &amp; Photo</td>\n",
              "      <td>Accessories</td>\n",
              "      <td>Batteries &amp; Chargers</td>\n",
              "      <td>Adapters</td>\n",
              "      <td></td>\n",
              "      <td>['minolta', 'aps', 'adapter', 'dimage', 'scan'...</td>\n",
              "      <td>minolta aps adapter dimage scan dual amp scan...</td>\n",
              "      <td>test_images/test_images/1508.jpg</td>\n",
              "      <td>security &amp; surveillance</td>\n",
              "      <td>adapters</td>\n",
              "      <td>radio scanners</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1985</th>\n",
              "      <td>Altec Lansing XA3051 5.1 Speakers (6-Speaker, ...</td>\n",
              "      <td></td>\n",
              "      <td>http://ecx.images-amazon.com/images/I/41M7MZ4P...</td>\n",
              "      <td>134.5</td>\n",
              "      <td></td>\n",
              "      <td>Electronics</td>\n",
              "      <td>Computers &amp; Accessories</td>\n",
              "      <td>Cables &amp; Accessories</td>\n",
              "      <td>Computer Speakers</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>['altec', 'lansing', 'speaker', 'black', 'amp'...</td>\n",
              "      <td>altec lansing speaker black amp silver</td>\n",
              "      <td>test_images/test_images/1985.jpg</td>\n",
              "      <td>security &amp; surveillance</td>\n",
              "      <td>computer speakers</td>\n",
              "      <td>radio scanners</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-05f88499-c8c3-47c8-bdcc-eb40b12db992')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-05f88499-c8c3-47c8-bdcc-eb40b12db992 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-05f88499-c8c3-47c8-bdcc-eb40b12db992');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d0a8979d-e069-403e-b518-826d9ff53825\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d0a8979d-e069-403e-b518-826d9ff53825')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d0a8979d-e069-403e-b518-826d9ff53825 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "testinp11",
              "repr_error": "0"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "testinp11.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g2vvVRSyTowy",
        "outputId": "a62f7a10-a34b-461f-e455-d9cb53dc9e01"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2378"
            ]
          },
          "execution_count": 96,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(testinp1)+len(testinp2)+len(testinp3)+len(testinp4)+len(testinp5)+len(testinp6)+len(testinp7)+len(testinp8)+len(testinp9)+len(testinp10)+len(testinp11)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "file_paths = [\n",
        "    'testinp1.csv',  # Replace 'file1.csv' with your actual file paths\n",
        "    'testinp2.csv','testinp3.csv','testinp5.csv','testinp6.csv','testinp7.csv','testinp9.csv','testinp10.csv','testinp11.csv'\n",
        "\n",
        "]\n",
        "\n",
        "# Initialize an empty list to store DataFrames\n",
        "dfs = []\n",
        "\n",
        "# Read each CSV file and append its contents to the 'dfs' list\n",
        "for file_path in file_paths:\n",
        "    df = pd.read_csv(file_path)\n",
        "    dfs.append(df)\n",
        "\n",
        "# Concatenate all DataFrames in the 'dfs' list into a single DataFrame\n",
        "combined_df = pd.concat(dfs, ignore_index=True)  # ignore_index=True resets the indices\n",
        "\n",
        "# Calculate accuracy between 'leaf' and 'pleaf' columns\n",
        "accuracy = accuracy_score(combined_df['leaf'], combined_df['pleaf']) * 100\n",
        "print(\"Overall accuracy between 'leaf' and 'pleaf' columns:\", accuracy)\n",
        "precision = precision_score(combined_df['leaf'], combined_df['pleaf'], average='weighted')\n",
        "recall = recall_score(combined_df['leaf'], combined_df['pleaf'], average='weighted')\n",
        "f1 = f1_score(combined_df['leaf'], combined_df['pleaf'], average='weighted')\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewAIeomlWxK8",
        "outputId": "20af2d69-d4f4-42d6-991b-b06eebcb4056"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall accuracy between 'leaf' and 'pleaf' columns: 63.43937298294144\n",
            "Precision: 0.6534927811798056\n",
            "Recall: 0.6343937298294144\n",
            "F1 Score: 0.623747736585257\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5hADjbRfTowz",
        "outputId": "dd0b308d-7312-4a59-fa75-00b7c2c6b34b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overall accuracy between 'leaf' and 'pleaf' columns: 61.50299677270632\n",
            "Precision: 0.6485690629872101\n",
            "Recall: 0.6150299677270632\n",
            "F1 Score: 0.6047127008664541\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "file_paths = [\n",
        "    'testinp1.csv',  # Replace 'file1.csv' with your actual file paths\n",
        "    'testinp2.csv','testinp3.csv','testinp5.csv','testinp6.csv','testinp7.csv','testinp9.csv','testinp10.csv','testinp11.csv'\n",
        "\n",
        "]\n",
        "\n",
        "# Initialize an empty list to store DataFrames\n",
        "dfs = []\n",
        "\n",
        "# Read each CSV file and append its contents to the 'dfs' list\n",
        "for file_path in file_paths:\n",
        "    df = pd.read_csv(file_path)\n",
        "    dfs.append(df)\n",
        "\n",
        "# Concatenate all DataFrames in the 'dfs' list into a single DataFrame\n",
        "combined_df = pd.concat(dfs, ignore_index=True)  # ignore_index=True resets the indices\n",
        "\n",
        "# Calculate accuracy between 'leaf' and 'pleaf' columns\n",
        "accuracy = accuracy_score(combined_df['leaf'], combined_df['pleaf']) * 100\n",
        "print(\"Overall accuracy between 'leaf' and 'pleaf' columns:\", accuracy)\n",
        "precision = precision_score(combined_df['leaf'], combined_df['pleaf'], average='weighted')\n",
        "recall = recall_score(combined_df['leaf'], combined_df['pleaf'], average='weighted')\n",
        "f1 = f1_score(combined_df['leaf'], combined_df['pleaf'], average='weighted')\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1 Score:\", f1)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MctuIqxDWwPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SGtpQ1ZJTowz"
      },
      "outputs": [],
      "source": [
        "type(dbn_df['leaf'])\n",
        "\n",
        "Overall accuracy between 'leaf' and 'pleaf' columns: 62.01014292300599"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pRDxb4ksTowz"
      },
      "outputs": [],
      "source": [
        "file_path = 'destination.csv'\n",
        "\n",
        "# Save the DataFrame to a CSV file\n",
        "combined_df.to_csv(file_path, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7l4HiSgyTowz"
      },
      "outputs": [],
      "source": [
        "def train_denoising_autoencoder(X_train, X_new, X_new_val):\n",
        "    # Build Denoising Autoencoder (DAE)\n",
        "    input_dim = X_train.shape[1]\n",
        "    input_layer = Input(shape=(input_dim,))\n",
        "    encoded = Dense(512, activation='relu')(input_layer)\n",
        "    encoded = Dropout(0.5)(encoded)\n",
        "    decoded = Dense(input_dim, activation='sigmoid')(encoded)\n",
        "\n",
        "    dae = Model(input_layer, decoded)\n",
        "    dae.compile(optimizer='adam', loss='binary_crossentropy')\n",
        "    dae.fit(X_train.toarray(), X_train.toarray(), epochs=40, batch_size=5, validation_data=(X_new_val.toarray(), X_new_val.toarray()))\n",
        "\n",
        "    # Extract features using DAE\n",
        "    encoder = Model(input_layer, encoded)\n",
        "    X_train_encoded = encoder.predict(X_train.toarray())\n",
        "    X_test_encoded = encoder.predict(X_new.toarray())\n",
        "    X_val_encoded = encoder.predict(X_new_val.toarray())\n",
        "    return X_train_encoded, X_test_encoded, X_val_encoded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O6PRqdjYTowz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}